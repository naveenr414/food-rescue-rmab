{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Semi Synthetic Experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analyze the performance of various algorithms to solve the joint matching + activity task, when the number of volunteers is large and structured"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random \n",
    "import matplotlib.pyplot as plt\n",
    "import json \n",
    "import argparse \n",
    "import sys\n",
    "import secrets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr0/home/naveenr/miniconda3/envs/food/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from rmab.simulator import RMABSimulator, run_heterogenous_policy, get_discounted_reward, create_random_transitions\n",
    "from rmab.omniscient_policies import *\n",
    "from rmab.dqn_policies import *\n",
    "from rmab.fr_dynamics import get_all_transitions, get_db_data, get_all_transitions_partition\n",
    "from rmab.mcts_policies import *\n",
    "from rmab.utils import get_save_path, delete_duplicate_results, create_prob_distro\n",
    "import resource"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.set_per_process_memory_fraction(0.5)\n",
    "torch.set_num_threads(1)\n",
    "resource.setrlimit(resource.RLIMIT_AS, (30 * 1024 * 1024 * 1024, -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "is_jupyter = 'ipykernel' in sys.modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "if is_jupyter: \n",
    "    seed        = 44\n",
    "    n_arms      = 4\n",
    "    volunteers_per_arm = 1\n",
    "    budget      = 2\n",
    "    discount    = 0.9\n",
    "    alpha       = 3 \n",
    "    n_episodes  = 100\n",
    "    episode_len = 50 \n",
    "    n_epochs    = 1\n",
    "    save_with_date = False \n",
    "    TIME_PER_RUN = 0.01 * 1000\n",
    "    lamb = 0.5\n",
    "    prob_distro = 'uniform'\n",
    "    reward_type = \"max\"\n",
    "    reward_parameters = {'universe_size': 20, 'arm_set_low': 0, 'arm_set_high': 1}\n",
    "    policy_lr=5e-3\n",
    "    value_lr=1e-4\n",
    "    train_iterations = 30\n",
    "    test_iterations = 30\n",
    "    out_folder = 'iterative'\n",
    "    time_limit = 100\n",
    "else:\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument('--n_arms',         '-N', help='num beneficiaries (arms)', type=int, default=2)\n",
    "    parser.add_argument('--volunteers_per_arm',         '-V', help='volunteers per arm', type=int, default=5)\n",
    "    parser.add_argument('--episode_len',    '-H', help='episode length', type=int, default=50)\n",
    "    parser.add_argument('--n_episodes',     '-T', help='num episodes', type=int, default=100)\n",
    "    parser.add_argument('--budget',         '-B', help='budget', type=int, default=3)\n",
    "    parser.add_argument('--n_epochs',       '-E', help='number of epochs (num_repeats)', type=int, default=1)\n",
    "    parser.add_argument('--discount',       '-d', help='discount factor', type=float, default=0.9)\n",
    "    parser.add_argument('--alpha',          '-a', help='alpha: for conf radius', type=float, default=3)\n",
    "    parser.add_argument('--lamb',          '-l', help='lambda for matching-engagement tradeoff', type=float, default=0.5)\n",
    "    parser.add_argument('--universe_size', help='For set cover, total num unvierse elems', type=int, default=10)\n",
    "    parser.add_argument('--arm_set_low', help='Least size of arm set, for set cover', type=float, default=3)\n",
    "    parser.add_argument('--arm_set_high', help='Largest size of arm set, for set cover', type=float, default=6)\n",
    "    parser.add_argument('--reward_type',          '-r', help='Which type of custom reward', type=str, default='set_cover')\n",
    "    parser.add_argument('--seed',           '-s', help='random seed', type=int, default=42)\n",
    "    parser.add_argument('--prob_distro',           '-p', help='which prob distro [uniform,uniform_small,uniform_large,normal]', type=str, default='uniform')\n",
    "    parser.add_argument('--time_per_run',      '-t', help='time per MCTS run', type=float, default=.01*1000)\n",
    "    parser.add_argument('--policy_lr', help='Learning Rate Policy', type=float, default=5e-3)\n",
    "    parser.add_argument('--value_lr', help='Learning Rate Value', type=float, default=1e-4)\n",
    "    parser.add_argument('--train_iterations', help='Number of MCTS train iterations', type=int, default=30)\n",
    "    parser.add_argument('--test_iterations', help='Number of MCTS test iterations', type=int, default=30)\n",
    "    parser.add_argument('--out_folder', help='Which folder to write results to', type=str, default='iterative')\n",
    "    parser.add_argument('--time_limit', help='Online time limit for computation', type=float, default=100)\n",
    "\n",
    "\n",
    "    parser.add_argument('--use_date', action='store_true')\n",
    "\n",
    "    args = parser.parse_args()\n",
    "\n",
    "    n_arms      = args.n_arms\n",
    "    volunteers_per_arm = args.volunteers_per_arm\n",
    "    budget      = args.budget\n",
    "    discount    = args.discount\n",
    "    alpha       = args.alpha \n",
    "    seed        = args.seed\n",
    "    n_episodes  = args.n_episodes\n",
    "    episode_len = args.episode_len\n",
    "    n_epochs    = args.n_epochs\n",
    "    lamb = args.lamb\n",
    "    save_with_date = args.use_date\n",
    "    TIME_PER_RUN = args.time_per_run\n",
    "    prob_distro = args.prob_distro\n",
    "    policy_lr = args.policy_lr \n",
    "    value_lr = args.value_lr \n",
    "    out_folder = args.out_folder\n",
    "    train_iterations = args.train_iterations \n",
    "    test_iterations = args.test_iterations \n",
    "    reward_type = args.reward_type\n",
    "    reward_parameters = {'universe_size': args.universe_size,\n",
    "                        'arm_set_low': args.arm_set_low, \n",
    "                        'arm_set_high': args.arm_set_high}\n",
    "    time_limit = args.time_limit \n",
    "\n",
    "save_name = secrets.token_hex(4)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_states = 2\n",
    "n_actions = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(seed)\n",
    "all_population_size = 100 \n",
    "max_transition_prob = 0.25\n",
    "all_transitions = create_random_transitions(all_population_size,max_transition_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def partition_volunteers(probs_by_num,num_by_section):\n",
    "    total = sum([len(probs_by_num[i]) for i in probs_by_num])\n",
    "    num_per_section = total//num_by_section\n",
    "\n",
    "    nums_by_partition = []\n",
    "    current_count = 0\n",
    "    current_partition = []\n",
    "\n",
    "    keys = sorted(probs_by_num.keys())\n",
    "\n",
    "    for i in keys:\n",
    "        if current_count >= num_per_section*(len(nums_by_partition)+1):\n",
    "            nums_by_partition.append(current_partition)\n",
    "            current_partition = []\n",
    "        \n",
    "        current_partition.append(i)\n",
    "        current_count += len(probs_by_num[i])\n",
    "    return nums_by_partition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "if prob_distro == \"food_rescue_top\":\n",
    "    all_population_size = 20 \n",
    "    probs_by_user = json.load(open(\"../../results/food_rescue/match_probs.json\",\"r\"))\n",
    "    donation_id_to_latlon, recipient_location_to_latlon, rescues_by_user, all_rescue_data, user_id_to_latlon = get_db_data()\n",
    "    probs_by_num = {}\n",
    "    for i in rescues_by_user:\n",
    "        if str(i) in probs_by_user and probs_by_user[str(i)] > 0 and len(rescues_by_user[i]) >= 100:\n",
    "            if len(rescues_by_user[i]) not in probs_by_num:\n",
    "                probs_by_num[len(rescues_by_user[i])] = []\n",
    "            probs_by_num[len(rescues_by_user[i])].append(probs_by_user[str(i)])\n",
    "\n",
    "    partitions = partition_volunteers(probs_by_num,all_population_size)\n",
    "    probs_by_partition = []\n",
    "\n",
    "    for i in range(len(partitions)):\n",
    "        temp_probs = []\n",
    "        for j in partitions[i]:\n",
    "            temp_probs += (probs_by_num[j])\n",
    "        probs_by_partition.append(temp_probs)\n",
    "\n",
    "    all_transitions = get_all_transitions_partition(all_population_size,partitions)\n",
    "\n",
    "    for i,partition in enumerate(partitions):\n",
    "        current_transitions = np.array(all_transitions[i])\n",
    "        partition_scale = np.array([len(probs_by_num[j]) for j in partition])\n",
    "        partition_scale = partition_scale/np.sum(partition_scale)\n",
    "        prod = current_transitions*partition_scale[:,np.newaxis,np.newaxis,np.newaxis]\n",
    "        new_transition = np.sum(prod,axis=0)\n",
    "        all_transitions[i] = new_transition\n",
    "    all_transitions = np.array(all_transitions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "if prob_distro == \"food_rescue\":\n",
    "    all_population_size = 100 \n",
    "\n",
    "    probs_by_user = json.load(open(\"../../results/food_rescue/match_probs.json\",\"r\"))\n",
    "    donation_id_to_latlon, recipient_location_to_latlon, rescues_by_user, all_rescue_data, user_id_to_latlon = get_db_data()\n",
    "    probs_by_num = {}\n",
    "    for i in rescues_by_user:\n",
    "        if str(i) in probs_by_user and probs_by_user[str(i)] > 0 and len(rescues_by_user[i]) >= 3:\n",
    "            if len(rescues_by_user[i]) not in probs_by_num:\n",
    "                probs_by_num[len(rescues_by_user[i])] = []\n",
    "            probs_by_num[len(rescues_by_user[i])].append(probs_by_user[str(i)])\n",
    "\n",
    "    partitions = partition_volunteers(probs_by_num,all_population_size)\n",
    "    probs_by_partition = []\n",
    "    all_transitions = get_all_transitions_partition(all_population_size,partitions)\n",
    "\n",
    "    for i in range(len(partitions)):\n",
    "        temp_probs = []\n",
    "        for j in partitions[i]:\n",
    "            temp_probs += (probs_by_num[j])\n",
    "        probs_by_partition.append(temp_probs)\n",
    "\n",
    "    for i,partition in enumerate(partitions):\n",
    "        current_transitions = np.array(all_transitions[i])\n",
    "        partition_scale = np.array([len(probs_by_num[j]) for j in partition])\n",
    "        partition_scale = partition_scale/np.sum(partition_scale)\n",
    "        prod = current_transitions*partition_scale[:,np.newaxis,np.newaxis,np.newaxis]\n",
    "        new_transition = np.sum(prod,axis=0)\n",
    "        all_transitions[i] = new_transition\n",
    "    all_transitions = np.array(all_transitions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "if prob_distro == \"high_prob\":\n",
    "    np.random.seed(seed)\n",
    "    all_population_size = 100 \n",
    "    max_transition_prob = 1.0\n",
    "    all_transitions = create_random_transitions(all_population_size,max_transition_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "if prob_distro == \"one_time\":\n",
    "    np.random.seed(seed)\n",
    "    all_population_size = 100 \n",
    "    max_transition_prob = 1.0\n",
    "    all_transitions = np.zeros((all_population_size,2,2,2))\n",
    "    all_transitions[:,:,1,0] = 1\n",
    "    all_transitions[:,1,0,1] = 1\n",
    "    all_transitions[:,0,0,0] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_environment(seed):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "\n",
    "    all_features = np.arange(all_population_size)\n",
    "    N = all_population_size*volunteers_per_arm\n",
    "    if reward_type == \"set_cover\":\n",
    "        if prob_distro == \"fixed\":\n",
    "            match_probabilities = []\n",
    "            set_sizes = [int(reward_parameters['arm_set_low']) for i in range(N)]\n",
    "            for i in range(N):\n",
    "                s = set() \n",
    "                while len(s) < set_sizes[i]:\n",
    "                    s.add(np.random.randint(0,reward_parameters['universe_size']))\n",
    "                match_probabilities.append(s)\n",
    "        else:\n",
    "            set_sizes = [np.random.randint(int(reward_parameters['arm_set_low']),int(reward_parameters['arm_set_high'])+1) for i in range(N)]\n",
    "            match_probabilities = [] \n",
    "            \n",
    "            for i in range(N):\n",
    "                temp_set = set() \n",
    "                \n",
    "                while len(temp_set) < set_sizes[i]:\n",
    "                    temp_set.add(np.random.randint(0,reward_parameters['universe_size']))\n",
    "                match_probabilities.append(temp_set)\n",
    "    elif prob_distro == \"food_rescue\" or prob_distro == \"food_rescue_top\":\n",
    "        match_probabilities = [np.random.choice(probs_by_partition[i//volunteers_per_arm]) for i in range(N)] \n",
    "    else:\n",
    "        match_probabilities = [np.random.uniform(reward_parameters['arm_set_low'],reward_parameters['arm_set_high']) for i in range(N)]\n",
    "\n",
    "    simulator = RMABSimulator(all_population_size, all_features, all_transitions,\n",
    "                n_arms, volunteers_per_arm, episode_len, n_epochs, n_episodes, budget, discount,number_states=n_states, reward_style='custom',match_probability_list=match_probabilities,TIME_PER_RUN=TIME_PER_RUN)\n",
    "    simulator.reward_type = reward_type \n",
    "    simulator.reward_parameters = reward_parameters \n",
    "    return simulator "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_multi_seed(seed_list,policy,is_mcts=False,per_epoch_function=None,train_iterations=0,test_iterations=0,test_length=20,avg_reward=0,num_samples=100):\n",
    "    memories = []\n",
    "    scores = {\n",
    "        'reward': [],\n",
    "        'time': [], \n",
    "        'match': [], \n",
    "        'active_rate': [],\n",
    "    }\n",
    "\n",
    "    for seed in seed_list:\n",
    "        simulator = create_environment(seed)\n",
    "        simulator.time_limit = time_limit\n",
    "        simulator.avg_reward = avg_reward\n",
    "        simulator.num_samples = num_samples\n",
    "        simulator.mcts_train_iterations = train_iterations\n",
    "        simulator.mcts_test_iterations = 400\n",
    "        simulator.policy_lr = policy_lr\n",
    "        simulator.value_lr = value_lr\n",
    "        simulator.mcts_depth = 2\n",
    "        simulator.shapley_iterations = 1000 \n",
    "\n",
    "        if prob_distro == \"one_time\":\n",
    "            N = n_arms*volunteers_per_arm\n",
    "            simulator.first_init_states = np.array([[[1 for i in range(N)] for i in range(n_episodes)]])\n",
    "            random.seed(seed)\n",
    "            shuffled_list = [reward_parameters['arm_set_high'] for i in range(2)] + [reward_parameters['arm_set_high'] for i in range(N-2)]\n",
    "            random.shuffle(shuffled_list)\n",
    "\n",
    "            simulator.match_probability_list[simulator.cohort_selection[0]] = shuffled_list\n",
    "\n",
    "        if is_mcts:\n",
    "            match, active_rate, memory = run_heterogenous_policy(simulator, n_episodes, n_epochs, discount,policy,seed,lamb=lamb,should_train=True,test_T=test_length,get_memory=True,per_epoch_function=per_epoch_function)\n",
    "        else:\n",
    "            match, active_rate = run_heterogenous_policy(simulator, n_episodes, n_epochs, discount,policy,seed,lamb=lamb,should_train=False,test_T=test_length,per_epoch_function=per_epoch_function)\n",
    "        time_whittle = simulator.time_taken\n",
    "        discounted_reward = get_discounted_reward(match,active_rate,discount,lamb)\n",
    "        scores['reward'].append(discounted_reward)\n",
    "        scores['time'].append(time_whittle)\n",
    "        scores['match'].append(np.mean(match))\n",
    "        scores['active_rate'].append(np.mean(active_rate))\n",
    "        if is_mcts:\n",
    "            memories.append(memory)\n",
    "\n",
    "    return scores, memories, simulator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = {}\n",
    "results['parameters'] = {'seed'      : seed,\n",
    "        'n_arms'    : n_arms,\n",
    "        'volunteers_per_arm': volunteers_per_arm, \n",
    "        'budget'    : budget,\n",
    "        'discount'  : discount, \n",
    "        'alpha'     : alpha, \n",
    "        'n_episodes': n_episodes, \n",
    "        'episode_len': episode_len, \n",
    "        'n_epochs'  : n_epochs, \n",
    "        'lamb': lamb,\n",
    "        'time_per_run': TIME_PER_RUN, \n",
    "        'prob_distro': prob_distro, \n",
    "        'policy_lr': policy_lr, \n",
    "        'value_lr': value_lr, \n",
    "        'reward_type': reward_type, \n",
    "        'universe_size': reward_parameters['universe_size'],\n",
    "        'arm_set_low': reward_parameters['arm_set_low'], \n",
    "        'arm_set_high': reward_parameters['arm_set_high'],\n",
    "        'time_limit': time_limit\n",
    "        } "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Index Policies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_list = [seed]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cohort [87 53 47  7]\n",
      "instance 0, ep 1\n",
      "instance 0, ep 2\n",
      "instance 0, ep 3\n",
      "instance 0, ep 4\n",
      "instance 0, ep 5\n",
      "instance 0, ep 6\n",
      "instance 0, ep 7\n",
      "instance 0, ep 8\n",
      "instance 0, ep 9\n",
      "instance 0, ep 10\n",
      "instance 0, ep 11\n",
      "instance 0, ep 12\n",
      "instance 0, ep 13\n",
      "instance 0, ep 14\n",
      "instance 0, ep 15\n",
      "instance 0, ep 16\n",
      "instance 0, ep 17\n",
      "instance 0, ep 18\n",
      "instance 0, ep 19\n",
      "instance 0, ep 20\n",
      "instance 0, ep 21\n",
      "instance 0, ep 22\n",
      "instance 0, ep 23\n",
      "instance 0, ep 24\n",
      "instance 0, ep 25\n",
      "instance 0, ep 26\n",
      "instance 0, ep 27\n",
      "instance 0, ep 28\n",
      "instance 0, ep 29\n",
      "instance 0, ep 30\n",
      "instance 0, ep 31\n",
      "instance 0, ep 32\n",
      "instance 0, ep 33\n",
      "instance 0, ep 34\n",
      "instance 0, ep 35\n",
      "instance 0, ep 36\n",
      "instance 0, ep 37\n",
      "instance 0, ep 38\n",
      "instance 0, ep 39\n",
      "instance 0, ep 40\n",
      "instance 0, ep 41\n",
      "instance 0, ep 42\n",
      "instance 0, ep 43\n",
      "instance 0, ep 44\n",
      "instance 0, ep 45\n",
      "instance 0, ep 46\n",
      "instance 0, ep 47\n",
      "instance 0, ep 48\n",
      "instance 0, ep 49\n",
      "instance 0, ep 50\n",
      "instance 0, ep 51\n",
      "instance 0, ep 52\n",
      "instance 0, ep 53\n",
      "instance 0, ep 54\n",
      "instance 0, ep 55\n",
      "instance 0, ep 56\n",
      "instance 0, ep 57\n",
      "instance 0, ep 58\n",
      "instance 0, ep 59\n",
      "instance 0, ep 60\n",
      "instance 0, ep 61\n",
      "instance 0, ep 62\n",
      "instance 0, ep 63\n",
      "instance 0, ep 64\n",
      "instance 0, ep 65\n",
      "instance 0, ep 66\n",
      "instance 0, ep 67\n",
      "instance 0, ep 68\n",
      "instance 0, ep 69\n",
      "instance 0, ep 70\n",
      "instance 0, ep 71\n",
      "instance 0, ep 72\n",
      "instance 0, ep 73\n",
      "instance 0, ep 74\n",
      "instance 0, ep 75\n",
      "instance 0, ep 76\n",
      "instance 0, ep 77\n",
      "instance 0, ep 78\n",
      "instance 0, ep 79\n",
      "instance 0, ep 80\n",
      "instance 0, ep 81\n",
      "instance 0, ep 82\n",
      "instance 0, ep 83\n",
      "instance 0, ep 84\n",
      "instance 0, ep 85\n",
      "instance 0, ep 86\n",
      "instance 0, ep 87\n",
      "instance 0, ep 88\n",
      "instance 0, ep 89\n",
      "instance 0, ep 90\n",
      "instance 0, ep 91\n",
      "instance 0, ep 92\n",
      "instance 0, ep 93\n",
      "instance 0, ep 94\n",
      "instance 0, ep 95\n",
      "instance 0, ep 96\n",
      "instance 0, ep 97\n",
      "instance 0, ep 98\n",
      "instance 0, ep 99\n",
      "Took 0.007283926010131836 time for inference and 0.4441714286804199 time for training\n",
      "cohort [35  4 66  7]\n",
      "instance 0, ep 1\n",
      "instance 0, ep 2\n",
      "instance 0, ep 3\n",
      "instance 0, ep 4\n",
      "instance 0, ep 5\n",
      "instance 0, ep 6\n",
      "instance 0, ep 7\n",
      "instance 0, ep 8\n",
      "instance 0, ep 9\n",
      "instance 0, ep 10\n",
      "instance 0, ep 11\n",
      "instance 0, ep 12\n",
      "instance 0, ep 13\n",
      "instance 0, ep 14\n",
      "instance 0, ep 15\n",
      "instance 0, ep 16\n",
      "instance 0, ep 17\n",
      "instance 0, ep 18\n",
      "instance 0, ep 19\n",
      "instance 0, ep 20\n",
      "instance 0, ep 21\n",
      "instance 0, ep 22\n",
      "instance 0, ep 23\n",
      "instance 0, ep 24\n",
      "instance 0, ep 25\n",
      "instance 0, ep 26\n",
      "instance 0, ep 27\n",
      "instance 0, ep 28\n",
      "instance 0, ep 29\n",
      "instance 0, ep 30\n",
      "instance 0, ep 31\n",
      "instance 0, ep 32\n",
      "instance 0, ep 33\n",
      "instance 0, ep 34\n",
      "instance 0, ep 35\n",
      "instance 0, ep 36\n",
      "instance 0, ep 37\n",
      "instance 0, ep 38\n",
      "instance 0, ep 39\n",
      "instance 0, ep 40\n",
      "instance 0, ep 41\n",
      "instance 0, ep 42\n",
      "instance 0, ep 43\n",
      "instance 0, ep 44\n",
      "instance 0, ep 45\n",
      "instance 0, ep 46\n",
      "instance 0, ep 47\n",
      "instance 0, ep 48\n",
      "instance 0, ep 49\n",
      "instance 0, ep 50\n",
      "instance 0, ep 51\n",
      "instance 0, ep 52\n",
      "instance 0, ep 53\n",
      "instance 0, ep 54\n",
      "instance 0, ep 55\n",
      "instance 0, ep 56\n",
      "instance 0, ep 57\n",
      "instance 0, ep 58\n",
      "instance 0, ep 59\n",
      "instance 0, ep 60\n",
      "instance 0, ep 61\n",
      "instance 0, ep 62\n",
      "instance 0, ep 63\n",
      "instance 0, ep 64\n",
      "instance 0, ep 65\n",
      "instance 0, ep 66\n",
      "instance 0, ep 67\n",
      "instance 0, ep 68\n",
      "instance 0, ep 69\n",
      "instance 0, ep 70\n",
      "instance 0, ep 71\n",
      "instance 0, ep 72\n",
      "instance 0, ep 73\n",
      "instance 0, ep 74\n",
      "instance 0, ep 75\n",
      "instance 0, ep 76\n",
      "instance 0, ep 77\n",
      "instance 0, ep 78\n",
      "instance 0, ep 79\n",
      "instance 0, ep 80\n",
      "instance 0, ep 81\n",
      "instance 0, ep 82\n",
      "instance 0, ep 83\n",
      "instance 0, ep 84\n",
      "instance 0, ep 85\n",
      "instance 0, ep 86\n",
      "instance 0, ep 87\n",
      "instance 0, ep 88\n",
      "instance 0, ep 89\n",
      "instance 0, ep 90\n",
      "instance 0, ep 91\n",
      "instance 0, ep 92\n",
      "instance 0, ep 93\n",
      "instance 0, ep 94\n",
      "instance 0, ep 95\n",
      "instance 0, ep 96\n",
      "instance 0, ep 97\n",
      "instance 0, ep 98\n",
      "instance 0, ep 99\n",
      "Took 0.007509946823120117 time for inference and 0.44161248207092285 time for training\n",
      "cohort [55 38 69 53]\n",
      "instance 0, ep 1\n",
      "instance 0, ep 2\n",
      "instance 0, ep 3\n",
      "instance 0, ep 4\n",
      "instance 0, ep 5\n",
      "instance 0, ep 6\n",
      "instance 0, ep 7\n",
      "instance 0, ep 8\n",
      "instance 0, ep 9\n",
      "instance 0, ep 10\n",
      "instance 0, ep 11\n",
      "instance 0, ep 12\n",
      "instance 0, ep 13\n",
      "instance 0, ep 14\n",
      "instance 0, ep 15\n",
      "instance 0, ep 16\n",
      "instance 0, ep 17\n",
      "instance 0, ep 18\n",
      "instance 0, ep 19\n",
      "instance 0, ep 20\n",
      "instance 0, ep 21\n",
      "instance 0, ep 22\n",
      "instance 0, ep 23\n",
      "instance 0, ep 24\n",
      "instance 0, ep 25\n",
      "instance 0, ep 26\n",
      "instance 0, ep 27\n",
      "instance 0, ep 28\n",
      "instance 0, ep 29\n",
      "instance 0, ep 30\n",
      "instance 0, ep 31\n",
      "instance 0, ep 32\n",
      "instance 0, ep 33\n",
      "instance 0, ep 34\n",
      "instance 0, ep 35\n",
      "instance 0, ep 36\n",
      "instance 0, ep 37\n",
      "instance 0, ep 38\n",
      "instance 0, ep 39\n",
      "instance 0, ep 40\n",
      "instance 0, ep 41\n",
      "instance 0, ep 42\n",
      "instance 0, ep 43\n",
      "instance 0, ep 44\n",
      "instance 0, ep 45\n",
      "instance 0, ep 46\n",
      "instance 0, ep 47\n",
      "instance 0, ep 48\n",
      "instance 0, ep 49\n",
      "instance 0, ep 50\n",
      "instance 0, ep 51\n",
      "instance 0, ep 52\n",
      "instance 0, ep 53\n",
      "instance 0, ep 54\n",
      "instance 0, ep 55\n",
      "instance 0, ep 56\n",
      "instance 0, ep 57\n",
      "instance 0, ep 58\n",
      "instance 0, ep 59\n",
      "instance 0, ep 60\n",
      "instance 0, ep 61\n",
      "instance 0, ep 62\n",
      "instance 0, ep 63\n",
      "instance 0, ep 64\n",
      "instance 0, ep 65\n",
      "instance 0, ep 66\n",
      "instance 0, ep 67\n",
      "instance 0, ep 68\n",
      "instance 0, ep 69\n",
      "instance 0, ep 70\n",
      "instance 0, ep 71\n",
      "instance 0, ep 72\n",
      "instance 0, ep 73\n",
      "instance 0, ep 74\n",
      "instance 0, ep 75\n",
      "instance 0, ep 76\n",
      "instance 0, ep 77\n",
      "instance 0, ep 78\n",
      "instance 0, ep 79\n",
      "instance 0, ep 80\n",
      "instance 0, ep 81\n",
      "instance 0, ep 82\n",
      "instance 0, ep 83\n",
      "instance 0, ep 84\n",
      "instance 0, ep 85\n",
      "instance 0, ep 86\n",
      "instance 0, ep 87\n",
      "instance 0, ep 88\n",
      "instance 0, ep 89\n",
      "instance 0, ep 90\n",
      "instance 0, ep 91\n",
      "instance 0, ep 92\n",
      "instance 0, ep 93\n",
      "instance 0, ep 94\n",
      "instance 0, ep 95\n",
      "instance 0, ep 96\n",
      "instance 0, ep 97\n",
      "instance 0, ep 98\n",
      "instance 0, ep 99\n",
      "Took 0.007329702377319336 time for inference and 0.4421091079711914 time for training\n",
      "cohort [84 53 80 94]\n",
      "instance 0, ep 1\n",
      "instance 0, ep 2\n",
      "instance 0, ep 3\n",
      "instance 0, ep 4\n",
      "instance 0, ep 5\n",
      "instance 0, ep 6\n",
      "instance 0, ep 7\n",
      "instance 0, ep 8\n",
      "instance 0, ep 9\n",
      "instance 0, ep 10\n",
      "instance 0, ep 11\n",
      "instance 0, ep 12\n",
      "instance 0, ep 13\n",
      "instance 0, ep 14\n",
      "instance 0, ep 15\n",
      "instance 0, ep 16\n",
      "instance 0, ep 17\n",
      "instance 0, ep 18\n",
      "instance 0, ep 19\n",
      "instance 0, ep 20\n",
      "instance 0, ep 21\n",
      "instance 0, ep 22\n",
      "instance 0, ep 23\n",
      "instance 0, ep 24\n",
      "instance 0, ep 25\n",
      "instance 0, ep 26\n",
      "instance 0, ep 27\n",
      "instance 0, ep 28\n",
      "instance 0, ep 29\n",
      "instance 0, ep 30\n",
      "instance 0, ep 31\n",
      "instance 0, ep 32\n",
      "instance 0, ep 33\n",
      "instance 0, ep 34\n",
      "instance 0, ep 35\n",
      "instance 0, ep 36\n",
      "instance 0, ep 37\n",
      "instance 0, ep 38\n",
      "instance 0, ep 39\n",
      "instance 0, ep 40\n",
      "instance 0, ep 41\n",
      "instance 0, ep 42\n",
      "instance 0, ep 43\n",
      "instance 0, ep 44\n",
      "instance 0, ep 45\n",
      "instance 0, ep 46\n",
      "instance 0, ep 47\n",
      "instance 0, ep 48\n",
      "instance 0, ep 49\n",
      "instance 0, ep 50\n",
      "instance 0, ep 51\n",
      "instance 0, ep 52\n",
      "instance 0, ep 53\n",
      "instance 0, ep 54\n",
      "instance 0, ep 55\n",
      "instance 0, ep 56\n",
      "instance 0, ep 57\n",
      "instance 0, ep 58\n",
      "instance 0, ep 59\n",
      "instance 0, ep 60\n",
      "instance 0, ep 61\n",
      "instance 0, ep 62\n",
      "instance 0, ep 63\n",
      "instance 0, ep 64\n",
      "instance 0, ep 65\n",
      "instance 0, ep 66\n",
      "instance 0, ep 67\n",
      "instance 0, ep 68\n",
      "instance 0, ep 69\n",
      "instance 0, ep 70\n",
      "instance 0, ep 71\n",
      "instance 0, ep 72\n",
      "instance 0, ep 73\n",
      "instance 0, ep 74\n",
      "instance 0, ep 75\n",
      "instance 0, ep 76\n",
      "instance 0, ep 77\n",
      "instance 0, ep 78\n",
      "instance 0, ep 79\n",
      "instance 0, ep 80\n",
      "instance 0, ep 81\n",
      "instance 0, ep 82\n",
      "instance 0, ep 83\n",
      "instance 0, ep 84\n",
      "instance 0, ep 85\n",
      "instance 0, ep 86\n",
      "instance 0, ep 87\n",
      "instance 0, ep 88\n",
      "instance 0, ep 89\n",
      "instance 0, ep 90\n",
      "instance 0, ep 91\n",
      "instance 0, ep 92\n",
      "instance 0, ep 93\n",
      "instance 0, ep 94\n",
      "instance 0, ep 95\n",
      "instance 0, ep 96\n",
      "instance 0, ep 97\n",
      "instance 0, ep 98\n",
      "instance 0, ep 99\n",
      "Took 0.00751805305480957 time for inference and 0.4407181739807129 time for training\n",
      "cohort [40  4  0  5]\n",
      "instance 0, ep 1\n",
      "instance 0, ep 2\n",
      "instance 0, ep 3\n",
      "instance 0, ep 4\n",
      "instance 0, ep 5\n",
      "instance 0, ep 6\n",
      "instance 0, ep 7\n",
      "instance 0, ep 8\n",
      "instance 0, ep 9\n",
      "instance 0, ep 10\n",
      "instance 0, ep 11\n",
      "instance 0, ep 12\n",
      "instance 0, ep 13\n",
      "instance 0, ep 14\n",
      "instance 0, ep 15\n",
      "instance 0, ep 16\n",
      "instance 0, ep 17\n",
      "instance 0, ep 18\n",
      "instance 0, ep 19\n",
      "instance 0, ep 20\n",
      "instance 0, ep 21\n",
      "instance 0, ep 22\n",
      "instance 0, ep 23\n",
      "instance 0, ep 24\n",
      "instance 0, ep 25\n",
      "instance 0, ep 26\n",
      "instance 0, ep 27\n",
      "instance 0, ep 28\n",
      "instance 0, ep 29\n",
      "instance 0, ep 30\n",
      "instance 0, ep 31\n",
      "instance 0, ep 32\n",
      "instance 0, ep 33\n",
      "instance 0, ep 34\n",
      "instance 0, ep 35\n",
      "instance 0, ep 36\n",
      "instance 0, ep 37\n",
      "instance 0, ep 38\n",
      "instance 0, ep 39\n",
      "instance 0, ep 40\n",
      "instance 0, ep 41\n",
      "instance 0, ep 42\n",
      "instance 0, ep 43\n",
      "instance 0, ep 44\n",
      "instance 0, ep 45\n",
      "instance 0, ep 46\n",
      "instance 0, ep 47\n",
      "instance 0, ep 48\n",
      "instance 0, ep 49\n",
      "instance 0, ep 50\n",
      "instance 0, ep 51\n",
      "instance 0, ep 52\n",
      "instance 0, ep 53\n",
      "instance 0, ep 54\n",
      "instance 0, ep 55\n",
      "instance 0, ep 56\n",
      "instance 0, ep 57\n",
      "instance 0, ep 58\n",
      "instance 0, ep 59\n",
      "instance 0, ep 60\n",
      "instance 0, ep 61\n",
      "instance 0, ep 62\n",
      "instance 0, ep 63\n",
      "instance 0, ep 64\n",
      "instance 0, ep 65\n",
      "instance 0, ep 66\n",
      "instance 0, ep 67\n",
      "instance 0, ep 68\n",
      "instance 0, ep 69\n",
      "instance 0, ep 70\n",
      "instance 0, ep 71\n",
      "instance 0, ep 72\n",
      "instance 0, ep 73\n",
      "instance 0, ep 74\n",
      "instance 0, ep 75\n",
      "instance 0, ep 76\n",
      "instance 0, ep 77\n",
      "instance 0, ep 78\n",
      "instance 0, ep 79\n",
      "instance 0, ep 80\n",
      "instance 0, ep 81\n",
      "instance 0, ep 82\n",
      "instance 0, ep 83\n",
      "instance 0, ep 84\n",
      "instance 0, ep 85\n",
      "instance 0, ep 86\n",
      "instance 0, ep 87\n",
      "instance 0, ep 88\n",
      "instance 0, ep 89\n",
      "instance 0, ep 90\n",
      "instance 0, ep 91\n",
      "instance 0, ep 92\n",
      "instance 0, ep 93\n",
      "instance 0, ep 94\n",
      "instance 0, ep 95\n",
      "instance 0, ep 96\n",
      "instance 0, ep 97\n",
      "instance 0, ep 98\n",
      "instance 0, ep 99\n",
      "Took 0.007315397262573242 time for inference and 0.44071435928344727 time for training\n",
      "cohort [71 36 43 49]\n",
      "instance 0, ep 1\n",
      "instance 0, ep 2\n",
      "instance 0, ep 3\n",
      "instance 0, ep 4\n",
      "instance 0, ep 5\n",
      "instance 0, ep 6\n",
      "instance 0, ep 7\n",
      "instance 0, ep 8\n",
      "instance 0, ep 9\n",
      "instance 0, ep 10\n",
      "instance 0, ep 11\n",
      "instance 0, ep 12\n",
      "instance 0, ep 13\n",
      "instance 0, ep 14\n",
      "instance 0, ep 15\n",
      "instance 0, ep 16\n",
      "instance 0, ep 17\n",
      "instance 0, ep 18\n",
      "instance 0, ep 19\n",
      "instance 0, ep 20\n",
      "instance 0, ep 21\n",
      "instance 0, ep 22\n",
      "instance 0, ep 23\n",
      "instance 0, ep 24\n",
      "instance 0, ep 25\n",
      "instance 0, ep 26\n",
      "instance 0, ep 27\n",
      "instance 0, ep 28\n",
      "instance 0, ep 29\n",
      "instance 0, ep 30\n",
      "instance 0, ep 31\n",
      "instance 0, ep 32\n",
      "instance 0, ep 33\n",
      "instance 0, ep 34\n",
      "instance 0, ep 35\n",
      "instance 0, ep 36\n",
      "instance 0, ep 37\n",
      "instance 0, ep 38\n",
      "instance 0, ep 39\n",
      "instance 0, ep 40\n",
      "instance 0, ep 41\n",
      "instance 0, ep 42\n",
      "instance 0, ep 43\n",
      "instance 0, ep 44\n",
      "instance 0, ep 45\n",
      "instance 0, ep 46\n",
      "instance 0, ep 47\n",
      "instance 0, ep 48\n",
      "instance 0, ep 49\n",
      "instance 0, ep 50\n",
      "instance 0, ep 51\n",
      "instance 0, ep 52\n",
      "instance 0, ep 53\n",
      "instance 0, ep 54\n",
      "instance 0, ep 55\n",
      "instance 0, ep 56\n",
      "instance 0, ep 57\n",
      "instance 0, ep 58\n",
      "instance 0, ep 59\n",
      "instance 0, ep 60\n",
      "instance 0, ep 61\n",
      "instance 0, ep 62\n",
      "instance 0, ep 63\n",
      "instance 0, ep 64\n",
      "instance 0, ep 65\n",
      "instance 0, ep 66\n",
      "instance 0, ep 67\n",
      "instance 0, ep 68\n",
      "instance 0, ep 69\n",
      "instance 0, ep 70\n",
      "instance 0, ep 71\n",
      "instance 0, ep 72\n",
      "instance 0, ep 73\n",
      "instance 0, ep 74\n",
      "instance 0, ep 75\n",
      "instance 0, ep 76\n",
      "instance 0, ep 77\n",
      "instance 0, ep 78\n",
      "instance 0, ep 79\n",
      "instance 0, ep 80\n",
      "instance 0, ep 81\n",
      "instance 0, ep 82\n",
      "instance 0, ep 83\n",
      "instance 0, ep 84\n",
      "instance 0, ep 85\n",
      "instance 0, ep 86\n",
      "instance 0, ep 87\n",
      "instance 0, ep 88\n",
      "instance 0, ep 89\n",
      "instance 0, ep 90\n",
      "instance 0, ep 91\n",
      "instance 0, ep 92\n",
      "instance 0, ep 93\n",
      "instance 0, ep 94\n",
      "instance 0, ep 95\n",
      "instance 0, ep 96\n",
      "instance 0, ep 97\n",
      "instance 0, ep 98\n",
      "instance 0, ep 99\n",
      "Took 0.007312774658203125 time for inference and 0.4391806125640869 time for training\n",
      "6.308520011287141\n"
     ]
    }
   ],
   "source": [
    "policy = whittle_policy\n",
    "name = \"linear_whittle\"\n",
    "\n",
    "rewards, memory, simulator = run_multi_seed(seed_list,policy,test_length=episode_len)\n",
    "results['{}_reward'.format(name)] = rewards['reward']\n",
    "results['{}_match'.format(name)] =  rewards['match'] \n",
    "results['{}_active'.format(name)] = rewards['active_rate']\n",
    "results['{}_time'.format(name)] =  rewards['time']\n",
    "print(np.mean(rewards['reward']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cohort [87 53 47  7]\n",
      "instance 0, ep 1\n",
      "instance 0, ep 2\n",
      "instance 0, ep 3\n",
      "instance 0, ep 4\n",
      "instance 0, ep 5\n",
      "instance 0, ep 6\n",
      "instance 0, ep 7\n",
      "instance 0, ep 8\n",
      "instance 0, ep 9\n",
      "instance 0, ep 10\n",
      "instance 0, ep 11\n",
      "instance 0, ep 12\n",
      "instance 0, ep 13\n",
      "instance 0, ep 14\n",
      "instance 0, ep 15\n",
      "instance 0, ep 16\n",
      "instance 0, ep 17\n",
      "instance 0, ep 18\n",
      "instance 0, ep 19\n",
      "instance 0, ep 20\n",
      "instance 0, ep 21\n",
      "instance 0, ep 22\n",
      "instance 0, ep 23\n",
      "instance 0, ep 24\n",
      "instance 0, ep 25\n",
      "instance 0, ep 26\n",
      "instance 0, ep 27\n",
      "instance 0, ep 28\n",
      "instance 0, ep 29\n",
      "instance 0, ep 30\n",
      "instance 0, ep 31\n",
      "instance 0, ep 32\n",
      "instance 0, ep 33\n",
      "instance 0, ep 34\n",
      "instance 0, ep 35\n",
      "instance 0, ep 36\n",
      "instance 0, ep 37\n",
      "instance 0, ep 38\n",
      "instance 0, ep 39\n",
      "instance 0, ep 40\n",
      "instance 0, ep 41\n",
      "instance 0, ep 42\n",
      "instance 0, ep 43\n",
      "instance 0, ep 44\n",
      "instance 0, ep 45\n",
      "instance 0, ep 46\n",
      "instance 0, ep 47\n",
      "instance 0, ep 48\n",
      "instance 0, ep 49\n",
      "instance 0, ep 50\n",
      "instance 0, ep 51\n",
      "instance 0, ep 52\n",
      "instance 0, ep 53\n",
      "instance 0, ep 54\n",
      "instance 0, ep 55\n",
      "instance 0, ep 56\n",
      "instance 0, ep 57\n",
      "instance 0, ep 58\n",
      "instance 0, ep 59\n",
      "instance 0, ep 60\n",
      "instance 0, ep 61\n",
      "instance 0, ep 62\n",
      "instance 0, ep 63\n",
      "instance 0, ep 64\n",
      "instance 0, ep 65\n",
      "instance 0, ep 66\n",
      "instance 0, ep 67\n",
      "instance 0, ep 68\n",
      "instance 0, ep 69\n",
      "instance 0, ep 70\n",
      "instance 0, ep 71\n",
      "instance 0, ep 72\n",
      "instance 0, ep 73\n",
      "instance 0, ep 74\n",
      "instance 0, ep 75\n",
      "instance 0, ep 76\n",
      "instance 0, ep 77\n",
      "instance 0, ep 78\n",
      "instance 0, ep 79\n",
      "instance 0, ep 80\n",
      "instance 0, ep 81\n",
      "instance 0, ep 82\n",
      "instance 0, ep 83\n",
      "instance 0, ep 84\n",
      "instance 0, ep 85\n",
      "instance 0, ep 86\n",
      "instance 0, ep 87\n",
      "instance 0, ep 88\n",
      "instance 0, ep 89\n",
      "instance 0, ep 90\n",
      "instance 0, ep 91\n",
      "instance 0, ep 92\n",
      "instance 0, ep 93\n",
      "instance 0, ep 94\n",
      "instance 0, ep 95\n",
      "instance 0, ep 96\n",
      "instance 0, ep 97\n",
      "instance 0, ep 98\n",
      "instance 0, ep 99\n",
      "Took 4.254887580871582 time for inference and 0.5626375675201416 time for training\n",
      "cohort [35  4 66  7]\n",
      "instance 0, ep 1\n",
      "instance 0, ep 2\n",
      "instance 0, ep 3\n",
      "instance 0, ep 4\n",
      "instance 0, ep 5\n",
      "instance 0, ep 6\n",
      "instance 0, ep 7\n",
      "instance 0, ep 8\n",
      "instance 0, ep 9\n",
      "instance 0, ep 10\n",
      "instance 0, ep 11\n",
      "instance 0, ep 12\n",
      "instance 0, ep 13\n",
      "instance 0, ep 14\n",
      "instance 0, ep 15\n",
      "instance 0, ep 16\n",
      "instance 0, ep 17\n",
      "instance 0, ep 18\n",
      "instance 0, ep 19\n",
      "instance 0, ep 20\n",
      "instance 0, ep 21\n",
      "instance 0, ep 22\n",
      "instance 0, ep 23\n",
      "instance 0, ep 24\n",
      "instance 0, ep 25\n",
      "instance 0, ep 26\n",
      "instance 0, ep 27\n",
      "instance 0, ep 28\n",
      "instance 0, ep 29\n",
      "instance 0, ep 30\n",
      "instance 0, ep 31\n",
      "instance 0, ep 32\n",
      "instance 0, ep 33\n",
      "instance 0, ep 34\n",
      "instance 0, ep 35\n",
      "instance 0, ep 36\n",
      "instance 0, ep 37\n",
      "instance 0, ep 38\n",
      "instance 0, ep 39\n",
      "instance 0, ep 40\n",
      "instance 0, ep 41\n",
      "instance 0, ep 42\n",
      "instance 0, ep 43\n",
      "instance 0, ep 44\n",
      "instance 0, ep 45\n",
      "instance 0, ep 46\n",
      "instance 0, ep 47\n",
      "instance 0, ep 48\n",
      "instance 0, ep 49\n",
      "instance 0, ep 50\n",
      "instance 0, ep 51\n",
      "instance 0, ep 52\n",
      "instance 0, ep 53\n",
      "instance 0, ep 54\n",
      "instance 0, ep 55\n",
      "instance 0, ep 56\n",
      "instance 0, ep 57\n",
      "instance 0, ep 58\n",
      "instance 0, ep 59\n",
      "instance 0, ep 60\n",
      "instance 0, ep 61\n",
      "instance 0, ep 62\n",
      "instance 0, ep 63\n",
      "instance 0, ep 64\n",
      "instance 0, ep 65\n",
      "instance 0, ep 66\n",
      "instance 0, ep 67\n",
      "instance 0, ep 68\n",
      "instance 0, ep 69\n",
      "instance 0, ep 70\n",
      "instance 0, ep 71\n",
      "instance 0, ep 72\n",
      "instance 0, ep 73\n",
      "instance 0, ep 74\n",
      "instance 0, ep 75\n",
      "instance 0, ep 76\n",
      "instance 0, ep 77\n",
      "instance 0, ep 78\n",
      "instance 0, ep 79\n",
      "instance 0, ep 80\n",
      "instance 0, ep 81\n",
      "instance 0, ep 82\n",
      "instance 0, ep 83\n",
      "instance 0, ep 84\n",
      "instance 0, ep 85\n",
      "instance 0, ep 86\n",
      "instance 0, ep 87\n",
      "instance 0, ep 88\n",
      "instance 0, ep 89\n",
      "instance 0, ep 90\n",
      "instance 0, ep 91\n",
      "instance 0, ep 92\n",
      "instance 0, ep 93\n",
      "instance 0, ep 94\n",
      "instance 0, ep 95\n",
      "instance 0, ep 96\n",
      "instance 0, ep 97\n",
      "instance 0, ep 98\n",
      "instance 0, ep 99\n",
      "Took 4.214541673660278 time for inference and 0.558903694152832 time for training\n",
      "cohort [55 38 69 53]\n",
      "instance 0, ep 1\n",
      "instance 0, ep 2\n",
      "instance 0, ep 3\n",
      "instance 0, ep 4\n",
      "instance 0, ep 5\n",
      "instance 0, ep 6\n",
      "instance 0, ep 7\n",
      "instance 0, ep 8\n",
      "instance 0, ep 9\n",
      "instance 0, ep 10\n",
      "instance 0, ep 11\n",
      "instance 0, ep 12\n",
      "instance 0, ep 13\n",
      "instance 0, ep 14\n",
      "instance 0, ep 15\n",
      "instance 0, ep 16\n",
      "instance 0, ep 17\n",
      "instance 0, ep 18\n",
      "instance 0, ep 19\n",
      "instance 0, ep 20\n",
      "instance 0, ep 21\n",
      "instance 0, ep 22\n",
      "instance 0, ep 23\n",
      "instance 0, ep 24\n",
      "instance 0, ep 25\n",
      "instance 0, ep 26\n",
      "instance 0, ep 27\n",
      "instance 0, ep 28\n",
      "instance 0, ep 29\n",
      "instance 0, ep 30\n",
      "instance 0, ep 31\n",
      "instance 0, ep 32\n",
      "instance 0, ep 33\n",
      "instance 0, ep 34\n",
      "instance 0, ep 35\n",
      "instance 0, ep 36\n",
      "instance 0, ep 37\n",
      "instance 0, ep 38\n",
      "instance 0, ep 39\n",
      "instance 0, ep 40\n",
      "instance 0, ep 41\n",
      "instance 0, ep 42\n",
      "instance 0, ep 43\n",
      "instance 0, ep 44\n",
      "instance 0, ep 45\n",
      "instance 0, ep 46\n",
      "instance 0, ep 47\n",
      "instance 0, ep 48\n",
      "instance 0, ep 49\n",
      "instance 0, ep 50\n",
      "instance 0, ep 51\n",
      "instance 0, ep 52\n",
      "instance 0, ep 53\n",
      "instance 0, ep 54\n",
      "instance 0, ep 55\n",
      "instance 0, ep 56\n",
      "instance 0, ep 57\n",
      "instance 0, ep 58\n",
      "instance 0, ep 59\n",
      "instance 0, ep 60\n",
      "instance 0, ep 61\n",
      "instance 0, ep 62\n",
      "instance 0, ep 63\n",
      "instance 0, ep 64\n",
      "instance 0, ep 65\n",
      "instance 0, ep 66\n",
      "instance 0, ep 67\n",
      "instance 0, ep 68\n",
      "instance 0, ep 69\n",
      "instance 0, ep 70\n",
      "instance 0, ep 71\n",
      "instance 0, ep 72\n",
      "instance 0, ep 73\n",
      "instance 0, ep 74\n",
      "instance 0, ep 75\n",
      "instance 0, ep 76\n",
      "instance 0, ep 77\n",
      "instance 0, ep 78\n",
      "instance 0, ep 79\n",
      "instance 0, ep 80\n",
      "instance 0, ep 81\n",
      "instance 0, ep 82\n",
      "instance 0, ep 83\n",
      "instance 0, ep 84\n",
      "instance 0, ep 85\n",
      "instance 0, ep 86\n",
      "instance 0, ep 87\n",
      "instance 0, ep 88\n",
      "instance 0, ep 89\n",
      "instance 0, ep 90\n",
      "instance 0, ep 91\n",
      "instance 0, ep 92\n",
      "instance 0, ep 93\n",
      "instance 0, ep 94\n",
      "instance 0, ep 95\n",
      "instance 0, ep 96\n",
      "instance 0, ep 97\n",
      "instance 0, ep 98\n",
      "instance 0, ep 99\n",
      "Took 4.199156284332275 time for inference and 0.5580348968505859 time for training\n",
      "cohort [84 53 80 94]\n",
      "instance 0, ep 1\n",
      "instance 0, ep 2\n",
      "instance 0, ep 3\n",
      "instance 0, ep 4\n",
      "instance 0, ep 5\n",
      "instance 0, ep 6\n",
      "instance 0, ep 7\n",
      "instance 0, ep 8\n",
      "instance 0, ep 9\n",
      "instance 0, ep 10\n",
      "instance 0, ep 11\n",
      "instance 0, ep 12\n",
      "instance 0, ep 13\n",
      "instance 0, ep 14\n",
      "instance 0, ep 15\n",
      "instance 0, ep 16\n",
      "instance 0, ep 17\n",
      "instance 0, ep 18\n",
      "instance 0, ep 19\n",
      "instance 0, ep 20\n",
      "instance 0, ep 21\n",
      "instance 0, ep 22\n",
      "instance 0, ep 23\n",
      "instance 0, ep 24\n",
      "instance 0, ep 25\n",
      "instance 0, ep 26\n",
      "instance 0, ep 27\n",
      "instance 0, ep 28\n",
      "instance 0, ep 29\n",
      "instance 0, ep 30\n",
      "instance 0, ep 31\n",
      "instance 0, ep 32\n",
      "instance 0, ep 33\n",
      "instance 0, ep 34\n",
      "instance 0, ep 35\n",
      "instance 0, ep 36\n",
      "instance 0, ep 37\n",
      "instance 0, ep 38\n",
      "instance 0, ep 39\n",
      "instance 0, ep 40\n",
      "instance 0, ep 41\n",
      "instance 0, ep 42\n",
      "instance 0, ep 43\n",
      "instance 0, ep 44\n",
      "instance 0, ep 45\n",
      "instance 0, ep 46\n",
      "instance 0, ep 47\n",
      "instance 0, ep 48\n",
      "instance 0, ep 49\n",
      "instance 0, ep 50\n",
      "instance 0, ep 51\n",
      "instance 0, ep 52\n",
      "instance 0, ep 53\n",
      "instance 0, ep 54\n",
      "instance 0, ep 55\n",
      "instance 0, ep 56\n",
      "instance 0, ep 57\n",
      "instance 0, ep 58\n",
      "instance 0, ep 59\n",
      "instance 0, ep 60\n",
      "instance 0, ep 61\n",
      "instance 0, ep 62\n",
      "instance 0, ep 63\n",
      "instance 0, ep 64\n",
      "instance 0, ep 65\n",
      "instance 0, ep 66\n",
      "instance 0, ep 67\n",
      "instance 0, ep 68\n",
      "instance 0, ep 69\n",
      "instance 0, ep 70\n",
      "instance 0, ep 71\n",
      "instance 0, ep 72\n",
      "instance 0, ep 73\n",
      "instance 0, ep 74\n",
      "instance 0, ep 75\n",
      "instance 0, ep 76\n",
      "instance 0, ep 77\n",
      "instance 0, ep 78\n",
      "instance 0, ep 79\n",
      "instance 0, ep 80\n",
      "instance 0, ep 81\n",
      "instance 0, ep 82\n",
      "instance 0, ep 83\n",
      "instance 0, ep 84\n",
      "instance 0, ep 85\n",
      "instance 0, ep 86\n",
      "instance 0, ep 87\n",
      "instance 0, ep 88\n",
      "instance 0, ep 89\n",
      "instance 0, ep 90\n",
      "instance 0, ep 91\n",
      "instance 0, ep 92\n",
      "instance 0, ep 93\n",
      "instance 0, ep 94\n",
      "instance 0, ep 95\n",
      "instance 0, ep 96\n",
      "instance 0, ep 97\n",
      "instance 0, ep 98\n",
      "instance 0, ep 99\n",
      "Took 4.225188493728638 time for inference and 0.5542471408843994 time for training\n",
      "cohort [40  4  0  5]\n",
      "instance 0, ep 1\n",
      "instance 0, ep 2\n",
      "instance 0, ep 3\n",
      "instance 0, ep 4\n",
      "instance 0, ep 5\n",
      "instance 0, ep 6\n",
      "instance 0, ep 7\n",
      "instance 0, ep 8\n",
      "instance 0, ep 9\n",
      "instance 0, ep 10\n",
      "instance 0, ep 11\n",
      "instance 0, ep 12\n",
      "instance 0, ep 13\n",
      "instance 0, ep 14\n",
      "instance 0, ep 15\n",
      "instance 0, ep 16\n",
      "instance 0, ep 17\n",
      "instance 0, ep 18\n",
      "instance 0, ep 19\n",
      "instance 0, ep 20\n",
      "instance 0, ep 21\n",
      "instance 0, ep 22\n",
      "instance 0, ep 23\n",
      "instance 0, ep 24\n",
      "instance 0, ep 25\n",
      "instance 0, ep 26\n",
      "instance 0, ep 27\n",
      "instance 0, ep 28\n",
      "instance 0, ep 29\n",
      "instance 0, ep 30\n",
      "instance 0, ep 31\n",
      "instance 0, ep 32\n",
      "instance 0, ep 33\n",
      "instance 0, ep 34\n",
      "instance 0, ep 35\n",
      "instance 0, ep 36\n",
      "instance 0, ep 37\n",
      "instance 0, ep 38\n",
      "instance 0, ep 39\n",
      "instance 0, ep 40\n",
      "instance 0, ep 41\n",
      "instance 0, ep 42\n",
      "instance 0, ep 43\n",
      "instance 0, ep 44\n",
      "instance 0, ep 45\n",
      "instance 0, ep 46\n",
      "instance 0, ep 47\n",
      "instance 0, ep 48\n",
      "instance 0, ep 49\n",
      "instance 0, ep 50\n",
      "instance 0, ep 51\n",
      "instance 0, ep 52\n",
      "instance 0, ep 53\n",
      "instance 0, ep 54\n",
      "instance 0, ep 55\n",
      "instance 0, ep 56\n",
      "instance 0, ep 57\n",
      "instance 0, ep 58\n",
      "instance 0, ep 59\n",
      "instance 0, ep 60\n",
      "instance 0, ep 61\n",
      "instance 0, ep 62\n",
      "instance 0, ep 63\n",
      "instance 0, ep 64\n",
      "instance 0, ep 65\n",
      "instance 0, ep 66\n",
      "instance 0, ep 67\n",
      "instance 0, ep 68\n",
      "instance 0, ep 69\n",
      "instance 0, ep 70\n",
      "instance 0, ep 71\n",
      "instance 0, ep 72\n",
      "instance 0, ep 73\n",
      "instance 0, ep 74\n",
      "instance 0, ep 75\n",
      "instance 0, ep 76\n",
      "instance 0, ep 77\n",
      "instance 0, ep 78\n",
      "instance 0, ep 79\n",
      "instance 0, ep 80\n",
      "instance 0, ep 81\n",
      "instance 0, ep 82\n",
      "instance 0, ep 83\n",
      "instance 0, ep 84\n",
      "instance 0, ep 85\n",
      "instance 0, ep 86\n",
      "instance 0, ep 87\n",
      "instance 0, ep 88\n",
      "instance 0, ep 89\n",
      "instance 0, ep 90\n",
      "instance 0, ep 91\n",
      "instance 0, ep 92\n",
      "instance 0, ep 93\n",
      "instance 0, ep 94\n",
      "instance 0, ep 95\n",
      "instance 0, ep 96\n",
      "instance 0, ep 97\n",
      "instance 0, ep 98\n",
      "instance 0, ep 99\n",
      "Took 4.209829330444336 time for inference and 0.5557529926300049 time for training\n",
      "cohort [71 36 43 49]\n",
      "instance 0, ep 1\n",
      "instance 0, ep 2\n",
      "instance 0, ep 3\n",
      "instance 0, ep 4\n",
      "instance 0, ep 5\n",
      "instance 0, ep 6\n",
      "instance 0, ep 7\n",
      "instance 0, ep 8\n",
      "instance 0, ep 9\n",
      "instance 0, ep 10\n",
      "instance 0, ep 11\n",
      "instance 0, ep 12\n",
      "instance 0, ep 13\n",
      "instance 0, ep 14\n",
      "instance 0, ep 15\n",
      "instance 0, ep 16\n",
      "instance 0, ep 17\n",
      "instance 0, ep 18\n",
      "instance 0, ep 19\n",
      "instance 0, ep 20\n",
      "instance 0, ep 21\n",
      "instance 0, ep 22\n",
      "instance 0, ep 23\n",
      "instance 0, ep 24\n",
      "instance 0, ep 25\n",
      "instance 0, ep 26\n",
      "instance 0, ep 27\n",
      "instance 0, ep 28\n",
      "instance 0, ep 29\n",
      "instance 0, ep 30\n",
      "instance 0, ep 31\n",
      "instance 0, ep 32\n",
      "instance 0, ep 33\n",
      "instance 0, ep 34\n",
      "instance 0, ep 35\n",
      "instance 0, ep 36\n",
      "instance 0, ep 37\n",
      "instance 0, ep 38\n",
      "instance 0, ep 39\n",
      "instance 0, ep 40\n",
      "instance 0, ep 41\n",
      "instance 0, ep 42\n",
      "instance 0, ep 43\n",
      "instance 0, ep 44\n",
      "instance 0, ep 45\n",
      "instance 0, ep 46\n",
      "instance 0, ep 47\n",
      "instance 0, ep 48\n",
      "instance 0, ep 49\n",
      "instance 0, ep 50\n",
      "instance 0, ep 51\n",
      "instance 0, ep 52\n",
      "instance 0, ep 53\n",
      "instance 0, ep 54\n",
      "instance 0, ep 55\n",
      "instance 0, ep 56\n",
      "instance 0, ep 57\n",
      "instance 0, ep 58\n",
      "instance 0, ep 59\n",
      "instance 0, ep 60\n",
      "instance 0, ep 61\n",
      "instance 0, ep 62\n",
      "instance 0, ep 63\n",
      "instance 0, ep 64\n",
      "instance 0, ep 65\n",
      "instance 0, ep 66\n",
      "instance 0, ep 67\n",
      "instance 0, ep 68\n",
      "instance 0, ep 69\n",
      "instance 0, ep 70\n",
      "instance 0, ep 71\n",
      "instance 0, ep 72\n",
      "instance 0, ep 73\n",
      "instance 0, ep 74\n",
      "instance 0, ep 75\n",
      "instance 0, ep 76\n",
      "instance 0, ep 77\n",
      "instance 0, ep 78\n",
      "instance 0, ep 79\n",
      "instance 0, ep 80\n",
      "instance 0, ep 81\n",
      "instance 0, ep 82\n",
      "instance 0, ep 83\n",
      "instance 0, ep 84\n",
      "instance 0, ep 85\n",
      "instance 0, ep 86\n",
      "instance 0, ep 87\n",
      "instance 0, ep 88\n",
      "instance 0, ep 89\n",
      "instance 0, ep 90\n",
      "instance 0, ep 91\n",
      "instance 0, ep 92\n",
      "instance 0, ep 93\n",
      "instance 0, ep 94\n",
      "instance 0, ep 95\n",
      "instance 0, ep 96\n",
      "instance 0, ep 97\n",
      "instance 0, ep 98\n",
      "instance 0, ep 99\n",
      "Took 4.188499450683594 time for inference and 0.5554471015930176 time for training\n",
      "6.4160838914775935\n"
     ]
    }
   ],
   "source": [
    "policy = mcts_policy\n",
    "name = \"mcts\"\n",
    "\n",
    "rewards, memory, simulator = run_multi_seed(seed_list,policy,test_length=episode_len,test_iterations=400)\n",
    "results['{}_reward'.format(name)] = rewards['reward']\n",
    "results['{}_match'.format(name)] =  rewards['match'] \n",
    "results['{}_active'.format(name)] = rewards['active_rate']\n",
    "results['{}_time'.format(name)] =  rewards['time']\n",
    "print(np.mean(rewards['reward']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acting should always be good! (0, 1) 0.108 < 0.183\n",
      "good start state should always be good! 0.380 < 0.508\n",
      "good start state should always be good! 0.506 < 0.760\n",
      "cohort [43 94  9 64]\n",
      "instance 0, ep 1\n",
      "instance 0, ep 2\n",
      "instance 0, ep 3\n",
      "instance 0, ep 4\n",
      "instance 0, ep 5\n",
      "instance 0, ep 6\n",
      "instance 0, ep 7\n",
      "instance 0, ep 8\n",
      "instance 0, ep 9\n",
      "instance 0, ep 10\n",
      "instance 0, ep 11\n",
      "instance 0, ep 12\n",
      "instance 0, ep 13\n",
      "instance 0, ep 14\n",
      "instance 0, ep 15\n",
      "instance 0, ep 16\n",
      "instance 0, ep 17\n",
      "instance 0, ep 18\n",
      "instance 0, ep 19\n",
      "instance 0, ep 20\n",
      "instance 0, ep 21\n",
      "instance 0, ep 22\n",
      "instance 0, ep 23\n",
      "instance 0, ep 24\n",
      "instance 0, ep 25\n",
      "instance 0, ep 26\n",
      "instance 0, ep 27\n",
      "instance 0, ep 28\n",
      "instance 0, ep 29\n",
      "instance 0, ep 30\n",
      "instance 0, ep 31\n",
      "instance 0, ep 32\n",
      "instance 0, ep 33\n",
      "instance 0, ep 34\n",
      "instance 0, ep 35\n",
      "instance 0, ep 36\n",
      "instance 0, ep 37\n",
      "instance 0, ep 38\n",
      "instance 0, ep 39\n",
      "instance 0, ep 40\n",
      "instance 0, ep 41\n",
      "instance 0, ep 42\n",
      "instance 0, ep 43\n",
      "instance 0, ep 44\n",
      "instance 0, ep 45\n",
      "instance 0, ep 46\n",
      "instance 0, ep 47\n",
      "instance 0, ep 48\n",
      "instance 0, ep 49\n",
      "instance 0, ep 50\n",
      "instance 0, ep 51\n",
      "instance 0, ep 52\n",
      "instance 0, ep 53\n",
      "instance 0, ep 54\n",
      "instance 0, ep 55\n",
      "instance 0, ep 56\n",
      "instance 0, ep 57\n",
      "instance 0, ep 58\n",
      "instance 0, ep 59\n",
      "instance 0, ep 60\n",
      "instance 0, ep 61\n",
      "instance 0, ep 62\n",
      "instance 0, ep 63\n",
      "instance 0, ep 64\n",
      "instance 0, ep 65\n",
      "instance 0, ep 66\n",
      "instance 0, ep 67\n",
      "instance 0, ep 68\n",
      "instance 0, ep 69\n",
      "instance 0, ep 70\n",
      "instance 0, ep 71\n",
      "instance 0, ep 72\n",
      "instance 0, ep 73\n",
      "instance 0, ep 74\n",
      "instance 0, ep 75\n",
      "instance 0, ep 76\n",
      "instance 0, ep 77\n",
      "instance 0, ep 78\n",
      "instance 0, ep 79\n",
      "instance 0, ep 80\n",
      "instance 0, ep 81\n",
      "instance 0, ep 82\n",
      "instance 0, ep 83\n",
      "instance 0, ep 84\n",
      "instance 0, ep 85\n",
      "instance 0, ep 86\n",
      "instance 0, ep 87\n",
      "instance 0, ep 88\n",
      "instance 0, ep 89\n",
      "instance 0, ep 90\n",
      "instance 0, ep 91\n",
      "instance 0, ep 92\n",
      "instance 0, ep 93\n",
      "instance 0, ep 94\n",
      "instance 0, ep 95\n",
      "instance 0, ep 96\n",
      "instance 0, ep 97\n",
      "instance 0, ep 98\n",
      "instance 0, ep 99\n",
      "Took 0.008028507232666016 time for inference and 0.460479736328125 time for training\n",
      "2.3667817732098624\n"
     ]
    }
   ],
   "source": [
    "policy = greedy_policy\n",
    "name = \"greedy\"\n",
    "\n",
    "rewards, memory, simulator = run_multi_seed(seed_list,policy,test_length=episode_len)\n",
    "results['{}_reward'.format(name)] = rewards['reward']\n",
    "results['{}_match'.format(name)] =  rewards['match'] \n",
    "results['{}_active'.format(name)] = rewards['active_rate']\n",
    "results['{}_time'.format(name)] =  rewards['time']\n",
    "print(np.mean(rewards['reward']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acting should always be good! (0, 1) 0.108 < 0.183\n",
      "good start state should always be good! 0.380 < 0.508\n",
      "good start state should always be good! 0.506 < 0.760\n",
      "cohort [43 94  9 64]\n",
      "instance 0, ep 1\n",
      "instance 0, ep 2\n",
      "instance 0, ep 3\n",
      "instance 0, ep 4\n",
      "instance 0, ep 5\n",
      "instance 0, ep 6\n",
      "instance 0, ep 7\n",
      "instance 0, ep 8\n",
      "instance 0, ep 9\n",
      "instance 0, ep 10\n",
      "instance 0, ep 11\n",
      "instance 0, ep 12\n",
      "instance 0, ep 13\n",
      "instance 0, ep 14\n",
      "instance 0, ep 15\n",
      "instance 0, ep 16\n",
      "instance 0, ep 17\n",
      "instance 0, ep 18\n",
      "instance 0, ep 19\n",
      "instance 0, ep 20\n",
      "instance 0, ep 21\n",
      "instance 0, ep 22\n",
      "instance 0, ep 23\n",
      "instance 0, ep 24\n",
      "instance 0, ep 25\n",
      "instance 0, ep 26\n",
      "instance 0, ep 27\n",
      "instance 0, ep 28\n",
      "instance 0, ep 29\n",
      "instance 0, ep 30\n",
      "instance 0, ep 31\n",
      "instance 0, ep 32\n",
      "instance 0, ep 33\n",
      "instance 0, ep 34\n",
      "instance 0, ep 35\n",
      "instance 0, ep 36\n",
      "instance 0, ep 37\n",
      "instance 0, ep 38\n",
      "instance 0, ep 39\n",
      "instance 0, ep 40\n",
      "instance 0, ep 41\n",
      "instance 0, ep 42\n",
      "instance 0, ep 43\n",
      "instance 0, ep 44\n",
      "instance 0, ep 45\n",
      "instance 0, ep 46\n",
      "instance 0, ep 47\n",
      "instance 0, ep 48\n",
      "instance 0, ep 49\n",
      "instance 0, ep 50\n",
      "instance 0, ep 51\n",
      "instance 0, ep 52\n",
      "instance 0, ep 53\n",
      "instance 0, ep 54\n",
      "instance 0, ep 55\n",
      "instance 0, ep 56\n",
      "instance 0, ep 57\n",
      "instance 0, ep 58\n",
      "instance 0, ep 59\n",
      "instance 0, ep 60\n",
      "instance 0, ep 61\n",
      "instance 0, ep 62\n",
      "instance 0, ep 63\n",
      "instance 0, ep 64\n",
      "instance 0, ep 65\n",
      "instance 0, ep 66\n",
      "instance 0, ep 67\n",
      "instance 0, ep 68\n",
      "instance 0, ep 69\n",
      "instance 0, ep 70\n",
      "instance 0, ep 71\n",
      "instance 0, ep 72\n",
      "instance 0, ep 73\n",
      "instance 0, ep 74\n",
      "instance 0, ep 75\n",
      "instance 0, ep 76\n",
      "instance 0, ep 77\n",
      "instance 0, ep 78\n",
      "instance 0, ep 79\n",
      "instance 0, ep 80\n",
      "instance 0, ep 81\n",
      "instance 0, ep 82\n",
      "instance 0, ep 83\n",
      "instance 0, ep 84\n",
      "instance 0, ep 85\n",
      "instance 0, ep 86\n",
      "instance 0, ep 87\n",
      "instance 0, ep 88\n",
      "instance 0, ep 89\n",
      "instance 0, ep 90\n",
      "instance 0, ep 91\n",
      "instance 0, ep 92\n",
      "instance 0, ep 93\n",
      "instance 0, ep 94\n",
      "instance 0, ep 95\n",
      "instance 0, ep 96\n",
      "instance 0, ep 97\n",
      "instance 0, ep 98\n",
      "instance 0, ep 99\n",
      "Took 0.4835238456726074 time for inference and 0.0001366138458251953 time for training\n",
      "2.4299300773173416\n"
     ]
    }
   ],
   "source": [
    "policy = random_policy\n",
    "name = \"random\"\n",
    "\n",
    "rewards, memory, simulator = run_multi_seed(seed_list,policy,test_length=episode_len)\n",
    "results['{}_reward'.format(name)] = rewards['reward']\n",
    "results['{}_match'.format(name)] =  rewards['match'] \n",
    "results['{}_active'.format(name)] = rewards['active_rate']\n",
    "results['{}_time'.format(name)] =  rewards['time']\n",
    "print(np.mean(rewards['reward']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acting should always be good! (0, 1) 0.108 < 0.183\n",
      "good start state should always be good! 0.380 < 0.508\n",
      "good start state should always be good! 0.506 < 0.760\n",
      "cohort [43 94  9 64]\n",
      "instance 0, ep 1\n",
      "instance 0, ep 2\n",
      "instance 0, ep 3\n",
      "instance 0, ep 4\n",
      "instance 0, ep 5\n",
      "instance 0, ep 6\n",
      "instance 0, ep 7\n",
      "instance 0, ep 8\n",
      "instance 0, ep 9\n",
      "instance 0, ep 10\n",
      "instance 0, ep 11\n",
      "instance 0, ep 12\n",
      "instance 0, ep 13\n",
      "instance 0, ep 14\n",
      "instance 0, ep 15\n",
      "instance 0, ep 16\n",
      "instance 0, ep 17\n",
      "instance 0, ep 18\n",
      "instance 0, ep 19\n",
      "instance 0, ep 20\n",
      "instance 0, ep 21\n",
      "instance 0, ep 22\n",
      "instance 0, ep 23\n",
      "instance 0, ep 24\n",
      "instance 0, ep 25\n",
      "instance 0, ep 26\n",
      "instance 0, ep 27\n",
      "instance 0, ep 28\n",
      "instance 0, ep 29\n",
      "instance 0, ep 30\n",
      "instance 0, ep 31\n",
      "instance 0, ep 32\n",
      "instance 0, ep 33\n",
      "instance 0, ep 34\n",
      "instance 0, ep 35\n",
      "instance 0, ep 36\n",
      "instance 0, ep 37\n",
      "instance 0, ep 38\n",
      "instance 0, ep 39\n",
      "instance 0, ep 40\n",
      "instance 0, ep 41\n",
      "instance 0, ep 42\n",
      "instance 0, ep 43\n",
      "instance 0, ep 44\n",
      "instance 0, ep 45\n",
      "instance 0, ep 46\n",
      "instance 0, ep 47\n",
      "instance 0, ep 48\n",
      "instance 0, ep 49\n",
      "instance 0, ep 50\n",
      "instance 0, ep 51\n",
      "instance 0, ep 52\n",
      "instance 0, ep 53\n",
      "instance 0, ep 54\n",
      "instance 0, ep 55\n",
      "instance 0, ep 56\n",
      "instance 0, ep 57\n",
      "instance 0, ep 58\n",
      "instance 0, ep 59\n",
      "instance 0, ep 60\n",
      "instance 0, ep 61\n",
      "instance 0, ep 62\n",
      "instance 0, ep 63\n",
      "instance 0, ep 64\n",
      "instance 0, ep 65\n",
      "instance 0, ep 66\n",
      "instance 0, ep 67\n",
      "instance 0, ep 68\n",
      "instance 0, ep 69\n",
      "instance 0, ep 70\n",
      "instance 0, ep 71\n",
      "instance 0, ep 72\n",
      "instance 0, ep 73\n",
      "instance 0, ep 74\n",
      "instance 0, ep 75\n",
      "instance 0, ep 76\n",
      "instance 0, ep 77\n",
      "instance 0, ep 78\n",
      "instance 0, ep 79\n",
      "instance 0, ep 80\n",
      "instance 0, ep 81\n",
      "instance 0, ep 82\n",
      "instance 0, ep 83\n",
      "instance 0, ep 84\n",
      "instance 0, ep 85\n",
      "instance 0, ep 86\n",
      "instance 0, ep 87\n",
      "instance 0, ep 88\n",
      "instance 0, ep 89\n",
      "instance 0, ep 90\n",
      "instance 0, ep 91\n",
      "instance 0, ep 92\n",
      "instance 0, ep 93\n",
      "instance 0, ep 94\n",
      "instance 0, ep 95\n",
      "instance 0, ep 96\n",
      "instance 0, ep 97\n",
      "instance 0, ep 98\n",
      "instance 0, ep 99\n",
      "Took 0.006594181060791016 time for inference and 0.8793606758117676 time for training\n",
      "2.0710357924860845\n"
     ]
    }
   ],
   "source": [
    "policy = whittle_activity_policy\n",
    "name = \"whittle_activity\"\n",
    "\n",
    "rewards, memory, simulator = run_multi_seed(seed_list,policy,test_length=episode_len)\n",
    "results['{}_reward'.format(name)] = rewards['reward']\n",
    "results['{}_match'.format(name)] =  rewards['match'] \n",
    "results['{}_active'.format(name)] = rewards['active_rate']\n",
    "results['{}_time'.format(name)] =  rewards['time']\n",
    "print(np.mean(rewards['reward']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running DQN\n",
      "cohort [87 53 47  7]\n",
      "instance 0, ep 1\n",
      "instance 0, ep 2\n",
      "instance 0, ep 3\n",
      "instance 0, ep 4\n",
      "instance 0, ep 5\n",
      "instance 0, ep 6\n",
      "instance 0, ep 7\n",
      "instance 0, ep 8\n",
      "instance 0, ep 9\n",
      "instance 0, ep 10\n",
      "instance 0, ep 11\n",
      "instance 0, ep 12\n",
      "instance 0, ep 13\n",
      "instance 0, ep 14\n",
      "instance 0, ep 15\n",
      "instance 0, ep 16\n",
      "instance 0, ep 17\n",
      "instance 0, ep 18\n",
      "instance 0, ep 19\n",
      "instance 0, ep 20\n",
      "instance 0, ep 21\n",
      "instance 0, ep 22\n",
      "instance 0, ep 23\n",
      "instance 0, ep 24\n",
      "instance 0, ep 25\n",
      "instance 0, ep 26\n",
      "instance 0, ep 27\n",
      "instance 0, ep 28\n",
      "instance 0, ep 29\n",
      "instance 0, ep 30\n",
      "instance 0, ep 31\n",
      "instance 0, ep 32\n",
      "instance 0, ep 33\n",
      "instance 0, ep 34\n",
      "instance 0, ep 35\n",
      "instance 0, ep 36\n",
      "instance 0, ep 37\n",
      "instance 0, ep 38\n",
      "instance 0, ep 39\n",
      "instance 0, ep 40\n",
      "instance 0, ep 41\n",
      "instance 0, ep 42\n",
      "instance 0, ep 43\n",
      "instance 0, ep 44\n",
      "instance 0, ep 45\n",
      "instance 0, ep 46\n",
      "instance 0, ep 47\n",
      "instance 0, ep 48\n",
      "instance 0, ep 49\n",
      "instance 0, ep 50\n",
      "instance 0, ep 51\n",
      "instance 0, ep 52\n",
      "instance 0, ep 53\n",
      "instance 0, ep 54\n",
      "instance 0, ep 55\n",
      "instance 0, ep 56\n",
      "instance 0, ep 57\n",
      "instance 0, ep 58\n",
      "instance 0, ep 59\n",
      "instance 0, ep 60\n",
      "instance 0, ep 61\n",
      "instance 0, ep 62\n",
      "instance 0, ep 63\n",
      "instance 0, ep 64\n",
      "instance 0, ep 65\n",
      "instance 0, ep 66\n",
      "instance 0, ep 67\n",
      "instance 0, ep 68\n",
      "instance 0, ep 69\n",
      "instance 0, ep 70\n",
      "instance 0, ep 71\n",
      "instance 0, ep 72\n",
      "instance 0, ep 73\n",
      "instance 0, ep 74\n",
      "instance 0, ep 75\n",
      "instance 0, ep 76\n",
      "instance 0, ep 77\n",
      "instance 0, ep 78\n",
      "instance 0, ep 79\n",
      "instance 0, ep 80\n",
      "instance 0, ep 81\n",
      "instance 0, ep 82\n",
      "instance 0, ep 83\n",
      "instance 0, ep 84\n",
      "instance 0, ep 85\n",
      "instance 0, ep 86\n",
      "instance 0, ep 87\n",
      "instance 0, ep 88\n",
      "instance 0, ep 89\n",
      "instance 0, ep 90\n",
      "instance 0, ep 91\n",
      "instance 0, ep 92\n",
      "instance 0, ep 93\n",
      "instance 0, ep 94\n",
      "instance 0, ep 95\n",
      "instance 0, ep 96\n",
      "instance 0, ep 97\n",
      "instance 0, ep 98\n",
      "instance 0, ep 99\n",
      "Took 0.027396202087402344 time for inference and 16.308341026306152 time for training\n",
      "cohort [35  4 66  7]\n",
      "instance 0, ep 1\n",
      "instance 0, ep 2\n",
      "instance 0, ep 3\n",
      "instance 0, ep 4\n",
      "instance 0, ep 5\n",
      "instance 0, ep 6\n",
      "instance 0, ep 7\n",
      "instance 0, ep 8\n",
      "instance 0, ep 9\n",
      "instance 0, ep 10\n",
      "instance 0, ep 11\n",
      "instance 0, ep 12\n",
      "instance 0, ep 13\n",
      "instance 0, ep 14\n",
      "instance 0, ep 15\n",
      "instance 0, ep 16\n",
      "instance 0, ep 17\n",
      "instance 0, ep 18\n",
      "instance 0, ep 19\n",
      "instance 0, ep 20\n",
      "instance 0, ep 21\n",
      "instance 0, ep 22\n",
      "instance 0, ep 23\n",
      "instance 0, ep 24\n",
      "instance 0, ep 25\n",
      "instance 0, ep 26\n",
      "instance 0, ep 27\n",
      "instance 0, ep 28\n",
      "instance 0, ep 29\n",
      "instance 0, ep 30\n",
      "instance 0, ep 31\n",
      "instance 0, ep 32\n",
      "instance 0, ep 33\n",
      "instance 0, ep 34\n",
      "instance 0, ep 35\n",
      "instance 0, ep 36\n",
      "instance 0, ep 37\n",
      "instance 0, ep 38\n",
      "instance 0, ep 39\n",
      "instance 0, ep 40\n",
      "instance 0, ep 41\n",
      "instance 0, ep 42\n",
      "instance 0, ep 43\n",
      "instance 0, ep 44\n",
      "instance 0, ep 45\n",
      "instance 0, ep 46\n",
      "instance 0, ep 47\n",
      "instance 0, ep 48\n",
      "instance 0, ep 49\n",
      "instance 0, ep 50\n",
      "instance 0, ep 51\n",
      "instance 0, ep 52\n",
      "instance 0, ep 53\n",
      "instance 0, ep 54\n",
      "instance 0, ep 55\n",
      "instance 0, ep 56\n",
      "instance 0, ep 57\n",
      "instance 0, ep 58\n",
      "instance 0, ep 59\n",
      "instance 0, ep 60\n",
      "instance 0, ep 61\n",
      "instance 0, ep 62\n",
      "instance 0, ep 63\n",
      "instance 0, ep 64\n",
      "instance 0, ep 65\n",
      "instance 0, ep 66\n",
      "instance 0, ep 67\n",
      "instance 0, ep 68\n",
      "instance 0, ep 69\n",
      "instance 0, ep 70\n",
      "instance 0, ep 71\n",
      "instance 0, ep 72\n",
      "instance 0, ep 73\n",
      "instance 0, ep 74\n",
      "instance 0, ep 75\n",
      "instance 0, ep 76\n",
      "instance 0, ep 77\n",
      "instance 0, ep 78\n",
      "instance 0, ep 79\n",
      "instance 0, ep 80\n",
      "instance 0, ep 81\n",
      "instance 0, ep 82\n",
      "instance 0, ep 83\n",
      "instance 0, ep 84\n",
      "instance 0, ep 85\n",
      "instance 0, ep 86\n",
      "instance 0, ep 87\n",
      "instance 0, ep 88\n",
      "instance 0, ep 89\n",
      "instance 0, ep 90\n",
      "instance 0, ep 91\n",
      "instance 0, ep 92\n",
      "instance 0, ep 93\n",
      "instance 0, ep 94\n",
      "instance 0, ep 95\n",
      "instance 0, ep 96\n",
      "instance 0, ep 97\n",
      "instance 0, ep 98\n",
      "instance 0, ep 99\n",
      "Took 0.027051210403442383 time for inference and 15.416279792785645 time for training\n",
      "cohort [55 38 69 53]\n",
      "instance 0, ep 1\n",
      "instance 0, ep 2\n",
      "instance 0, ep 3\n",
      "instance 0, ep 4\n",
      "instance 0, ep 5\n",
      "instance 0, ep 6\n",
      "instance 0, ep 7\n",
      "instance 0, ep 8\n",
      "instance 0, ep 9\n",
      "instance 0, ep 10\n",
      "instance 0, ep 11\n",
      "instance 0, ep 12\n",
      "instance 0, ep 13\n",
      "instance 0, ep 14\n",
      "instance 0, ep 15\n",
      "instance 0, ep 16\n",
      "instance 0, ep 17\n",
      "instance 0, ep 18\n",
      "instance 0, ep 19\n",
      "instance 0, ep 20\n",
      "instance 0, ep 21\n",
      "instance 0, ep 22\n",
      "instance 0, ep 23\n",
      "instance 0, ep 24\n",
      "instance 0, ep 25\n",
      "instance 0, ep 26\n",
      "instance 0, ep 27\n",
      "instance 0, ep 28\n",
      "instance 0, ep 29\n",
      "instance 0, ep 30\n",
      "instance 0, ep 31\n",
      "instance 0, ep 32\n",
      "instance 0, ep 33\n",
      "instance 0, ep 34\n",
      "instance 0, ep 35\n",
      "instance 0, ep 36\n",
      "instance 0, ep 37\n",
      "instance 0, ep 38\n",
      "instance 0, ep 39\n",
      "instance 0, ep 40\n",
      "instance 0, ep 41\n",
      "instance 0, ep 42\n",
      "instance 0, ep 43\n",
      "instance 0, ep 44\n",
      "instance 0, ep 45\n",
      "instance 0, ep 46\n",
      "instance 0, ep 47\n",
      "instance 0, ep 48\n",
      "instance 0, ep 49\n",
      "instance 0, ep 50\n",
      "instance 0, ep 51\n",
      "instance 0, ep 52\n",
      "instance 0, ep 53\n",
      "instance 0, ep 54\n",
      "instance 0, ep 55\n",
      "instance 0, ep 56\n",
      "instance 0, ep 57\n",
      "instance 0, ep 58\n",
      "instance 0, ep 59\n",
      "instance 0, ep 60\n",
      "instance 0, ep 61\n",
      "instance 0, ep 62\n",
      "instance 0, ep 63\n",
      "instance 0, ep 64\n",
      "instance 0, ep 65\n",
      "instance 0, ep 66\n",
      "instance 0, ep 67\n",
      "instance 0, ep 68\n",
      "instance 0, ep 69\n",
      "instance 0, ep 70\n",
      "instance 0, ep 71\n",
      "instance 0, ep 72\n",
      "instance 0, ep 73\n",
      "instance 0, ep 74\n",
      "instance 0, ep 75\n",
      "instance 0, ep 76\n",
      "instance 0, ep 77\n",
      "instance 0, ep 78\n",
      "instance 0, ep 79\n",
      "instance 0, ep 80\n",
      "instance 0, ep 81\n",
      "instance 0, ep 82\n",
      "instance 0, ep 83\n",
      "instance 0, ep 84\n",
      "instance 0, ep 85\n",
      "instance 0, ep 86\n",
      "instance 0, ep 87\n",
      "instance 0, ep 88\n",
      "instance 0, ep 89\n",
      "instance 0, ep 90\n",
      "instance 0, ep 91\n",
      "instance 0, ep 92\n",
      "instance 0, ep 93\n",
      "instance 0, ep 94\n",
      "instance 0, ep 95\n",
      "instance 0, ep 96\n",
      "instance 0, ep 97\n",
      "instance 0, ep 98\n",
      "instance 0, ep 99\n",
      "Took 0.026889324188232422 time for inference and 15.088267803192139 time for training\n",
      "cohort [84 53 80 94]\n",
      "instance 0, ep 1\n",
      "instance 0, ep 2\n",
      "instance 0, ep 3\n",
      "instance 0, ep 4\n",
      "instance 0, ep 5\n",
      "instance 0, ep 6\n",
      "instance 0, ep 7\n",
      "instance 0, ep 8\n",
      "instance 0, ep 9\n",
      "instance 0, ep 10\n",
      "instance 0, ep 11\n",
      "instance 0, ep 12\n",
      "instance 0, ep 13\n",
      "instance 0, ep 14\n",
      "instance 0, ep 15\n",
      "instance 0, ep 16\n",
      "instance 0, ep 17\n",
      "instance 0, ep 18\n",
      "instance 0, ep 19\n",
      "instance 0, ep 20\n",
      "instance 0, ep 21\n",
      "instance 0, ep 22\n",
      "instance 0, ep 23\n",
      "instance 0, ep 24\n",
      "instance 0, ep 25\n",
      "instance 0, ep 26\n",
      "instance 0, ep 27\n",
      "instance 0, ep 28\n",
      "instance 0, ep 29\n",
      "instance 0, ep 30\n",
      "instance 0, ep 31\n",
      "instance 0, ep 32\n",
      "instance 0, ep 33\n",
      "instance 0, ep 34\n",
      "instance 0, ep 35\n",
      "instance 0, ep 36\n",
      "instance 0, ep 37\n",
      "instance 0, ep 38\n",
      "instance 0, ep 39\n",
      "instance 0, ep 40\n",
      "instance 0, ep 41\n",
      "instance 0, ep 42\n",
      "instance 0, ep 43\n",
      "instance 0, ep 44\n",
      "instance 0, ep 45\n",
      "instance 0, ep 46\n",
      "instance 0, ep 47\n",
      "instance 0, ep 48\n",
      "instance 0, ep 49\n",
      "instance 0, ep 50\n",
      "instance 0, ep 51\n",
      "instance 0, ep 52\n",
      "instance 0, ep 53\n",
      "instance 0, ep 54\n",
      "instance 0, ep 55\n",
      "instance 0, ep 56\n",
      "instance 0, ep 57\n",
      "instance 0, ep 58\n",
      "instance 0, ep 59\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[20], line 7\u001b[0m\n\u001b[1;32m      3\u001b[0m name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdqn\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRunning DQN\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 7\u001b[0m rewards, memory, simulator \u001b[38;5;241m=\u001b[39m \u001b[43mrun_multi_seed\u001b[49m\u001b[43m(\u001b[49m\u001b[43mseed_list\u001b[49m\u001b[43m,\u001b[49m\u001b[43mpolicy\u001b[49m\u001b[43m,\u001b[49m\u001b[43mis_mcts\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43mavg_reward\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmean\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresults\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mlinear_whittle_reward\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43mtest_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mepisode_len\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      8\u001b[0m results[\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m_reward\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(name)] \u001b[38;5;241m=\u001b[39m rewards[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mreward\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m      9\u001b[0m results[\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m_match\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(name)] \u001b[38;5;241m=\u001b[39m  rewards[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmatch\u001b[39m\u001b[38;5;124m'\u001b[39m] \n",
      "Cell \u001b[0;32mIn[15], line 22\u001b[0m, in \u001b[0;36mrun_multi_seed\u001b[0;34m(seed_list, policy, is_mcts, per_epoch_function, train_iterations, test_iterations, test_length, avg_reward, num_samples)\u001b[0m\n\u001b[1;32m     19\u001b[0m simulator\u001b[38;5;241m.\u001b[39mmcts_depth \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m2\u001b[39m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_mcts:\n\u001b[0;32m---> 22\u001b[0m     match, active_rate, memory \u001b[38;5;241m=\u001b[39m \u001b[43mrun_heterogenous_policy\u001b[49m\u001b[43m(\u001b[49m\u001b[43msimulator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_episodes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_epochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdiscount\u001b[49m\u001b[43m,\u001b[49m\u001b[43mpolicy\u001b[49m\u001b[43m,\u001b[49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\u001b[43mlamb\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlamb\u001b[49m\u001b[43m,\u001b[49m\u001b[43mshould_train\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43mtest_T\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest_length\u001b[49m\u001b[43m,\u001b[49m\u001b[43mget_memory\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43mper_epoch_function\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mper_epoch_function\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     24\u001b[0m     match, active_rate \u001b[38;5;241m=\u001b[39m run_heterogenous_policy(simulator, n_episodes, n_epochs, discount,policy,seed,lamb\u001b[38;5;241m=\u001b[39mlamb,should_train\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,test_T\u001b[38;5;241m=\u001b[39mtest_length,per_epoch_function\u001b[38;5;241m=\u001b[39mper_epoch_function)\n",
      "File \u001b[0;32m~/projects/food_rescue_rmab/rmab/simulator.py:746\u001b[0m, in \u001b[0;36mrun_heterogenous_policy\u001b[0;34m(env, n_episodes, n_epochs, discount, policy, seed, per_epoch_function, lamb, get_memory, should_train, test_T)\u001b[0m\n\u001b[1;32m    743\u001b[0m     all_active_rate[epoch,t\u001b[38;5;241m-\u001b[39m(T\u001b[38;5;241m-\u001b[39mtest_T)] \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39msum(state)\u001b[38;5;241m/\u001b[39m\u001b[38;5;28mlen\u001b[39m(state)\n\u001b[1;32m    745\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m should_train \u001b[38;5;129;01mor\u001b[39;00m t \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39mT\u001b[38;5;241m-\u001b[39mtest_T:\n\u001b[0;32m--> 746\u001b[0m     action,memory \u001b[38;5;241m=\u001b[39m \u001b[43mpolicy\u001b[49m\u001b[43m(\u001b[49m\u001b[43menv\u001b[49m\u001b[43m,\u001b[49m\u001b[43mstate\u001b[49m\u001b[43m,\u001b[49m\u001b[43mbudget\u001b[49m\u001b[43m,\u001b[49m\u001b[43mlamb\u001b[49m\u001b[43m,\u001b[49m\u001b[43mmemory\u001b[49m\u001b[43m,\u001b[49m\u001b[43mper_epoch_results\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    747\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    748\u001b[0m     action,memory \u001b[38;5;241m=\u001b[39m random_policy(env,state,budget,lamb,memory,per_epoch_results)\n",
      "File \u001b[0;32m~/projects/food_rescue_rmab/rmab/dqn_policies.py:242\u001b[0m, in \u001b[0;36mdqn_policy_greedy\u001b[0;34m(env, state, budget, lamb, memory, per_epoch_results, group_setup)\u001b[0m\n\u001b[1;32m    241\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdqn_policy_greedy\u001b[39m(env,state,budget,lamb,memory,per_epoch_results,group_setup\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnone\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m--> 242\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mdqn_policy\u001b[49m\u001b[43m(\u001b[49m\u001b[43menv\u001b[49m\u001b[43m,\u001b[49m\u001b[43mstate\u001b[49m\u001b[43m,\u001b[49m\u001b[43mbudget\u001b[49m\u001b[43m,\u001b[49m\u001b[43mlamb\u001b[49m\u001b[43m,\u001b[49m\u001b[43mmemory\u001b[49m\u001b[43m,\u001b[49m\u001b[43mper_epoch_results\u001b[49m\u001b[43m,\u001b[49m\u001b[43mgroup_setup\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mnone\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mgreedy_eval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/projects/food_rescue_rmab/rmab/dqn_policies.py:133\u001b[0m, in \u001b[0;36mdqn_policy\u001b[0;34m(env, state, budget, lamb, memory, per_epoch_results, group_setup, stabilization, greedy_eval)\u001b[0m\n\u001b[1;32m    131\u001b[0m random_memories \u001b[38;5;241m=\u001b[39m random\u001b[38;5;241m.\u001b[39msample(\u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(past_states)\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m2\u001b[39m)),batch_size)\n\u001b[1;32m    132\u001b[0m sample_state \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(past_states)[random_memories]\n\u001b[0;32m--> 133\u001b[0m sample_action \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marray\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpast_actions\u001b[49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[43mrandom_memories\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m    134\u001b[0m sample_probs \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(past_probs)[random_memories]\n\u001b[1;32m    135\u001b[0m action_idx \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray([action_to_idx[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin([\u001b[38;5;28mstr\u001b[39m(j) \u001b[38;5;28;01mfor\u001b[39;00m j \u001b[38;5;129;01min\u001b[39;00m i])] \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m sample_action])\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "if n_arms*volunteers_per_arm <= 10:\n",
    "    policy = dqn_policy_greedy\n",
    "    name = \"dqn\"\n",
    "\n",
    "    print(\"Running DQN\")\n",
    "\n",
    "    rewards, memory, simulator = run_multi_seed(seed_list,policy,is_mcts=True,avg_reward=np.mean(results['linear_whittle_reward'][0]),test_length=episode_len)\n",
    "    results['{}_reward'.format(name)] = rewards['reward']\n",
    "    results['{}_match'.format(name)] =  rewards['match'] \n",
    "    results['{}_active'.format(name)] = rewards['active_rate']\n",
    "    results['{}_time'.format(name)] =  rewards['time']\n",
    "    print(np.mean(rewards['reward']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running DQN Step\n",
      "acting should always be good! (0, 1) 0.108 < 0.183\n",
      "good start state should always be good! 0.380 < 0.508\n",
      "good start state should always be good! 0.506 < 0.760\n",
      "cohort [43 94  9 64]\n",
      "instance 0, ep 1\n",
      "instance 0, ep 2\n",
      "instance 0, ep 3\n",
      "instance 0, ep 4\n",
      "instance 0, ep 5\n",
      "instance 0, ep 6\n",
      "instance 0, ep 7\n",
      "instance 0, ep 8\n",
      "instance 0, ep 9\n",
      "instance 0, ep 10\n",
      "instance 0, ep 11\n",
      "instance 0, ep 12\n",
      "instance 0, ep 13\n",
      "instance 0, ep 14\n",
      "instance 0, ep 15\n",
      "instance 0, ep 16\n",
      "instance 0, ep 17\n",
      "instance 0, ep 18\n",
      "instance 0, ep 19\n",
      "instance 0, ep 20\n",
      "instance 0, ep 21\n",
      "instance 0, ep 22\n",
      "instance 0, ep 23\n",
      "instance 0, ep 24\n",
      "instance 0, ep 25\n",
      "instance 0, ep 26\n",
      "instance 0, ep 27\n",
      "instance 0, ep 28\n",
      "instance 0, ep 29\n",
      "instance 0, ep 30\n",
      "instance 0, ep 31\n",
      "instance 0, ep 32\n",
      "instance 0, ep 33\n",
      "instance 0, ep 34\n",
      "instance 0, ep 35\n",
      "instance 0, ep 36\n",
      "instance 0, ep 37\n",
      "instance 0, ep 38\n",
      "instance 0, ep 39\n",
      "instance 0, ep 40\n",
      "instance 0, ep 41\n",
      "instance 0, ep 42\n",
      "instance 0, ep 43\n",
      "instance 0, ep 44\n",
      "instance 0, ep 45\n",
      "instance 0, ep 46\n",
      "instance 0, ep 47\n",
      "instance 0, ep 48\n",
      "instance 0, ep 49\n",
      "instance 0, ep 50\n",
      "instance 0, ep 51\n",
      "instance 0, ep 52\n",
      "instance 0, ep 53\n",
      "instance 0, ep 54\n",
      "instance 0, ep 55\n",
      "instance 0, ep 56\n",
      "instance 0, ep 57\n",
      "instance 0, ep 58\n",
      "instance 0, ep 59\n",
      "instance 0, ep 60\n",
      "instance 0, ep 61\n",
      "instance 0, ep 62\n",
      "instance 0, ep 63\n",
      "instance 0, ep 64\n",
      "instance 0, ep 65\n",
      "instance 0, ep 66\n",
      "instance 0, ep 67\n",
      "instance 0, ep 68\n",
      "instance 0, ep 69\n",
      "instance 0, ep 70\n",
      "instance 0, ep 71\n",
      "instance 0, ep 72\n",
      "instance 0, ep 73\n",
      "instance 0, ep 74\n",
      "instance 0, ep 75\n",
      "instance 0, ep 76\n",
      "instance 0, ep 77\n",
      "instance 0, ep 78\n",
      "instance 0, ep 79\n",
      "instance 0, ep 80\n",
      "instance 0, ep 81\n",
      "instance 0, ep 82\n",
      "instance 0, ep 83\n",
      "instance 0, ep 84\n",
      "instance 0, ep 85\n",
      "instance 0, ep 86\n",
      "instance 0, ep 87\n",
      "instance 0, ep 88\n",
      "instance 0, ep 89\n",
      "instance 0, ep 90\n",
      "instance 0, ep 91\n",
      "instance 0, ep 92\n",
      "instance 0, ep 93\n",
      "instance 0, ep 94\n",
      "instance 0, ep 95\n",
      "instance 0, ep 96\n",
      "instance 0, ep 97\n",
      "instance 0, ep 98\n",
      "instance 0, ep 99\n",
      "Took 0.017782211303710938 time for inference and 10.430238485336304 time for training\n",
      "2.8231535039813154\n"
     ]
    }
   ],
   "source": [
    "policy = dqn_with_steps\n",
    "name = \"dqn_step\"\n",
    "\n",
    "print(\"Running DQN Step\")\n",
    "\n",
    "rewards, memory, simulator = run_multi_seed(seed_list,policy,is_mcts=True,avg_reward=np.mean(results['linear_whittle_reward'][0]),test_length=episode_len)\n",
    "results['{}_reward'.format(name)] = rewards['reward']\n",
    "results['{}_match'.format(name)] =  rewards['match'] \n",
    "results['{}_active'.format(name)] = rewards['active_rate']\n",
    "results['{}_time'.format(name)] =  rewards['time']\n",
    "print(np.mean(rewards['reward']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running DQN Step\n",
      "acting should always be good! (0, 1) 0.108 < 0.183\n",
      "good start state should always be good! 0.380 < 0.508\n",
      "good start state should always be good! 0.506 < 0.760\n",
      "cohort [43 94  9 64]\n",
      "instance 0, ep 1\n",
      "instance 0, ep 2\n",
      "instance 0, ep 3\n",
      "instance 0, ep 4\n",
      "instance 0, ep 5\n",
      "instance 0, ep 6\n",
      "instance 0, ep 7\n",
      "instance 0, ep 8\n",
      "instance 0, ep 9\n",
      "instance 0, ep 10\n",
      "instance 0, ep 11\n",
      "instance 0, ep 12\n",
      "instance 0, ep 13\n",
      "instance 0, ep 14\n",
      "instance 0, ep 15\n",
      "instance 0, ep 16\n",
      "instance 0, ep 17\n",
      "instance 0, ep 18\n",
      "instance 0, ep 19\n",
      "instance 0, ep 20\n",
      "instance 0, ep 21\n",
      "instance 0, ep 22\n",
      "instance 0, ep 23\n",
      "instance 0, ep 24\n",
      "instance 0, ep 25\n",
      "instance 0, ep 26\n",
      "instance 0, ep 27\n",
      "instance 0, ep 28\n",
      "instance 0, ep 29\n",
      "instance 0, ep 30\n",
      "instance 0, ep 31\n",
      "instance 0, ep 32\n",
      "instance 0, ep 33\n",
      "instance 0, ep 34\n",
      "instance 0, ep 35\n",
      "instance 0, ep 36\n",
      "instance 0, ep 37\n",
      "instance 0, ep 38\n",
      "instance 0, ep 39\n",
      "instance 0, ep 40\n",
      "instance 0, ep 41\n",
      "instance 0, ep 42\n",
      "instance 0, ep 43\n",
      "instance 0, ep 44\n",
      "instance 0, ep 45\n",
      "instance 0, ep 46\n",
      "instance 0, ep 47\n",
      "instance 0, ep 48\n",
      "instance 0, ep 49\n",
      "instance 0, ep 50\n",
      "instance 0, ep 51\n",
      "instance 0, ep 52\n",
      "instance 0, ep 53\n",
      "instance 0, ep 54\n",
      "instance 0, ep 55\n",
      "instance 0, ep 56\n",
      "instance 0, ep 57\n",
      "instance 0, ep 58\n",
      "instance 0, ep 59\n",
      "instance 0, ep 60\n",
      "instance 0, ep 61\n",
      "instance 0, ep 62\n",
      "instance 0, ep 63\n",
      "instance 0, ep 64\n",
      "instance 0, ep 65\n",
      "instance 0, ep 66\n",
      "instance 0, ep 67\n",
      "instance 0, ep 68\n",
      "instance 0, ep 69\n",
      "instance 0, ep 70\n",
      "instance 0, ep 71\n",
      "instance 0, ep 72\n",
      "instance 0, ep 73\n",
      "instance 0, ep 74\n",
      "instance 0, ep 75\n",
      "instance 0, ep 76\n",
      "instance 0, ep 77\n",
      "instance 0, ep 78\n",
      "instance 0, ep 79\n",
      "instance 0, ep 80\n",
      "instance 0, ep 81\n",
      "instance 0, ep 82\n",
      "instance 0, ep 83\n",
      "instance 0, ep 84\n",
      "instance 0, ep 85\n",
      "instance 0, ep 86\n",
      "instance 0, ep 87\n",
      "instance 0, ep 88\n",
      "instance 0, ep 89\n",
      "instance 0, ep 90\n",
      "instance 0, ep 91\n",
      "instance 0, ep 92\n",
      "instance 0, ep 93\n",
      "instance 0, ep 94\n",
      "instance 0, ep 95\n",
      "instance 0, ep 96\n",
      "instance 0, ep 97\n",
      "instance 0, ep 98\n",
      "instance 0, ep 99\n",
      "Took 0.018950223922729492 time for inference and 12.458272695541382 time for training\n",
      "3.0558903007848537\n"
     ]
    }
   ],
   "source": [
    "# policy = dqn_with_stablization_steps\n",
    "# name = \"dqn_stable_step\"\n",
    "\n",
    "# print(\"Running DQN Step\")\n",
    "\n",
    "# rewards, memory, simulator = run_multi_seed(seed_list,policy,is_mcts=True,avg_reward=np.mean(results['linear_whittle_reward'][0]),test_length=episode_len,num_samples=1024)\n",
    "# results['{}_reward'.format(name)] = rewards['reward']\n",
    "# results['{}_match'.format(name)] =  rewards['match'] \n",
    "# results['{}_active'.format(name)] = rewards['active_rate']\n",
    "# results['{}_time'.format(name)] =  rewards['time']\n",
    "# print(np.mean(rewards['reward']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acting should always be good! (0, 1) 0.108 < 0.183\n",
      "good start state should always be good! 0.380 < 0.508\n",
      "good start state should always be good! 0.506 < 0.760\n",
      "cohort [43 94  9 64]\n",
      "instance 0, ep 1\n",
      "instance 0, ep 2\n",
      "instance 0, ep 3\n",
      "instance 0, ep 4\n",
      "instance 0, ep 5\n",
      "instance 0, ep 6\n",
      "instance 0, ep 7\n",
      "instance 0, ep 8\n",
      "instance 0, ep 9\n",
      "instance 0, ep 10\n",
      "instance 0, ep 11\n",
      "instance 0, ep 12\n",
      "instance 0, ep 13\n",
      "instance 0, ep 14\n",
      "instance 0, ep 15\n",
      "instance 0, ep 16\n",
      "instance 0, ep 17\n",
      "instance 0, ep 18\n",
      "instance 0, ep 19\n",
      "instance 0, ep 20\n",
      "instance 0, ep 21\n",
      "instance 0, ep 22\n",
      "instance 0, ep 23\n",
      "instance 0, ep 24\n",
      "instance 0, ep 25\n",
      "instance 0, ep 26\n",
      "instance 0, ep 27\n",
      "instance 0, ep 28\n",
      "instance 0, ep 29\n",
      "instance 0, ep 30\n",
      "instance 0, ep 31\n",
      "instance 0, ep 32\n",
      "instance 0, ep 33\n",
      "instance 0, ep 34\n",
      "instance 0, ep 35\n",
      "instance 0, ep 36\n",
      "instance 0, ep 37\n",
      "instance 0, ep 38\n",
      "instance 0, ep 39\n",
      "instance 0, ep 40\n",
      "instance 0, ep 41\n",
      "instance 0, ep 42\n",
      "instance 0, ep 43\n",
      "instance 0, ep 44\n",
      "instance 0, ep 45\n",
      "instance 0, ep 46\n",
      "instance 0, ep 47\n",
      "instance 0, ep 48\n",
      "instance 0, ep 49\n",
      "instance 0, ep 50\n",
      "instance 0, ep 51\n",
      "instance 0, ep 52\n",
      "instance 0, ep 53\n",
      "instance 0, ep 54\n",
      "instance 0, ep 55\n",
      "instance 0, ep 56\n",
      "instance 0, ep 57\n",
      "instance 0, ep 58\n",
      "instance 0, ep 59\n",
      "instance 0, ep 60\n",
      "instance 0, ep 61\n",
      "instance 0, ep 62\n",
      "instance 0, ep 63\n",
      "instance 0, ep 64\n",
      "instance 0, ep 65\n",
      "instance 0, ep 66\n",
      "instance 0, ep 67\n",
      "instance 0, ep 68\n",
      "instance 0, ep 69\n",
      "instance 0, ep 70\n",
      "instance 0, ep 71\n",
      "instance 0, ep 72\n",
      "instance 0, ep 73\n",
      "instance 0, ep 74\n",
      "instance 0, ep 75\n",
      "instance 0, ep 76\n",
      "instance 0, ep 77\n",
      "instance 0, ep 78\n",
      "instance 0, ep 79\n",
      "instance 0, ep 80\n",
      "instance 0, ep 81\n",
      "instance 0, ep 82\n",
      "instance 0, ep 83\n",
      "instance 0, ep 84\n",
      "instance 0, ep 85\n",
      "instance 0, ep 86\n",
      "instance 0, ep 87\n",
      "instance 0, ep 88\n",
      "instance 0, ep 89\n",
      "instance 0, ep 90\n",
      "instance 0, ep 91\n",
      "instance 0, ep 92\n",
      "instance 0, ep 93\n",
      "instance 0, ep 94\n",
      "instance 0, ep 95\n",
      "instance 0, ep 96\n",
      "instance 0, ep 97\n",
      "instance 0, ep 98\n",
      "instance 0, ep 99\n",
      "Took 0.005267143249511719 time for inference and 3.446704626083374 time for training\n",
      "2.9035509595378146\n"
     ]
    }
   ],
   "source": [
    "if n_arms * volunteers_per_arm <= 4:\n",
    "    policy = q_iteration_policy\n",
    "    per_epoch_function = q_iteration_custom_epoch()\n",
    "    name = \"optimal\"\n",
    "\n",
    "    rewards, memory, simulator = run_multi_seed(seed_list,policy,per_epoch_function=per_epoch_function,test_length=episode_len)\n",
    "    results['{}_reward'.format(name)] = rewards['reward']\n",
    "    results['{}_match'.format(name)] =  rewards['match'] \n",
    "    results['{}_active'.format(name)] = rewards['active_rate']\n",
    "    results['{}_time'.format(name)] =  rewards['time']\n",
    "    print(np.mean(rewards['reward']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Write Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path = get_save_path(out_folder,save_name,seed,use_date=save_with_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deleting ../../results/mcts_exploration/rl_exploration/63d9ed7d_44.json\n"
     ]
    }
   ],
   "source": [
    "delete_duplicate_results(out_folder,\"\",results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "json.dump(results,open('../../results/'+save_path,'w'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "food",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
