{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Contextual Policies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analyze the performance of our Whittle and Adaptive Policies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random \n",
    "import matplotlib.pyplot as plt\n",
    "import json \n",
    "import argparse \n",
    "import sys\n",
    "import secrets\n",
    "from itertools import combinations\n",
    "import gurobipy as gp\n",
    "from gurobipy import GRB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/usr0/home/naveenr/projects/food_rescue_preferences')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rmab.simulator import run_multi_seed\n",
    "from rmab.whittle_policies import *\n",
    "from rmab.baseline_policies import *\n",
    "from rmab.mcts_policies import *\n",
    "from rmab.occupancy_policies import *\n",
    "from rmab.utils import get_save_path, delete_duplicate_results, restrict_resources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "is_jupyter = 'ipykernel' in sys.modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "if is_jupyter: \n",
    "    seed        = 44\n",
    "    n_arms      = 10\n",
    "    volunteers_per_arm = 1\n",
    "    budget      = 2\n",
    "    discount    = 0.9\n",
    "    alpha       = 3 \n",
    "    n_episodes  = 30\n",
    "    episode_len = 50 \n",
    "    n_epochs    = 1\n",
    "    save_with_date = False \n",
    "    lamb = 0.5\n",
    "    prob_distro = 'uniform'\n",
    "    reward_type = \"probability_context\"\n",
    "    reward_parameters = {'universe_size': 20, 'arm_set_low': 0, 'arm_set_high': 1}\n",
    "    out_folder = 'unknown_parameters'\n",
    "    time_limit = 100\n",
    "    use_context = True\n",
    "else:\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument('--n_arms',         '-N', help='num beneficiaries (arms)', type=int, default=2)\n",
    "    parser.add_argument('--volunteers_per_arm',         '-V', help='volunteers per arm', type=int, default=5)\n",
    "    parser.add_argument('--episode_len',    '-H', help='episode length', type=int, default=50)\n",
    "    parser.add_argument('--n_episodes',     '-T', help='num episodes', type=int, default=30)\n",
    "    parser.add_argument('--budget',         '-B', help='budget', type=int, default=3)\n",
    "    parser.add_argument('--n_epochs',       '-E', help='number of epochs (num_repeats)', type=int, default=1)\n",
    "    parser.add_argument('--discount',       '-d', help='discount factor', type=float, default=0.9)\n",
    "    parser.add_argument('--alpha',          '-a', help='alpha: for conf radius', type=float, default=3)\n",
    "    parser.add_argument('--lamb',          '-l', help='lambda for matching-engagement tradeoff', type=float, default=0.5)\n",
    "    parser.add_argument('--universe_size', help='For set cover, total num unvierse elems', type=int, default=10)\n",
    "    parser.add_argument('--arm_set_low', help='Least size of arm set, for set cover', type=float, default=3)\n",
    "    parser.add_argument('--arm_set_high', help='Largest size of arm set, for set cover', type=float, default=6)\n",
    "    parser.add_argument('--reward_type',          '-r', help='Which type of custom reward', type=str, default='set_cover')\n",
    "    parser.add_argument('--seed',           '-s', help='random seed', type=int, default=42)\n",
    "    parser.add_argument('--prob_distro',           '-p', help='which prob distro [uniform,uniform_small,uniform_large,normal]', type=str, default='uniform')\n",
    "    parser.add_argument('--out_folder', help='Which folder to write results to', type=str, default='iterative')\n",
    "    parser.add_argument('--time_limit', help='Online time limit for computation', type=float, default=100)\n",
    "    parser.add_argument('--use_date', action='store_true')\n",
    "\n",
    "    args = parser.parse_args()\n",
    "\n",
    "    n_arms      = args.n_arms\n",
    "    volunteers_per_arm = args.volunteers_per_arm\n",
    "    budget      = args.budget\n",
    "    discount    = args.discount\n",
    "    alpha       = args.alpha \n",
    "    seed        = args.seed\n",
    "    n_episodes  = args.n_episodes\n",
    "    episode_len = args.episode_len\n",
    "    n_epochs    = args.n_epochs\n",
    "    lamb = args.lamb\n",
    "    save_with_date = args.use_date\n",
    "    prob_distro = args.prob_distro\n",
    "    out_folder = args.out_folder\n",
    "    reward_type = args.reward_type\n",
    "    reward_parameters = {'universe_size': args.universe_size,\n",
    "                        'arm_set_low': args.arm_set_low, \n",
    "                        'arm_set_high': args.arm_set_high}\n",
    "    time_limit = args.time_limit \n",
    "    context_dim = n_arms*volunteers_per_arm\n",
    "\n",
    "save_name = secrets.token_hex(4)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = {}\n",
    "results['parameters'] = {'seed'      : seed,\n",
    "        'n_arms'    : n_arms,\n",
    "        'volunteers_per_arm': volunteers_per_arm, \n",
    "        'budget'    : budget,\n",
    "        'discount'  : discount, \n",
    "        'alpha'     : alpha, \n",
    "        'n_episodes': n_episodes, \n",
    "        'episode_len': episode_len, \n",
    "        'n_epochs'  : n_epochs, \n",
    "        'lamb': lamb,\n",
    "        'prob_distro': prob_distro, \n",
    "        'reward_type': reward_type, \n",
    "        'universe_size': reward_parameters['universe_size'],\n",
    "        'arm_set_low': reward_parameters['arm_set_low'], \n",
    "        'arm_set_high': reward_parameters['arm_set_high'],\n",
    "        'time_limit': time_limit, \n",
    "        'use_context': use_context\n",
    "        } "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Occupancy Measure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_list = [seed]\n",
    "restrict_resources()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cohort [ 6 61 24 28 93  0 91 23 74 73]\n",
      "instance 0, ep 1\n",
      "instance 0, ep 2\n",
      "instance 0, ep 3\n",
      "instance 0, ep 4\n",
      "instance 0, ep 5\n",
      "instance 0, ep 6\n",
      "instance 0, ep 7\n",
      "instance 0, ep 8\n",
      "instance 0, ep 9\n",
      "instance 0, ep 10\n",
      "instance 0, ep 11\n",
      "instance 0, ep 12\n",
      "instance 0, ep 13\n",
      "instance 0, ep 14\n",
      "instance 0, ep 15\n",
      "instance 0, ep 16\n",
      "instance 0, ep 17\n",
      "instance 0, ep 18\n",
      "instance 0, ep 19\n",
      "instance 0, ep 20\n",
      "instance 0, ep 21\n",
      "instance 0, ep 22\n",
      "instance 0, ep 23\n",
      "instance 0, ep 24\n",
      "instance 0, ep 25\n",
      "instance 0, ep 26\n",
      "instance 0, ep 27\n",
      "instance 0, ep 28\n",
      "instance 0, ep 29\n",
      "Took 0.5036983489990234 time for inference and 0.0004925727844238281 time for training\n",
      "0.30208567105994144\n"
     ]
    }
   ],
   "source": [
    "policy = random_policy\n",
    "name = \"random\"\n",
    "\n",
    "rewards, memory, simulator = run_multi_seed(seed_list,policy,results['parameters'],test_length=episode_len*(n_episodes%50))\n",
    "results['{}_reward'.format(name)] = rewards['reward']\n",
    "results['{}_match'.format(name)] =  rewards['match'] \n",
    "results['{}_active'.format(name)] = rewards['active_rate']\n",
    "results['{}_time'.format(name)] =  rewards['time']\n",
    "print(np.mean(rewards['reward']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cohort [ 6 61 24 28 93  0 91 23 74 73]\n",
      "instance 0, ep 1\n",
      "instance 0, ep 2\n",
      "instance 0, ep 3\n",
      "instance 0, ep 4\n",
      "instance 0, ep 5\n",
      "instance 0, ep 6\n",
      "instance 0, ep 7\n",
      "instance 0, ep 8\n",
      "instance 0, ep 9\n",
      "instance 0, ep 10\n",
      "instance 0, ep 11\n",
      "instance 0, ep 12\n",
      "instance 0, ep 13\n",
      "instance 0, ep 14\n",
      "instance 0, ep 15\n",
      "instance 0, ep 16\n",
      "instance 0, ep 17\n",
      "instance 0, ep 18\n",
      "instance 0, ep 19\n",
      "instance 0, ep 20\n",
      "instance 0, ep 21\n",
      "instance 0, ep 22\n",
      "instance 0, ep 23\n",
      "instance 0, ep 24\n",
      "instance 0, ep 25\n",
      "instance 0, ep 26\n",
      "instance 0, ep 27\n",
      "instance 0, ep 28\n",
      "instance 0, ep 29\n",
      "Took 0.9506993293762207 time for inference and 0.0007562637329101562 time for training\n",
      "0.42782865635924355\n"
     ]
    }
   ],
   "source": [
    "policy = greedy_policy\n",
    "name = \"greedy\"\n",
    "\n",
    "rewards, memory, simulator = run_multi_seed(seed_list,policy,results['parameters'],test_length=episode_len*(n_episodes%50))\n",
    "results['{}_reward'.format(name)] = rewards['reward']\n",
    "results['{}_match'.format(name)] =  rewards['match'] \n",
    "results['{}_active'.format(name)] = rewards['active_rate']\n",
    "results['{}_time'.format(name)] =  rewards['time']\n",
    "print(np.mean(rewards['reward']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "if n_arms * volunteers_per_arm <= 4:\n",
    "    policy = q_iteration_policy\n",
    "    per_epoch_function = q_iteration_custom_epoch()\n",
    "    name = \"optimal\"\n",
    "\n",
    "    rewards, memory, simulator = run_multi_seed(seed_list,policy,results['parameters'],per_epoch_function=per_epoch_function,test_length=episode_len*(n_episodes%50))\n",
    "    results['{}_reward'.format(name)] = rewards['reward']\n",
    "    results['{}_match'.format(name)] =  rewards['match'] \n",
    "    results['{}_active'.format(name)] = rewards['active_rate']\n",
    "    results['{}_time'.format(name)] =  rewards['time']\n",
    "    print(np.mean(rewards['reward']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cohort [ 6 61 24 28 93  0 91 23 74 73]\n",
      "Match probs [0.6464105624033935, 0.028544667945797242, 0.03768029232900816, 0.0182551076829518, 0.6273932545535863, 0.8348421486656494, 0.9969792586179441, 0.01585780035126383, 0.9327638698856681, 0.6415666006071534]\n",
      "instance 0, ep 1\n",
      "instance 0, ep 2\n",
      "instance 0, ep 3\n",
      "instance 0, ep 4\n",
      "instance 0, ep 5\n",
      "instance 0, ep 6\n",
      "instance 0, ep 7\n",
      "instance 0, ep 8\n",
      "instance 0, ep 9\n",
      "instance 0, ep 10\n",
      "instance 0, ep 11\n",
      "instance 0, ep 12\n",
      "instance 0, ep 13\n",
      "instance 0, ep 14\n",
      "instance 0, ep 15\n",
      "instance 0, ep 16\n",
      "instance 0, ep 17\n",
      "instance 0, ep 18\n",
      "instance 0, ep 19\n",
      "instance 0, ep 20\n",
      "instance 0, ep 21\n",
      "instance 0, ep 22\n",
      "instance 0, ep 23\n",
      "instance 0, ep 24\n",
      "instance 0, ep 25\n",
      "instance 0, ep 26\n",
      "instance 0, ep 27\n",
      "instance 0, ep 28\n",
      "instance 0, ep 29\n",
      "Took 0.7975940704345703 time for inference and 0.001750946044921875 time for training\n",
      "0.42560622109522167\n"
     ]
    }
   ],
   "source": [
    "if n_arms * volunteers_per_arm <= 1000:\n",
    "    policy = whittle_policy \n",
    "    name = \"linear_whittle\"\n",
    "\n",
    "    rewards, memory, simulator = run_multi_seed(seed_list,policy,results['parameters'],test_length=episode_len*(n_episodes%50),shapley_iterations=1000)\n",
    "    results['{}_reward'.format(name)] = rewards['reward']\n",
    "    results['{}_match'.format(name)] =  rewards['match'] \n",
    "    results['{}_active'.format(name)] = rewards['active_rate']\n",
    "    results['{}_time'.format(name)] =  rewards['time']\n",
    "    print(np.mean(rewards['reward']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cohort [ 6 61 24 28 93  0 91 23 74 73]\n",
      "instance 0, ep 1\n",
      "instance 0, ep 2\n",
      "instance 0, ep 3\n",
      "instance 0, ep 4\n",
      "instance 0, ep 5\n",
      "instance 0, ep 6\n",
      "instance 0, ep 7\n",
      "instance 0, ep 8\n",
      "instance 0, ep 9\n",
      "instance 0, ep 10\n",
      "instance 0, ep 11\n",
      "instance 0, ep 12\n",
      "instance 0, ep 13\n",
      "instance 0, ep 14\n",
      "instance 0, ep 15\n",
      "instance 0, ep 16\n",
      "instance 0, ep 17\n",
      "instance 0, ep 18\n",
      "instance 0, ep 19\n",
      "instance 0, ep 20\n",
      "instance 0, ep 21\n",
      "instance 0, ep 22\n",
      "instance 0, ep 23\n",
      "instance 0, ep 24\n",
      "instance 0, ep 25\n",
      "instance 0, ep 26\n",
      "instance 0, ep 27\n",
      "instance 0, ep 28\n",
      "instance 0, ep 29\n",
      "Took 0.7736258506774902 time for inference and 0.2330608367919922 time for training\n",
      "0.42560622109522167\n"
     ]
    }
   ],
   "source": [
    "if n_arms * volunteers_per_arm <= 1000:\n",
    "    policy = shapley_whittle_custom_policy \n",
    "    name = \"shapley_whittle_custom\"\n",
    "\n",
    "    rewards, memory, simulator = run_multi_seed(seed_list,policy,results['parameters'],test_length=episode_len*(n_episodes%50),shapley_iterations=1000)\n",
    "    results['{}_reward'.format(name)] = rewards['reward']\n",
    "    results['{}_match'.format(name)] =  rewards['match'] \n",
    "    results['{}_active'.format(name)] = rewards['active_rate']\n",
    "    results['{}_time'.format(name)] =  rewards['time']\n",
    "    print(np.mean(rewards['reward']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cohort [ 6 61 24 28 93  0 91 23 74 73]\n",
      "instance 0, ep 1\n",
      "instance 0, ep 2\n",
      "instance 0, ep 3\n",
      "instance 0, ep 4\n",
      "instance 0, ep 5\n",
      "instance 0, ep 6\n",
      "instance 0, ep 7\n",
      "instance 0, ep 8\n",
      "instance 0, ep 9\n",
      "instance 0, ep 10\n",
      "instance 0, ep 11\n",
      "instance 0, ep 12\n",
      "instance 0, ep 13\n",
      "instance 0, ep 14\n",
      "instance 0, ep 15\n",
      "instance 0, ep 16\n",
      "instance 0, ep 17\n",
      "instance 0, ep 18\n",
      "instance 0, ep 19\n",
      "instance 0, ep 20\n",
      "instance 0, ep 21\n",
      "instance 0, ep 22\n",
      "instance 0, ep 23\n",
      "instance 0, ep 24\n",
      "instance 0, ep 25\n",
      "instance 0, ep 26\n",
      "instance 0, ep 27\n",
      "instance 0, ep 28\n",
      "instance 0, ep 29\n",
      "Took 0.8108088970184326 time for inference and 0.028658628463745117 time for training\n",
      "0.42842611350033244\n"
     ]
    }
   ],
   "source": [
    "if n_arms * volunteers_per_arm <= 1000:\n",
    "    policy = regression_policy \n",
    "    name = \"regression_whittle\"\n",
    "\n",
    "    rewards, memory, simulator = run_multi_seed(seed_list,policy,results['parameters'],test_length=episode_len*(n_episodes%50),shapley_iterations=1000)\n",
    "    results['{}_reward'.format(name)] = rewards['reward']\n",
    "    results['{}_match'.format(name)] =  rewards['match'] \n",
    "    results['{}_active'.format(name)] = rewards['active_rate']\n",
    "    results['{}_time'.format(name)] =  rewards['time']\n",
    "    print(np.mean(rewards['reward']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cohort [ 6 61 24 28 93  0 91 23 74 73]\n",
      "instance 0, ep 1\n",
      "instance 0, ep 2\n",
      "instance 0, ep 3\n",
      "instance 0, ep 4\n",
      "instance 0, ep 5\n",
      "instance 0, ep 6\n",
      "instance 0, ep 7\n",
      "instance 0, ep 8\n",
      "instance 0, ep 9\n",
      "instance 0, ep 10\n",
      "instance 0, ep 11\n",
      "instance 0, ep 12\n",
      "instance 0, ep 13\n",
      "instance 0, ep 14\n",
      "instance 0, ep 15\n",
      "instance 0, ep 16\n",
      "instance 0, ep 17\n",
      "instance 0, ep 18\n",
      "instance 0, ep 19\n",
      "instance 0, ep 20\n",
      "instance 0, ep 21\n",
      "instance 0, ep 22\n",
      "instance 0, ep 23\n",
      "instance 0, ep 24\n",
      "instance 0, ep 25\n",
      "instance 0, ep 26\n",
      "instance 0, ep 27\n",
      "instance 0, ep 28\n",
      "instance 0, ep 29\n",
      "Took 3.0176427364349365 time for inference and 0.10313963890075684 time for training\n",
      "0.42448692078557165\n"
     ]
    }
   ],
   "source": [
    "if n_arms * volunteers_per_arm <= 1000:\n",
    "    policy = occupancy_measure_linear \n",
    "    name = \"occupancy_measure_linear\"\n",
    "\n",
    "    rewards, memory, simulator = run_multi_seed(seed_list,policy,results['parameters'],test_length=episode_len*(n_episodes%50),shapley_iterations=1000)\n",
    "    results['{}_reward'.format(name)] = rewards['reward']\n",
    "    results['{}_match'.format(name)] =  rewards['match'] \n",
    "    results['{}_active'.format(name)] = rewards['active_rate']\n",
    "    results['{}_time'.format(name)] =  rewards['time']\n",
    "    print(np.mean(rewards['reward']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cohort [ 6 61 24 28 93  0 91 23 74 73]\n",
      "instance 0, ep 1\n",
      "instance 0, ep 2\n",
      "instance 0, ep 3\n",
      "instance 0, ep 4\n",
      "instance 0, ep 5\n",
      "instance 0, ep 6\n",
      "instance 0, ep 7\n",
      "instance 0, ep 8\n",
      "instance 0, ep 9\n",
      "instance 0, ep 10\n",
      "instance 0, ep 11\n",
      "instance 0, ep 12\n",
      "instance 0, ep 13\n",
      "instance 0, ep 14\n",
      "instance 0, ep 15\n",
      "instance 0, ep 16\n",
      "instance 0, ep 17\n",
      "instance 0, ep 18\n",
      "instance 0, ep 19\n",
      "instance 0, ep 20\n",
      "instance 0, ep 21\n",
      "instance 0, ep 22\n",
      "instance 0, ep 23\n",
      "instance 0, ep 24\n",
      "instance 0, ep 25\n",
      "instance 0, ep 26\n",
      "instance 0, ep 27\n",
      "instance 0, ep 28\n",
      "instance 0, ep 29\n",
      "Took 2.9885637760162354 time for inference and 0.2987332344055176 time for training\n",
      "0.42448692078557165\n"
     ]
    }
   ],
   "source": [
    "if n_arms * volunteers_per_arm <= 1000:\n",
    "    policy = occupancy_measure_shapley \n",
    "    name = \"occupancy_measure_shapley\"\n",
    "\n",
    "    rewards, memory, simulator = run_multi_seed(seed_list,policy,results['parameters'],test_length=episode_len*(n_episodes%50),shapley_iterations=1000)\n",
    "    results['{}_reward'.format(name)] = rewards['reward']\n",
    "    results['{}_match'.format(name)] =  rewards['match'] \n",
    "    results['{}_active'.format(name)] = rewards['active_rate']\n",
    "    results['{}_time'.format(name)] =  rewards['time']\n",
    "    print(np.mean(rewards['reward']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cohort [ 6 61 24 28 93  0 91 23 74 73]\n",
      "instance 0, ep 1\n",
      "instance 0, ep 2\n",
      "instance 0, ep 3\n",
      "instance 0, ep 4\n",
      "instance 0, ep 5\n",
      "instance 0, ep 6\n",
      "instance 0, ep 7\n",
      "instance 0, ep 8\n",
      "instance 0, ep 9\n",
      "instance 0, ep 10\n",
      "instance 0, ep 11\n",
      "instance 0, ep 12\n",
      "instance 0, ep 13\n",
      "instance 0, ep 14\n",
      "instance 0, ep 15\n",
      "instance 0, ep 16\n",
      "instance 0, ep 17\n",
      "instance 0, ep 18\n",
      "instance 0, ep 19\n",
      "instance 0, ep 20\n",
      "instance 0, ep 21\n",
      "instance 0, ep 22\n",
      "instance 0, ep 23\n",
      "instance 0, ep 24\n",
      "instance 0, ep 25\n",
      "instance 0, ep 26\n",
      "instance 0, ep 27\n",
      "instance 0, ep 28\n",
      "instance 0, ep 29\n",
      "Took 120.44960165023804 time for inference and 0.00046515464782714844 time for training\n",
      "0.42993704852947645\n"
     ]
    }
   ],
   "source": [
    "if n_arms * volunteers_per_arm <= 1000 and use_context:\n",
    "    policy = occupancy_measure_shapley_contextual \n",
    "    name = \"occupancy_measure_shapley\"\n",
    "\n",
    "    rewards, memory, simulator = run_multi_seed(seed_list,policy,results['parameters'],test_length=episode_len*(n_episodes%50),shapley_iterations=1000)\n",
    "    results['{}_reward'.format(name)] = rewards['reward']\n",
    "    results['{}_match'.format(name)] =  rewards['match'] \n",
    "    results['{}_active'.format(name)] = rewards['active_rate']\n",
    "    results['{}_time'.format(name)] =  rewards['time']\n",
    "    print(np.mean(rewards['reward']))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cohort [ 6 61 24 28 93  0 91 23 74 73]\n",
      "instance 0, ep 1\n",
      "Mem [0.20207827 0.20569939 0.10015009 0.04658524 0.29079465 0.27838352\n",
      " 0.         0.36037708 0.         0.38698717]\n",
      "Real [0.46098838 0.12496121 0.12931173 0.12008338 0.4493804  0.58034846\n",
      " 0.68936815 0.1189503  0.64549157 0.45802404]\n",
      "14 0.1519153007688595\n",
      "instance 0, ep 2\n",
      "Mem [2.02078267e-01 2.29597727e-01 1.00150089e-01 3.46360758e-02\n",
      " 3.14692983e-01 3.02281854e-01 1.38777878e-17 3.00631244e-01\n",
      " 1.26291969e-01 3.39190505e-01]\n",
      "Real [0.46098838 0.12496121 0.12931173 0.12008338 0.4493804  0.58034846\n",
      " 0.68936815 0.1189503  0.64549157 0.45802404]\n",
      "16 0.27444517168932864\n",
      "instance 0, ep 3\n",
      "Mem [2.02078267e-01 2.46540910e-01 1.00150089e-01 5.49678959e-02\n",
      " 2.74029343e-01 3.19225038e-01 4.85722573e-17 3.25481247e-01\n",
      " 1.60178336e-01 3.05304138e-01]\n",
      "Real [0.46098838 0.12496121 0.12931173 0.12008338 0.4493804  0.58034846\n",
      " 0.68936815 0.1189503  0.64549157 0.45802404]\n",
      "17 0.1989313331516097\n",
      "instance 0, ep 4\n",
      "Mem [ 2.02078267e-01  2.32112847e-01  1.00150089e-01  5.09877404e-02\n",
      "  2.81989654e-01  2.38129369e-01 -6.93889390e-18  2.68764030e-01\n",
      "  1.31322208e-01  3.34160266e-01]\n",
      "Real [0.46098838 0.12496121 0.12931173 0.12008338 0.4493804  0.58034846\n",
      " 0.68936815 0.1189503  0.64549157 0.45802404]\n",
      "18 0.19582183665221725\n",
      "instance 0, ep 5\n",
      "Mem [ 2.02078267e-01  2.32112847e-01  1.00150089e-01  5.09877404e-02\n",
      "  2.81989654e-01  2.38129369e-01 -6.93889390e-18  2.68764030e-01\n",
      "  1.31322208e-01  3.34160266e-01]\n",
      "Real [0.46098838 0.12496121 0.12931173 0.12008338 0.4493804  0.58034846\n",
      " 0.68936815 0.1189503  0.64549157 0.45802404]\n",
      "18 0.2594913408852023\n",
      "instance 0, ep 6\n",
      "Mem [ 2.02078267e-01  2.32112847e-01  1.00150089e-01  5.09877404e-02\n",
      "  2.81989654e-01  2.38129369e-01 -6.93889390e-18  2.68764030e-01\n",
      "  1.31322208e-01  3.34160266e-01]\n",
      "Real [0.46098838 0.12496121 0.12931173 0.12008338 0.4493804  0.58034846\n",
      " 0.68936815 0.1189503  0.64549157 0.45802404]\n",
      "18 0.2594913408852023\n",
      "instance 0, ep 7\n",
      "Mem [ 2.02078267e-01  2.32112847e-01  1.00150089e-01  5.09877404e-02\n",
      "  2.81989654e-01  2.38129369e-01 -6.93889390e-18  2.68764030e-01\n",
      "  1.31322208e-01  3.34160266e-01]\n",
      "Real [0.46098838 0.12496121 0.12931173 0.12008338 0.4493804  0.58034846\n",
      " 0.68936815 0.1189503  0.64549157 0.45802404]\n",
      "18 0.2509589222322343\n",
      "instance 0, ep 8\n",
      "Mem [ 2.02078267e-01  2.32112847e-01  1.00150089e-01  5.09877404e-02\n",
      "  2.81989654e-01  2.38129369e-01 -6.93889390e-18  2.68764030e-01\n",
      "  1.31322208e-01  3.34160266e-01]\n",
      "Real [0.46098838 0.12496121 0.12931173 0.12008338 0.4493804  0.58034846\n",
      " 0.68936815 0.1189503  0.64549157 0.45802404]\n",
      "18 0.2509589222322343\n",
      "instance 0, ep 9\n",
      "Mem [2.02078267e-01 2.46326749e-01 1.00150089e-01 4.73842157e-02\n",
      " 2.89196704e-01 2.46537593e-01 6.93889390e-18 2.71967163e-01\n",
      " 2.68856732e-01 3.05732460e-01]\n",
      "Real [0.46098838 0.12496121 0.12931173 0.12008338 0.4493804  0.58034846\n",
      " 0.68936815 0.1189503  0.64549157 0.45802404]\n",
      "19 0.23914132576931282\n",
      "instance 0, ep 10\n",
      "Mem [ 2.02078267e-01  1.51604890e-01  1.00150089e-01  4.87384066e-02\n",
      "  2.86488322e-01  1.68082763e-01 -1.38777878e-17  2.84848716e-01\n",
      "  2.54038230e-01  3.35369464e-01]\n",
      "Real [0.46098838 0.12496121 0.12931173 0.12008338 0.4493804  0.58034846\n",
      " 0.68936815 0.1189503  0.64549157 0.45802404]\n",
      "21 0.2231818746343957\n",
      "instance 0, ep 11\n",
      "Mem [ 2.02078267e-01  1.51604890e-01  1.00150089e-01  4.87384066e-02\n",
      "  2.86488322e-01  1.68082763e-01 -1.38777878e-17  2.84848716e-01\n",
      "  2.54038230e-01  3.35369464e-01]\n",
      "Real [0.46098838 0.12496121 0.12931173 0.12008338 0.4493804  0.58034846\n",
      " 0.68936815 0.1189503  0.64549157 0.45802404]\n",
      "21 0.21072460235927254\n",
      "instance 0, ep 12\n",
      "Mem [ 2.02078267e-01  1.51604890e-01  1.00150089e-01  4.87384066e-02\n",
      "  2.86488322e-01  1.68082763e-01 -1.38777878e-17  2.84848716e-01\n",
      "  2.54038230e-01  3.35369464e-01]\n",
      "Real [0.46098838 0.12496121 0.12931173 0.12008338 0.4493804  0.58034846\n",
      " 0.68936815 0.1189503  0.64549157 0.45802404]\n",
      "21 0.21072460235927254\n",
      "instance 0, ep 13\n",
      "Mem [ 2.02078267e-01  1.51604890e-01  1.00150089e-01  4.87384066e-02\n",
      "  2.86488322e-01  1.68082763e-01 -1.38777878e-17  2.84848716e-01\n",
      "  2.54038230e-01  3.35369464e-01]\n",
      "Real [0.46098838 0.12496121 0.12931173 0.12008338 0.4493804  0.58034846\n",
      " 0.68936815 0.1189503  0.64549157 0.45802404]\n",
      "21 0.21072460235927254\n",
      "instance 0, ep 14\n",
      "Mem [ 2.02078267e-01  1.51604890e-01  1.00150089e-01  4.87384066e-02\n",
      "  2.86488322e-01  1.68082763e-01 -1.38777878e-17  2.84848716e-01\n",
      "  2.54038230e-01  3.35369464e-01]\n",
      "Real [0.46098838 0.12496121 0.12931173 0.12008338 0.4493804  0.58034846\n",
      " 0.68936815 0.1189503  0.64549157 0.45802404]\n",
      "21 0.15048169112804435\n",
      "instance 0, ep 15\n",
      "Mem [ 2.02078267e-01  1.51604890e-01  1.00150089e-01  4.87384066e-02\n",
      "  2.86488322e-01  1.68082763e-01 -1.38777878e-17  2.84848716e-01\n",
      "  2.54038230e-01  3.35369464e-01]\n",
      "Real [0.46098838 0.12496121 0.12931173 0.12008338 0.4493804  0.58034846\n",
      " 0.68936815 0.1189503  0.64549157 0.45802404]\n",
      "21 0.21072460235927254\n",
      "instance 0, ep 16\n",
      "Mem [ 2.02078267e-01  1.51604890e-01  1.00150089e-01  4.87384066e-02\n",
      "  2.86488322e-01  1.68082763e-01 -1.38777878e-17  2.84848716e-01\n",
      "  2.54038230e-01  3.35369464e-01]\n",
      "Real [0.46098838 0.12496121 0.12931173 0.12008338 0.4493804  0.58034846\n",
      " 0.68936815 0.1189503  0.64549157 0.45802404]\n",
      "21 0.21072460235927254\n",
      "instance 0, ep 17\n",
      "Mem [ 2.02078267e-01  1.51604890e-01  1.00150089e-01  4.87384066e-02\n",
      "  2.86488322e-01  1.68082763e-01 -1.38777878e-17  2.84848716e-01\n",
      "  2.54038230e-01  3.35369464e-01]\n",
      "Real [0.46098838 0.12496121 0.12931173 0.12008338 0.4493804  0.58034846\n",
      " 0.68936815 0.1189503  0.64549157 0.45802404]\n",
      "21 0.15048169112804435\n",
      "instance 0, ep 18\n",
      "Mem [ 2.02078267e-01  1.51604890e-01  1.00150089e-01  4.87384066e-02\n",
      "  2.86488322e-01  1.68082763e-01 -1.38777878e-17  2.84848716e-01\n",
      "  2.54038230e-01  3.35369464e-01]\n",
      "Real [0.46098838 0.12496121 0.12931173 0.12008338 0.4493804  0.58034846\n",
      " 0.68936815 0.1189503  0.64549157 0.45802404]\n",
      "21 0.21072460235927254\n",
      "instance 0, ep 19\n",
      "Mem [ 2.02078267e-01  1.51604890e-01  1.00150089e-01  4.87384066e-02\n",
      "  2.86488322e-01  1.68082763e-01 -1.38777878e-17  2.84848716e-01\n",
      "  2.54038230e-01  3.35369464e-01]\n",
      "Real [0.46098838 0.12496121 0.12931173 0.12008338 0.4493804  0.58034846\n",
      " 0.68936815 0.1189503  0.64549157 0.45802404]\n",
      "21 0.15048169112804435\n",
      "instance 0, ep 20\n",
      "Mem [ 2.02078267e-01  1.51604890e-01  1.00150089e-01  4.87384066e-02\n",
      "  2.86488322e-01  1.68082763e-01 -1.38777878e-17  2.84848716e-01\n",
      "  2.54038230e-01  3.35369464e-01]\n",
      "Real [0.46098838 0.12496121 0.12931173 0.12008338 0.4493804  0.58034846\n",
      " 0.68936815 0.1189503  0.64549157 0.45802404]\n",
      "21 0.15048169112804435\n",
      "instance 0, ep 21\n",
      "Mem [ 2.02078267e-01  1.51604890e-01  1.00150089e-01  4.87384066e-02\n",
      "  2.86488322e-01  1.68082763e-01 -1.38777878e-17  2.84848716e-01\n",
      "  2.54038230e-01  3.35369464e-01]\n",
      "Real [0.46098838 0.12496121 0.12931173 0.12008338 0.4493804  0.58034846\n",
      " 0.68936815 0.1189503  0.64549157 0.45802404]\n",
      "21 0.21072460235927254\n",
      "instance 0, ep 22\n",
      "Mem [ 2.02078267e-01  1.51604890e-01  1.00150089e-01  4.87384066e-02\n",
      "  2.86488322e-01  1.68082763e-01 -1.38777878e-17  2.84848716e-01\n",
      "  2.54038230e-01  3.35369464e-01]\n",
      "Real [0.46098838 0.12496121 0.12931173 0.12008338 0.4493804  0.58034846\n",
      " 0.68936815 0.1189503  0.64549157 0.45802404]\n",
      "21 0.21072460235927254\n",
      "instance 0, ep 23\n",
      "Mem [ 2.02078267e-01  1.51604890e-01  1.00150089e-01  4.87384066e-02\n",
      "  2.86488322e-01  1.68082763e-01 -1.38777878e-17  2.84848716e-01\n",
      "  2.54038230e-01  3.35369464e-01]\n",
      "Real [0.46098838 0.12496121 0.12931173 0.12008338 0.4493804  0.58034846\n",
      " 0.68936815 0.1189503  0.64549157 0.45802404]\n",
      "21 0.15048169112804435\n",
      "instance 0, ep 24\n",
      "Mem [ 2.02078267e-01  1.51604890e-01  1.00150089e-01  4.87384066e-02\n",
      "  2.86488322e-01  1.68082763e-01 -1.38777878e-17  2.84848716e-01\n",
      "  2.54038230e-01  3.35369464e-01]\n",
      "Real [0.46098838 0.12496121 0.12931173 0.12008338 0.4493804  0.58034846\n",
      " 0.68936815 0.1189503  0.64549157 0.45802404]\n",
      "21 0.21072460235927254\n",
      "instance 0, ep 25\n",
      "Mem [ 2.02078267e-01  1.51604890e-01  1.00150089e-01  4.87384066e-02\n",
      "  2.86488322e-01  1.68082763e-01 -1.38777878e-17  2.84848716e-01\n",
      "  2.54038230e-01  3.35369464e-01]\n",
      "Real [0.46098838 0.12496121 0.12931173 0.12008338 0.4493804  0.58034846\n",
      " 0.68936815 0.1189503  0.64549157 0.45802404]\n",
      "21 0.15048169112804435\n",
      "instance 0, ep 26\n",
      "Mem [ 2.02078267e-01  1.51604890e-01  1.00150089e-01  4.87384066e-02\n",
      "  2.86488322e-01  1.68082763e-01 -1.38777878e-17  2.84848716e-01\n",
      "  2.54038230e-01  3.35369464e-01]\n",
      "Real [0.46098838 0.12496121 0.12931173 0.12008338 0.4493804  0.58034846\n",
      " 0.68936815 0.1189503  0.64549157 0.45802404]\n",
      "21 0.21072460235927254\n",
      "instance 0, ep 27\n",
      "Mem [ 2.12783366e-01  1.51032479e-01  9.47975394e-02  4.89794220e-02\n",
      "  2.86006291e-01  1.67540478e-01 -6.93889390e-18  2.84276304e-01\n",
      "  2.52381250e-01  3.38683425e-01]\n",
      "Real [0.46098838 0.12496121 0.12931173 0.12008338 0.4493804  0.58034846\n",
      " 0.68936815 0.1189503  0.64549157 0.45802404]\n",
      "22 0.21787121149309302\n",
      "instance 0, ep 28\n",
      "Mem [ 2.12783366e-01  1.51032479e-01  9.47975394e-02  4.89794220e-02\n",
      "  2.86006291e-01  1.67540478e-01 -6.93889390e-18  2.84276304e-01\n",
      "  2.52381250e-01  3.38683425e-01]\n",
      "Real [0.46098838 0.12496121 0.12931173 0.12008338 0.4493804  0.58034846\n",
      " 0.68936815 0.1189503  0.64549157 0.45802404]\n",
      "22 0.21787121149309302\n",
      "instance 0, ep 29\n",
      "Mem [ 2.12783366e-01  1.51032479e-01  9.47975394e-02  4.89794220e-02\n",
      "  2.86006291e-01  1.67540478e-01 -6.93889390e-18  2.84276304e-01\n",
      "  2.52381250e-01  3.38683425e-01]\n",
      "Real [0.46098838 0.12496121 0.12931173 0.12008338 0.4493804  0.58034846\n",
      " 0.68936815 0.1189503  0.64549157 0.45802404]\n",
      "22 0.149346910442687\n",
      "Took 10.827899932861328 time for inference and 0.0005021095275878906 time for training\n",
      "0.4024041800301705\n"
     ]
    }
   ],
   "source": [
    "if n_arms * volunteers_per_arm <= 1000:\n",
    "    policy = occupancy_measure_learn_shapley \n",
    "    name = \"occupancy_measure_learn_shapley\"\n",
    "\n",
    "    rewards, memory, simulator = run_multi_seed(seed_list,policy,results['parameters'],test_length=episode_len*(n_episodes%50),shapley_iterations=1000)\n",
    "    results['{}_reward'.format(name)] = rewards['reward']\n",
    "    results['{}_match'.format(name)] =  rewards['match'] \n",
    "    results['{}_active'.format(name)] = rewards['active_rate']\n",
    "    results['{}_time'.format(name)] =  rewards['time']\n",
    "    results['{}_predicted_regression'.format(name)] = list(simulator.predicted_regression)\n",
    "    results['{}_actual_regression'.format(name)] = list(simulator.actual_regression)\n",
    "    print(np.mean(rewards['reward']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f93771fb8e0>]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(np.cumsum(results['regression_whittle_reward']) - np.cumsum(results['occupancy_measure_learn_shapley_reward']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cohort [ 6 61 24 28 93  0 91 23 74 73]\n",
      "instance 0, ep 1\n",
      "instance 0, ep 2\n",
      "instance 0, ep 3\n",
      "instance 0, ep 4\n",
      "instance 0, ep 5\n",
      "instance 0, ep 6\n",
      "instance 0, ep 7\n",
      "instance 0, ep 8\n",
      "instance 0, ep 9\n",
      "instance 0, ep 10\n",
      "instance 0, ep 11\n",
      "instance 0, ep 12\n",
      "instance 0, ep 13\n",
      "instance 0, ep 14\n",
      "instance 0, ep 15\n",
      "instance 0, ep 16\n",
      "instance 0, ep 17\n",
      "instance 0, ep 18\n",
      "instance 0, ep 19\n",
      "instance 0, ep 20\n",
      "instance 0, ep 21\n",
      "instance 0, ep 22\n",
      "instance 0, ep 23\n",
      "instance 0, ep 24\n",
      "instance 0, ep 25\n",
      "instance 0, ep 26\n",
      "instance 0, ep 27\n",
      "instance 0, ep 28\n",
      "instance 0, ep 29\n",
      "Took 368.9375021457672 time for inference and 0.0006377696990966797 time for training\n",
      "0.4326696203316666\n"
     ]
    }
   ],
   "source": [
    "if n_arms * volunteers_per_arm <= 1000 and use_context:\n",
    "    policy = occupancy_measure_learn_shapley_contextual \n",
    "    name = \"occupancy_measure_learn_shapley\"\n",
    "\n",
    "    rewards, memory, simulator = run_multi_seed(seed_list,policy,results['parameters'],test_length=episode_len*(n_episodes%50),shapley_iterations=1000)\n",
    "    results['{}_reward'.format(name)] = rewards['reward']\n",
    "    results['{}_match'.format(name)] =  rewards['match'] \n",
    "    results['{}_active'.format(name)] = rewards['active_rate']\n",
    "    results['{}_time'.format(name)] =  rewards['time']\n",
    "    results['{}_predicted_regression'.format(name)] = list(simulator.predicted_regression)\n",
    "    results['{}_actual_regression'.format(name)] = list(simulator.actual_regression)\n",
    "    print(np.mean(rewards['reward']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cohort [ 6 61 24 28 93  0 91 23 74 73]\n",
      "instance 0, ep 1\n",
      "instance 0, ep 2\n",
      "instance 0, ep 3\n",
      "instance 0, ep 4\n",
      "instance 0, ep 5\n",
      "instance 0, ep 6\n",
      "instance 0, ep 7\n",
      "instance 0, ep 8\n",
      "instance 0, ep 9\n",
      "instance 0, ep 10\n",
      "instance 0, ep 11\n",
      "instance 0, ep 12\n",
      "instance 0, ep 13\n",
      "instance 0, ep 14\n",
      "instance 0, ep 15\n",
      "instance 0, ep 16\n",
      "instance 0, ep 17\n",
      "instance 0, ep 18\n",
      "instance 0, ep 19\n",
      "instance 0, ep 20\n",
      "instance 0, ep 21\n",
      "instance 0, ep 22\n",
      "instance 0, ep 23\n",
      "instance 0, ep 24\n",
      "instance 0, ep 25\n",
      "instance 0, ep 26\n",
      "instance 0, ep 27\n",
      "instance 0, ep 28\n",
      "instance 0, ep 29\n",
      "Took 5.341778755187988 time for inference and 0.0004985332489013672 time for training\n",
      "0.40262200288185335\n"
     ]
    }
   ],
   "source": [
    "if n_arms * volunteers_per_arm <= 1000:\n",
    "    policy = occupancy_measure_learn_shapley_confidence\n",
    "    name = \"occupancy_measure_learn_shapley\"\n",
    "\n",
    "    rewards, memory, simulator = run_multi_seed(seed_list,policy,results['parameters'],test_length=episode_len*(n_episodes%50),shapley_iterations=1000)\n",
    "    results['{}_reward'.format(name)] = rewards['reward']\n",
    "    results['{}_match'.format(name)] =  rewards['match'] \n",
    "    results['{}_active'.format(name)] = rewards['active_rate']\n",
    "    results['{}_time'.format(name)] =  rewards['time']\n",
    "    results['{}_predicted_regression'.format(name)] = list(simulator.predicted_regression)\n",
    "    results['{}_actual_regression'.format(name)] = list(simulator.actual_regression)\n",
    "    print(np.mean(rewards['reward']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Write Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path = get_save_path(out_folder,save_name,seed,use_date=save_with_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "delete_duplicate_results(out_folder,\"\",results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "json.dump(results,open('../../results/'+save_path,'w'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "food",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
