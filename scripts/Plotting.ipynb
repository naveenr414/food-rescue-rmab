{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "import numpy as np\n",
    "from rmab.utils import get_results_matching_parameters, filter_pareto_optimal\n",
    "from rmab.plots import plot_line_plot_parameter, plot_tradeoff_curve, process_two_parameter_data, process_one_parameter_data, process_zero_parameter_data\n",
    "import seaborn as sns\n",
    "import itertools "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.style.use('ggplot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['xtick.labelsize'] = 18\n",
    "plt.rcParams['ytick.labelsize'] = 18\n",
    "plt.rcParams['axes.labelsize'] = 18\n",
    "plt.rcParams['legend.fontsize'] = 18\n",
    "plt.rcParams['savefig.dpi'] = 300\n",
    "plt.rcParams['savefig.bbox'] = 'tight'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "method_to_nice = {\n",
    "    'random_rewards': 'Random',\n",
    "    'optimal_rewards': 'Whittle (Oracle)',\n",
    "    'wiql_rewards': 'WIQL', \n",
    "    'ucw_perfect_rewards': 'Approx. Whittle + Known Distance (Oracle)',\n",
    "    'extreme_rewards': 'Extreme', \n",
    "    'ucb_rewards': 'UCB', \n",
    "    'ucb_fixed_rewards': 'UCB w/o Normal',\n",
    "    'fixed_rewards': 'UCB w/o Normal',\n",
    "    'norm_rewards': 'UCB + Normal.',\n",
    "    'predicted_optimal_match_rewards': 'UCB Match',\n",
    "    'qp_fixed_rewards': 'QP',\n",
    "    'value_fixed_rewards': 'Value',\n",
    "    'optimal_match_rewards': 'Whittle Match (Oracle)',\n",
    "    'whittle_approximate_rewards': 'Whittle Approx. Match (Oracle)',\n",
    "    'zero_step_rewards': 'Myopic Zero-Step', \n",
    "    'one_step_rewards': 'Myopic One-Step',\n",
    "    'infinite_step_rewards': 'Myopic Infinite-Step',\n",
    "    'combined_rewards': 'Combined',\n",
    "    'ucw_match_rewards': 'UCW + Whittle Match'\n",
    "}\n",
    "\n",
    "match_to_nice = {\n",
    "    'random_match': 'Random',\n",
    "    'optimal_match': 'Optimal',\n",
    "    'wiql_match': 'WIQL', \n",
    "    'extreme_match': 'Extreme', \n",
    "    'ucb_match': 'UCB', \n",
    "    'fixed_match': 'Fixed',\n",
    "    'qp_match': 'QP',\n",
    "    'value_match': 'Value', \n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline Bandit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seeds = [42,43,44]\n",
    "data = get_results_matching_parameters(\"baseline\",\"results\",{'n_arms': 8, 'budget': 3})\n",
    "data = sorted(data,key=lambda k: k['parameters']['seed'])\n",
    "full_data = {}\n",
    "for i in data[0]['mean_reward']:\n",
    "    mean_val = np.round(np.mean([j['mean_reward'][i] for j in data]),2)\n",
    "    std_val = np.round(np.std([j['mean_reward'][i] for j in data]),2)\n",
    "    full_data[i] = (mean_val,std_val)\n",
    "\n",
    "for m in method_to_nice:\n",
    "    if m in full_data:\n",
    "        full_data[method_to_nice[m]] = full_data.pop(m)\n",
    "\n",
    "matching_performance = {}\n",
    "for i in data[0]['match_rate']:\n",
    "    mean_val = np.mean([j['match_rate'][i] for j in data])\n",
    "    std_val = np.std([j['match_rate'][i] for j in data])\n",
    "    matching_performance[i] = (mean_val,std_val)\n",
    "\n",
    "for m in match_to_nice:\n",
    "    if m in matching_performance:\n",
    "        matching_performance[match_to_nice[m]] = matching_performance.pop(m)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "latex_table = f\"\"\"\n",
    "\\\\begin{{table}}\n",
    "    \\\\centering\n",
    "    \\\\begin{{tabular}}{{@{{}}lccc@{{}}}}\n",
    "        \\\\toprule\n",
    "        Algorithm & \\\\multicolumn{{1}}{{c}}{{Bandit Perf.}} & \\\\multicolumn{{1}}{{c}}{{Matching Perf.}} \\\\\\\\ \n",
    "        \\\\midrule\n",
    "\"\"\"\n",
    "\n",
    "for algorithm in full_data.keys():\n",
    "    bandit_value, bandit_error = full_data[algorithm]\n",
    "    matching_value, matching_error = matching_performance.get(algorithm, (0, 0))\n",
    "    \n",
    "    latex_table += f\"        {algorithm} & ${bandit_value:.2f} \\\\pm {bandit_error:.2f}$ & ${matching_value:.3f} \\\\pm {matching_error:.3f}$ \\\\\\\\ \\n\"\n",
    "\n",
    "latex_table += \"\"\"\n",
    "        \\\\bottomrule\n",
    "    \\end{tabular}\n",
    "    \\\\caption{Bandit and Matching Performance}\n",
    "\\\\end{table}\n",
    "\"\"\"\n",
    "\n",
    "print(latex_table)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = get_results_matching_parameters(\"baseline\",\"hyperparameter\",{'budget': 3})\n",
    "plot_line_plot_parameter(data,'n_arms','mean_reward',method_to_nice)\n",
    "plt.yticks([2,3,4,5])\n",
    "plt.xticks([4,8,12,16])\n",
    "sns.despine()\n",
    "plt.legend()\n",
    "plt.xlabel(\"Cohort Size\")\n",
    "plt.ylabel(\"Reward\")\n",
    "plt.savefig(\"../figures/baseline/reward_arms.pdf\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_line_plot_parameter(data,'n_arms','match_rate',match_to_nice)\n",
    "plt.yticks([0.95,0.96,0.97,0.98,0.99,1.00],['95%','96%','97%','98%','99%','100%'])\n",
    "plt.xticks([4,8,12,16])\n",
    "sns.despine()\n",
    "plt.legend()\n",
    "plt.xlabel(\"Cohort Size\")\n",
    "plt.ylabel(\"Match Rate\")\n",
    "plt.savefig(\"../figures/baseline/match_arms.pdf\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = get_results_matching_parameters(\"baseline\",\"hyperparameter\",{'n_arms': 8})\n",
    "plot_line_plot_parameter(data,'budget','mean_reward',method_to_nice)\n",
    "plt.yticks([2,3,4,5])\n",
    "plt.xticks([2,4,6])\n",
    "sns.despine()\n",
    "plt.legend()\n",
    "plt.xlabel(\"Budget\")\n",
    "plt.ylabel(\"Reward\")\n",
    "plt.savefig(\"../figures/baseline/reward_budget.pdf\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_line_plot_parameter(data,'budget','match_rate',match_to_nice)\n",
    "plt.yticks([0.9,0.92,0.94,0.96,0.98,1.00],['90%','92%','94%','96%','98%','100%'])\n",
    "plt.xticks([2,4,6])\n",
    "sns.despine()\n",
    "plt.legend()\n",
    "plt.xlabel(\"Budget\")\n",
    "plt.ylabel(\"Match Rate\")\n",
    "plt.savefig(\"../figures/baseline/match_budget.pdf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Improving Bandits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_synthetic = get_results_matching_parameters(\"replication\",\"synthetic\",{})\n",
    "data_fr = get_results_matching_parameters(\"baseline\",\"results\",{'n_arms': 8, 'budget': 3})\n",
    "data_better = get_results_matching_parameters(\"better_bandit\",\"normal\",{})\n",
    "\n",
    "\n",
    "synthetic_data = []\n",
    "fr_data = []\n",
    "\n",
    "synthetic_data.append(np.mean([np.mean(i['mean_rewards']['ucw_ucb']) for i in data_synthetic]))\n",
    "synthetic_data.append(np.mean([i['mean_reward_baseline'] for i in data_better if i['parameters']['dataset'] == 'synthetic'])-synthetic_data[0])\n",
    "synthetic_data.append(np.mean([i['mean_reward_norm'] for i in data_better if i['parameters']['dataset'] == 'synthetic'])-(synthetic_data[1]+synthetic_data[0]))\n",
    "synthetic_data_optimal = np.mean([i['mean_optimal_reward'] for i in data_better if i['parameters']['dataset'] == 'synthetic'])\n",
    "synthetic_data_perfect= np.mean([i['mean_reward_perfect'] for i in data_better if i['parameters']['dataset'] == 'synthetic'])\n",
    "\n",
    "fr_data.append(np.mean([i['mean_reward']['ucb_rewards'] for i in data_fr]))\n",
    "fr_data.append(np.mean([i['mean_reward_baseline'] for i in data_better if i['parameters']['dataset'] == 'fr'])-fr_data[0])\n",
    "fr_data.append(np.mean([i['mean_reward_norm'] for i in data_better if i['parameters']['dataset'] == 'fr'])-(fr_data[1]+fr_data[0]))\n",
    "fr_data_optimal = np.mean([i['mean_optimal_reward'] for i in data_better if i['parameters']['dataset'] == 'fr'])\n",
    "fr_data_perfect = np.mean([i['mean_reward_perfect'] for i in data_better if i['parameters']['dataset'] == 'fr'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colors = ['#87CEEB', '#FFFF99', '#FFA07A']  # Pastel Blue, Yellow, and Red\n",
    "labels = ['UCB','Fixed','Normal']\n",
    "\n",
    "\n",
    "# Create a figure and axis\n",
    "fig, ax = plt.subplots(figsize=(6,6))\n",
    "\n",
    "# Create a stacked bar chart for the data\n",
    "bottom = 0\n",
    "for i, value in enumerate(synthetic_data):\n",
    "    ax.bar(0, value, color=colors[i], bottom=bottom,label=labels[i])\n",
    "    bottom += value\n",
    "\n",
    "bottom = 0\n",
    "for i, value in enumerate(fr_data):\n",
    "    ax.bar(1, value, color=colors[i], bottom=bottom)\n",
    "    bottom += value\n",
    "\n",
    "\n",
    "# Customize labels and legend\n",
    "ax.set_xticks([0,1])\n",
    "ax.set_xticklabels(['Synthetic','Food'])\n",
    "ax.set_xlabel('Dataset')\n",
    "ax.set_ylabel('Reward')\n",
    "\n",
    "ax.axhline(synthetic_data_optimal, color='green', linestyle='--',xmin=-0.5,xmax=0.5,label='Optimal')\n",
    "ax.axhline(synthetic_data_perfect, color='black', linestyle='--',xmin=-0.5,xmax=0.5,label='Max. Whittle Estimate')\n",
    "\n",
    "\n",
    "ax.axhline(fr_data_optimal, color='green', linestyle='--',xmin=0.5,xmax=1.5)\n",
    "ax.axhline(fr_data_perfect, color='black', linestyle='--',xmin=0.5,xmax=1.5)\n",
    "\n",
    "plt.legend()\n",
    "plt.savefig(\"../figures/better_bandit/normal_improvement.pdf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Matching Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_matching = get_results_matching_parameters(\"matching\",\"p_val\",{})\n",
    "avg_reward_by_method = {}\n",
    "all_p_vals = sorted(list(set([i['parameters']['match_prob'] for i in data_matching])))\n",
    "\n",
    "for i in data_matching[0]['mean_reward'].keys():\n",
    "    avg_reward_by_method[i] = []\n",
    "\n",
    "    for p in all_p_vals:\n",
    "        results_p = [data['mean_reward'][i] for data in data_matching if data['parameters']['match_prob'] == p]\n",
    "        avg_reward_by_method[i].append(np.mean(results_p))\n",
    "\n",
    "line_styles = ['-', '--', ':']\n",
    "line_style_cycle = itertools.cycle(line_styles)\n",
    "\n",
    "plt.figure(figsize=(8, 8))\n",
    "\n",
    "for method in avg_reward_by_method:\n",
    "    style = next(line_style_cycle)\n",
    "    plt.plot(all_p_vals, avg_reward_by_method[method], label=method_to_nice[method], linestyle=style)\n",
    "\n",
    "plt.xlabel(\"Matching Probability\")\n",
    "plt.ylabel(\"Claim Rate\")\n",
    "plt.yticks([0.2, 0.4, 0.6, 0.8, 1.0], [\"20%\", \"40%\", \"60%\", \"80%\", \"100%\"])\n",
    "plt.legend(fontsize=14)\n",
    "\n",
    "plt.savefig(\"../figures/matching/matching_p.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_matching = get_results_matching_parameters(\"matching_baseline\",\"results\",{})\n",
    "avg_reward_by_method = {}\n",
    "all_n_arm_vals = sorted(list(set([i['parameters']['n_arms'] for i in data_matching])))\n",
    "\n",
    "for i in data_matching[0]['mean_reward'].keys():\n",
    "    avg_reward_by_method[i] = []\n",
    "\n",
    "    for n in all_n_arm_vals:\n",
    "        results_p = [data['mean_reward'][i] for data in data_matching if data['parameters']['n_arms'] == n]\n",
    "        avg_reward_by_method[i].append(np.mean(results_p))\n",
    "\n",
    "line_styles = ['-', '--', ':']\n",
    "line_style_cycle = itertools.cycle(line_styles)\n",
    "\n",
    "plt.figure(figsize=(8, 8))\n",
    "\n",
    "for method in avg_reward_by_method:\n",
    "    style = next(line_style_cycle)\n",
    "    plt.plot(all_n_arm_vals, avg_reward_by_method[method], label=method_to_nice[method], linestyle=style)\n",
    "\n",
    "plt.xlabel(\"Number of Arms\")\n",
    "plt.ylabel(\"Match Rate\")\n",
    "plt.yticks([0.2, 0.4, 0.6, 0.8, 1.0], [\"20%\", \"40%\", \"60%\", \"80%\", \"100%\"])\n",
    "plt.xticks([4,6,8])\n",
    "plt.legend(fontsize=14)\n",
    "\n",
    "plt.savefig(\"../figures/matching/matching_baseline_n_arms.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_matching = get_results_matching_parameters(\"matching_baseline\",\"results\",{})\n",
    "avg_reward_by_method = {}\n",
    "all_n_arm_vals = sorted(list(set([i['parameters']['n_arms'] for i in data_matching])))\n",
    "\n",
    "for i in data_matching[0]['mean_reward'].keys():\n",
    "    avg_reward_by_method[i] = []\n",
    "\n",
    "    for n in all_n_arm_vals:\n",
    "        results_p = [data['mean_reward'][i] for data in data_matching if data['parameters']['n_arms'] == n]\n",
    "        avg_reward_by_method[i].append(np.mean(results_p))\n",
    "\n",
    "line_styles = ['-', '--', ':']\n",
    "line_style_cycle = itertools.cycle(line_styles)\n",
    "\n",
    "plt.figure(figsize=(8, 8))\n",
    "\n",
    "for method in avg_reward_by_method:\n",
    "    style = next(line_style_cycle)\n",
    "    plt.plot(all_n_arm_vals, avg_reward_by_method[method], label=method_to_nice[method], linestyle=style)\n",
    "\n",
    "plt.xlabel(\"Number of Arms\")\n",
    "plt.ylabel(\"Match Rate\")\n",
    "plt.yticks([0.75,0.8,0.85], [\"75%\", \"80%\", \"85%\"])\n",
    "plt.ylim([0.73,0.86])\n",
    "plt.xticks([4,6,8])\n",
    "plt.legend(fontsize=14)\n",
    "\n",
    "plt.savefig(\"../figures/matching/matching_baseline_n_arms_zoomed.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_matching = get_results_matching_parameters(\"matching_baseline\",\"results\",{})\n",
    "data_matching = [i for i in data_matching if i['parameters']['n_arms']<=6]\n",
    "avg_reward_by_method = {}\n",
    "\n",
    "all_n_arm_vals = sorted(list(set([i['parameters']['n_arms'] for i in data_matching])))\n",
    "\n",
    "for i in data_matching[0]['mean_reward'].keys():\n",
    "    avg_reward_by_method[i] = []\n",
    "\n",
    "    for n in all_n_arm_vals:\n",
    "        results_p = [data['mean_reward'][i] for data in data_matching if data['parameters']['n_arms'] == n]\n",
    "        avg_reward_by_method[i].append(np.mean(results_p))\n",
    "\n",
    "line_styles = ['-', '--', ':']\n",
    "line_style_cycle = itertools.cycle(line_styles)\n",
    "\n",
    "plt.figure(figsize=(8, 8))\n",
    "\n",
    "for method in avg_reward_by_method:\n",
    "    style = next(line_style_cycle)\n",
    "    plt.plot(all_n_arm_vals, avg_reward_by_method[method], label=method_to_nice[method], linestyle=style)\n",
    "\n",
    "plt.xlabel(\"Number of Arms\")\n",
    "plt.ylabel(\"Match Rate\")\n",
    "plt.yticks([0.75,0.8], [\"75%\", \"80%\"])\n",
    "plt.ylim([0.73,0.82])\n",
    "plt.xticks([4,5,6])\n",
    "plt.legend()\n",
    "\n",
    "plt.savefig(\"../figures/matching/matching_baseline_n_arms_zoomed_2.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_matching = get_results_matching_parameters(\"matching_baseline\",\"results\",{})\n",
    "data_matching = [i for i in data_matching if i['parameters']['n_arms']<=6]\n",
    "avg_reward_by_method = {}\n",
    "\n",
    "all_n_arm_vals = sorted(list(set([i['parameters']['n_arms'] for i in data_matching])))\n",
    "\n",
    "for i in data_matching[0]['mean_reward'].keys():\n",
    "    avg_reward_by_method[i] = []\n",
    "\n",
    "    for n in all_n_arm_vals:\n",
    "        results_p = [data['mean_reward'][i] for data in data_matching if data['parameters']['n_arms'] == n]\n",
    "        avg_reward_by_method[i].append(np.mean(results_p))\n",
    "\n",
    "for i in avg_reward_by_method:\n",
    "    for j in range(len(avg_reward_by_method[i])):\n",
    "        avg_reward_by_method[i][j] /= avg_reward_by_method['optimal_match_rewards'][j]\n",
    "\n",
    "categories = list(avg_reward_by_method.keys())\n",
    "values = np.array(list(avg_reward_by_method.values()))\n",
    "\n",
    "# Determine the number of bars\n",
    "num_bars = len(avg_reward_by_method[categories[0]])\n",
    "\n",
    "# Set the bar width and spacing\n",
    "bar_width = 0.2\n",
    "bar_spacing = 0\n",
    "\n",
    "# Calculate the x-positions for each set of bars\n",
    "x = np.arange(num_bars)*2\n",
    "\n",
    "# Set up the color palette for the legend\n",
    "color_palette = plt.cm.viridis(np.linspace(0, 1, len(categories)))  # Change the colormap as needed\n",
    "\n",
    "# Create the paired bar chart\n",
    "fig, ax = plt.subplots(figsize=(10,10))\n",
    "\n",
    "for i, category in enumerate(categories):\n",
    "    ax.bar(x + (i - (len(categories) - 1) / 2) * (bar_width + bar_spacing), values[i], width=bar_width, label=method_to_nice[category], color=color_palette[i])\n",
    "\n",
    "# Customize the plot\n",
    "ax.set_xlabel('')\n",
    "plt.xticks(x,all_n_arm_vals)\n",
    "plt.yticks([0.2, 0.4, 0.6, 0.8, 1.0], [\"20%\", \"40%\", \"60%\", \"80%\", \"100%\"])\n",
    "ax.set_ylabel('Match% of Optimal')\n",
    "ax.set_xlabel(\"Number of Arms\")\n",
    "\n",
    "plt.legend(loc='lower left') \n",
    "\n",
    "plt.savefig(\"../figures/matching/matching_baseline_bar.pdf\")\n",
    "\n",
    "avg_reward_by_method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_matching = get_results_matching_parameters(\"matching\",\"results\",{})\n",
    "avg_reward_by_method = {}\n",
    "all_n_arm_vals = sorted(list(set([i['parameters']['n_arms'] for i in data_matching])))\n",
    "\n",
    "for i in data_matching[0]['mean_reward'].keys():\n",
    "    avg_reward_by_method[i] = []\n",
    "\n",
    "    for n in all_n_arm_vals:\n",
    "        results_p = [data['mean_reward'][i] for data in data_matching if data['parameters']['n_arms'] == n]\n",
    "        avg_reward_by_method[i].append(np.mean(results_p))\n",
    "\n",
    "line_styles = ['-', '--', ':']\n",
    "line_style_cycle = itertools.cycle(line_styles)\n",
    "\n",
    "plt.figure(figsize=(8, 8))\n",
    "\n",
    "labels = {}\n",
    "for method in avg_reward_by_method:\n",
    "    labels[method] = method_to_nice[method]\n",
    "    if 'random' in method.lower() or 'oracle' in method.lower():\n",
    "        pass \n",
    "    else:\n",
    "        labels[method] += ' est.'\n",
    "\n",
    "for method in avg_reward_by_method:\n",
    "    style = next(line_style_cycle)\n",
    "    plt.plot(all_n_arm_vals, avg_reward_by_method[method], label=labels[method], linestyle=style)\n",
    "\n",
    "plt.xlabel(\"Number of Arms\")\n",
    "plt.ylabel(\"Match Rate\")\n",
    "plt.yticks([0.2, 0.4, 0.6, 0.8, 1.0], [\"20%\", \"40%\", \"60%\", \"80%\", \"100%\"])\n",
    "plt.xticks([4,6,8])\n",
    "plt.legend(loc='lower left')\n",
    "\n",
    "plt.savefig(\"../figures/matching/matching_estimated_n_arms.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_matching = get_results_matching_parameters(\"matching\",\"results\",{})\n",
    "data_matching = [i for i in data_matching if i['parameters']['n_arms']<=6]\n",
    "avg_reward_by_method = {}\n",
    "all_n_arm_vals = sorted(list(set([i['parameters']['n_arms'] for i in data_matching])))\n",
    "\n",
    "for i in data_matching[0]['mean_reward'].keys():\n",
    "    if i not in ['zero_step_rewards','one_step_rewards','infinite_step_rewards','ucw_match_rewards',\n",
    "    'ucw_perfect_rewards','whittle_approximate_rewards','optimal_match_rewards']:\n",
    "        print(i)\n",
    "        continue \n",
    "\n",
    "    avg_reward_by_method[i] = []\n",
    "\n",
    "    for n in all_n_arm_vals:\n",
    "        results_p = [data['mean_reward'][i] for data in data_matching if data['parameters']['n_arms'] == n]\n",
    "        avg_reward_by_method[i].append(np.mean(results_p))\n",
    "\n",
    "line_styles = ['-', '--', ':']\n",
    "line_style_cycle = itertools.cycle(line_styles)\n",
    "\n",
    "plt.figure(figsize=(8, 8))\n",
    "\n",
    "labels = {}\n",
    "for method in avg_reward_by_method:\n",
    "    labels[method] = method_to_nice[method]\n",
    "    if 'random' in method.lower() or 'oracle' in method.lower():\n",
    "        pass \n",
    "    else:\n",
    "        labels[method] += ' est.'\n",
    "\n",
    "for method in avg_reward_by_method:\n",
    "    style = next(line_style_cycle)\n",
    "    plt.plot(all_n_arm_vals, avg_reward_by_method[method], label=labels[method], linestyle=style)\n",
    "\n",
    "plt.xlabel(\"Number of Arms\")\n",
    "plt.ylabel(\"Match Rate\")\n",
    "plt.yticks([0.75,0.8,0.85], [\"75%\", \"80%\", \"85%\"])\n",
    "plt.ylim([0.73,0.86])\n",
    "plt.xticks([4,5,6])\n",
    "plt.legend(fontsize=14)\n",
    "\n",
    "plt.savefig(\"../figures/matching/matching_estimated_n_arms_zoomed.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_matching = get_results_matching_parameters(\"matching\",\"results\",{})\n",
    "data_matching = [i for i in data_matching if i['parameters']['n_arms']<=6]\n",
    "avg_reward_by_method = {}\n",
    "\n",
    "all_n_arm_vals = sorted(list(set([i['parameters']['n_arms'] for i in data_matching])))\n",
    "\n",
    "for i in data_matching[0]['mean_reward'].keys():\n",
    "    avg_reward_by_method[i] = []\n",
    "\n",
    "    for n in all_n_arm_vals:\n",
    "        results_p = [data['mean_reward'][i] for data in data_matching if data['parameters']['n_arms'] == n]\n",
    "        avg_reward_by_method[i].append(np.mean(results_p))\n",
    "\n",
    "for i in avg_reward_by_method:\n",
    "    for j in range(len(avg_reward_by_method[i])):\n",
    "        avg_reward_by_method[i][j] /= avg_reward_by_method['optimal_match_rewards'][j]\n",
    "\n",
    "categories = list(avg_reward_by_method.keys())\n",
    "values = np.array(list(avg_reward_by_method.values()))\n",
    "\n",
    "# Determine the number of bars\n",
    "num_bars = len(avg_reward_by_method[categories[0]])\n",
    "\n",
    "# Set the bar width and spacing\n",
    "bar_width = 0.2\n",
    "bar_spacing = 0\n",
    "\n",
    "# Calculate the x-positions for each set of bars\n",
    "x = np.arange(num_bars)*2\n",
    "\n",
    "# Set up the color palette for the legend\n",
    "color_palette = plt.cm.viridis(np.linspace(0, 1, len(categories)))  # Change the colormap as needed\n",
    "\n",
    "# Create the paired bar chart\n",
    "fig, ax = plt.subplots(figsize=(10,10))\n",
    "\n",
    "labels = {}\n",
    "for method in avg_reward_by_method:\n",
    "    labels[method] = method_to_nice[method]\n",
    "    if 'random' in method.lower() or 'oracle' in method_to_nice[method].lower():\n",
    "        pass \n",
    "    else:\n",
    "        labels[method] += ' est.'\n",
    "\n",
    "for i, category in enumerate(categories):\n",
    "    ax.bar(x + (i - (len(categories) - 1) / 2) * (bar_width + bar_spacing), values[i], width=bar_width, label=labels[category], color=color_palette[i])\n",
    "\n",
    "# Customize the plot\n",
    "ax.set_xlabel('')\n",
    "plt.xticks(x,all_n_arm_vals)\n",
    "plt.yticks([0.2, 0.4, 0.6, 0.8, 1.0], [\"20%\", \"40%\", \"60%\", \"80%\", \"100%\"])\n",
    "ax.set_ylabel('Match% of Optimal')\n",
    "ax.set_xlabel(\"Number of Arms\")\n",
    "\n",
    "plt.legend(loc='lower left') \n",
    "\n",
    "plt.savefig(\"../figures/matching/matching_estimated_bar.pdf\")\n",
    "\n",
    "avg_reward_by_method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_matching = get_results_matching_parameters(\"matching\",\"results\",{})\n",
    "data_matching = [i for i in data_matching if i['parameters']['n_arms']<=6]\n",
    "avg_reward_by_method = {}\n",
    "\n",
    "all_n_arm_vals = sorted(list(set([i['parameters']['n_arms'] for i in data_matching])))\n",
    "\n",
    "for i in data_matching[0]['mean_reward'].keys():\n",
    "    if i not in ['optimal_match_rewards','ucw_match_rewards','ucw_perfect_rewards']:\n",
    "        continue \n",
    "    avg_reward_by_method[i] = []\n",
    "\n",
    "    for n in all_n_arm_vals:\n",
    "        results_p = [data['mean_reward'][i] for data in data_matching if data['parameters']['n_arms'] == n]\n",
    "        avg_reward_by_method[i].append(np.mean(results_p))\n",
    "\n",
    "# for i in avg_reward_by_method:\n",
    "#     for j in range(len(avg_reward_by_method[i])):\n",
    "#         avg_reward_by_method[i][j] /= avg_reward_by_method['optimal_match_rewards'][j]\n",
    "\n",
    "categories = list(avg_reward_by_method.keys())\n",
    "values = np.array(list(avg_reward_by_method.values()))\n",
    "\n",
    "# Determine the number of bars\n",
    "num_bars = len(avg_reward_by_method[categories[0]])\n",
    "\n",
    "# Set the bar width and spacing\n",
    "bar_width = 0.2\n",
    "bar_spacing = 0\n",
    "\n",
    "# Calculate the x-positions for each set of bars\n",
    "x = np.arange(num_bars)*2\n",
    "\n",
    "# Set up the color palette for the legend\n",
    "color_palette = plt.cm.viridis(np.linspace(0, 1, len(categories)))  # Change the colormap as needed\n",
    "\n",
    "# Create the paired bar chart\n",
    "fig, ax = plt.subplots(figsize=(10,10))\n",
    "\n",
    "labels = {}\n",
    "for method in avg_reward_by_method:\n",
    "    labels[method] = method_to_nice[method]\n",
    "    if 'random' in method.lower() or 'oracle' in method_to_nice[method].lower():\n",
    "        pass \n",
    "    else:\n",
    "        labels[method] += ' est.'\n",
    "\n",
    "for i, category in enumerate(categories):\n",
    "    ax.bar(x + (i - (len(categories) - 1) / 2) * (bar_width + bar_spacing), values[i], width=bar_width, label=labels[category], color=color_palette[i])\n",
    "\n",
    "# Customize the plot\n",
    "ax.set_xlabel('')\n",
    "plt.xticks(x,all_n_arm_vals)\n",
    "plt.yticks([0.2, 0.4, 0.6, 0.8, 1.0], [\"20%\", \"40%\", \"60%\", \"80%\", \"100%\"])\n",
    "ax.set_ylabel('Match%')\n",
    "ax.set_xlabel(\"Number of Arms\")\n",
    "\n",
    "plt.legend(loc='lower left') \n",
    "\n",
    "avg_reward_by_method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Activity vs. Matching Tradeoff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined = get_results_matching_parameters(\"combined\",\"results\",{})\n",
    "data_by_arms = process_one_parameter_data(combined,\"n_arms\")\n",
    "\n",
    "n_arms = 4\n",
    "names = [\"whittle\",\"sufficient\",\"joint\"]\n",
    "nice_names = [\"Whittle\",\"Sufficient Q Iteration\",\"Optimal\"]\n",
    "plot_tradeoff_curve(data_by_arms[n_arms],names,nice_names,\"N Arms {}\".format(n_arms))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined = get_results_matching_parameters(\"combined\",\"results\",{})\n",
    "data_by_arms = process_one_parameter_data(combined,\"n_arms\")\n",
    "\n",
    "n_arms = 7\n",
    "names = [\"whittle\",\"sufficient\"]\n",
    "nice_names = [\"Whittle\",\"Sufficient Q Iteration\"]\n",
    "plot_tradeoff_curve(data_by_arms[n_arms],names,nice_names,\"N Arms {}\".format(n_arms))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined = get_results_matching_parameters(\"combined\",\"results\",{})\n",
    "data_by_arms = process_one_parameter_data(combined,\"n_arms\")\n",
    "\n",
    "n_arms = 4\n",
    "names = [\"whittle\",\"sufficient\"]\n",
    "nice_names = [\"Whittle\",\"Sufficient Q Iteration\"]\n",
    "plot_tradeoff_curve(data_by_arms[n_arms],names,nice_names,\"N Arms {}\".format(n_arms))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined = get_results_matching_parameters(\"combined\",\"results\",{})\n",
    "data_by_arms = process_one_parameter_data(combined,\"n_arms\")\n",
    "\n",
    "n_arms = 4\n",
    "names = [\"whittle\",\"sufficient\",\"neural\"]\n",
    "nice_names = [\"Whittle\",\"Sufficient Q Iteration\",\"PPO\"]\n",
    "plot_tradeoff_curve(data_by_arms[n_arms],names,nice_names,\"N Arms {}\".format(n_arms))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## New Matching + Engagement Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined = get_results_matching_parameters(\"combined\",\"heterogeneous_arms\",{})\n",
    "data_by_arms = process_one_parameter_data(combined,\"n_arms\")\n",
    "\n",
    "n_arms = 4\n",
    "names = [\"whittle\",\"joint\",\"greedy\"]\n",
    "nice_names = [\"Whittle\",\"Optimal\",\"Greedy\"]\n",
    "plot_tradeoff_curve(data_by_arms[n_arms],names,nice_names,\"N Arms {}\".format(n_arms))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined = get_results_matching_parameters(\"combined\",\"heterogeneous_arms\",{})\n",
    "data_by_arms = process_one_parameter_data(combined,\"n_arms\")\n",
    "\n",
    "n_arms = 4\n",
    "names = [\"whittle\",\"joint\",\"greedy\",\"iterative\",\"iterative_q\"]\n",
    "nice_names = [\"Whittle\",\"Optimal\",\"Greedy\",\"Iterative\",\"Iterative + Q\"]\n",
    "plot_tradeoff_curve(data_by_arms[n_arms],names,nice_names,\"N Arms {}\".format(n_arms))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined = get_results_matching_parameters(\"combined\",\"heterogeneous_arms\",{})\n",
    "data_by_arms = process_one_parameter_data(combined,\"n_arms\")\n",
    "\n",
    "n_arms = 4\n",
    "names = [\"whittle\",\"joint\",\"iterative_q\",\"iterative_shapley\",\"iterative_q_shapley\"]\n",
    "nice_names = [\"Whittle\",\"Optimal\",\"Iterative + Q\",\"Iterative+Shapley\",\"Iterative + Q + Shapley\"]\n",
    "plot_tradeoff_curve(data_by_arms[n_arms],names,nice_names,\"N Arms {}\".format(n_arms))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined = get_results_matching_parameters(\"combined\",\"heterogeneous_arms\",{})\n",
    "data_by_arms = process_one_parameter_data(combined,\"n_arms\")\n",
    "\n",
    "n_arms = 4\n",
    "names = [\"whittle\",\"joint\",\"mcts\",\"mcts_q\"]\n",
    "nice_names = [\"Whittle\",\"Optimal\",\"MCTS\",\"MCTS+Q Iteration\"]\n",
    "plot_tradeoff_curve(data_by_arms[n_arms],names,nice_names,\"N Arms {}\".format(n_arms))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined = get_results_matching_parameters(\"combined\",\"heterogeneous_arms\",{})\n",
    "data_by_arms = process_one_parameter_data(combined,\"n_arms\")\n",
    "\n",
    "n_arms = 4\n",
    "names = [\"whittle\",\"joint\",\"mcts\",\"iterative\",\"greedy\"]\n",
    "nice_names = [\"Whittle\",\"Optimal\",\"MCTS\",\"Iterative\",\"Greedy\"]\n",
    "plot_tradeoff_curve(data_by_arms[n_arms],names,nice_names,\"N Arms {}\".format(n_arms))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Large N Matching Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined = get_results_matching_parameters(\"combined_large\",\"combined\",{})\n",
    "data_by_arm_volunteer = process_two_parameter_data(combined,\"n_arms\",\"volunteers_per_arm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_arms = 2\n",
    "n_volunteers = 2\n",
    "\n",
    "names = [\"whittle\",\"whittle_activity\",\"greedy\",\"shapley_whittle\",\"whittle_greedy\"]\n",
    "nice_names = [\"Combined Whittle\",\"Pure Whittle\",\"Greedy\",\"Shapley+Whittle\",\"Greedy+Whittle\"]\n",
    "\n",
    "if n_arms * n_volunteers <= 6:\n",
    "    names.append(\"optimal\")\n",
    "    nice_names.append(\"Optimal\")\n",
    "\n",
    "plot_tradeoff_curve(data_by_arm_volunteer[n_arms][n_volunteers],names,nice_names,\"{} arms, {} Volunteers/Arm\".format(n_arms,n_volunteers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_arms = 2\n",
    "n_volunteers = 16\n",
    "\n",
    "names = [\"whittle\",\"whittle_activity\",\"greedy\",\"shapley_whittle\",\"whittle_greedy\"]\n",
    "nice_names = [\"Combined Whittle\",\"Pure Whittle\",\"Greedy\",\"Shapley+Whittle\",\"Greedy+Whittle\"]\n",
    "\n",
    "if n_arms * n_volunteers <= 6:\n",
    "    names.append(\"optimal\")\n",
    "    nice_names.append(\"Optimal\")\n",
    "\n",
    "plot_tradeoff_curve(data_by_arm_volunteer[n_arms][n_volunteers],names,nice_names,\"{} arms, {} Volunteers/Arm\".format(n_arms,n_volunteers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_arms = 16\n",
    "n_volunteers = 2\n",
    "\n",
    "names = [\"whittle\",\"greedy\",\"shapley_whittle\",\"whittle_greedy\"]\n",
    "nice_names = [\"Combined Whittle\",\"Greedy\",\"Shapley+Whittle\",\"Greedy+Whittle\"]\n",
    "\n",
    "if n_arms * n_volunteers <= 6:\n",
    "    names.append(\"optimal\")\n",
    "    nice_names.append(\"Optimal\")\n",
    "\n",
    "plot_tradeoff_curve(data_by_arm_volunteer[n_arms][n_volunteers],names,nice_names,\"{} arms, {} Volunteers/Arm\".format(n_arms,n_volunteers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_arms = 16\n",
    "n_volunteers = 16\n",
    "\n",
    "names = [\"whittle\",\"greedy\",\"shapley_whittle\",\"whittle_greedy\"]\n",
    "nice_names = [\"Combined Whittle\",\"Greedy\",\"Shapley+Whittle\",\"Greedy+Whittle\"]\n",
    "\n",
    "if n_arms * n_volunteers <= 6:\n",
    "    names.append(\"optimal\")\n",
    "    nice_names.append(\"Optimal\")\n",
    "\n",
    "plot_tradeoff_curve(data_by_arm_volunteer[n_arms][n_volunteers],names,nice_names,\"{} arms, {} Volunteers/Arm\".format(n_arms,n_volunteers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "food",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
