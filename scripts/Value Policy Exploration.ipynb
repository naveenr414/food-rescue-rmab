{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Semi Synthetic Experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analyze the performance of various algorithms to solve the joint matching + activity task, when the number of volunteers is large and structured"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random \n",
    "import matplotlib.pyplot as plt\n",
    "import json \n",
    "import argparse \n",
    "import sys\n",
    "import secrets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr0/home/naveenr/miniconda3/envs/food/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from rmab.simulator import RMABSimulator\n",
    "from rmab.omniscient_policies import *\n",
    "from rmab.fr_dynamics import get_all_transitions\n",
    "from rmab.mcts_policies import full_mcts_policy, get_policy_network_input\n",
    "from rmab.utils import get_save_path, delete_duplicate_results, create_prob_distro\n",
    "import resource"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.set_per_process_memory_fraction(0.5)\n",
    "torch.set_num_threads(1)\n",
    "resource.setrlimit(resource.RLIMIT_AS, (30 * 1024 * 1024 * 1024, -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "is_jupyter = 'ipykernel' in sys.modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "if is_jupyter: \n",
    "    seed        = 42\n",
    "    n_arms      = 2\n",
    "    volunteers_per_arm = 2\n",
    "    budget      = 3\n",
    "    discount    = 0.9\n",
    "    alpha       = 3 \n",
    "    n_episodes  = 200\n",
    "    episode_len = 20 \n",
    "    n_epochs    = 1 \n",
    "    save_with_date = False \n",
    "    TIME_PER_RUN = 0.01 * 1000\n",
    "    lamb = 0.5\n",
    "    prob_distro = 'uniform'\n",
    "    policy_lr=5e-3\n",
    "    value_lr=0.1\n",
    "    train_iterations = 30\n",
    "    test_iterations = 30\n",
    "    out_folder = 'value_policy_exploration/exploration'\n",
    "else:\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument('--n_arms',         '-N', help='num beneficiaries (arms)', type=int, default=2)\n",
    "    parser.add_argument('--volunteers_per_arm',         '-V', help='volunteers per arm', type=int, default=5)\n",
    "    parser.add_argument('--episode_len',    '-H', help='episode length', type=int, default=20)\n",
    "    parser.add_argument('--n_episodes',     '-T', help='num episodes', type=int, default=200)\n",
    "    parser.add_argument('--budget',         '-B', help='budget', type=int, default=3)\n",
    "    parser.add_argument('--n_epochs',       '-E', help='number of epochs (num_repeats)', type=int, default=1)\n",
    "    parser.add_argument('--discount',       '-d', help='discount factor', type=float, default=0.9)\n",
    "    parser.add_argument('--alpha',          '-a', help='alpha: for conf radius', type=float, default=3)\n",
    "    parser.add_argument('--lamb',          '-l', help='lambda for matching-engagement tradeoff', type=float, default=0.5)\n",
    "    parser.add_argument('--seed',           '-s', help='random seed', type=int, default=42)\n",
    "    parser.add_argument('--prob_distro',           '-p', help='which prob distro [uniform,uniform_small,uniform_large,normal]', type=str, default='uniform')\n",
    "    parser.add_argument('--time_per_run',      '-t', help='time per MCTS run', type=float, default=.01*1000)\n",
    "    parser.add_argument('--policy_lr', help='Learning Rate Policy', type=float, default=5e-3)\n",
    "    parser.add_argument('--value_lr', help='Learning Rate Value', type=float, default=1e-4)\n",
    "    parser.add_argument('--train_iterations', help='Number of MCTS train iterations', type=int, default=30)\n",
    "    parser.add_argument('--test_iterations', help='Number of MCTS test iterations', type=int, default=30)\n",
    "    parser.add_argument('--out_folder', help='Which folder to write results to', type=str, default='semi_synthetic_mcts')\n",
    "\n",
    "    parser.add_argument('--use_date', action='store_true')\n",
    "\n",
    "    args = parser.parse_args()\n",
    "\n",
    "    n_arms      = args.n_arms\n",
    "    volunteers_per_arm = args.volunteers_per_arm\n",
    "    budget      = args.budget\n",
    "    discount    = args.discount\n",
    "    alpha       = args.alpha \n",
    "    seed        = args.seed\n",
    "    n_episodes  = args.n_episodes\n",
    "    episode_len = args.episode_len\n",
    "    n_epochs    = args.n_epochs\n",
    "    lamb = args.lamb\n",
    "    save_with_date = args.use_date\n",
    "    TIME_PER_RUN = args.time_per_run\n",
    "    prob_distro = args.prob_distro\n",
    "    policy_lr = args.policy_lr \n",
    "    value_lr = args.value_lr \n",
    "    out_folder = args.out_folder\n",
    "    train_iterations = args.train_iterations \n",
    "    test_iterations = args.test_iterations \n",
    "\n",
    "save_name = secrets.token_hex(4)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_states = 2\n",
    "n_actions = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_population_size = 100 # number of random arms to generate\n",
    "all_transitions = get_all_transitions(all_population_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_environment(seed):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "\n",
    "    if prob_distro == 'uniform':\n",
    "        match_probabilities = [np.random.random() for i in range(all_population_size * volunteers_per_arm)] \n",
    "    elif prob_distro == 'uniform_small':\n",
    "        match_probabilities = [np.random.random()/4 for i in range(all_population_size * volunteers_per_arm)] \n",
    "    elif prob_distro == 'uniform_large':\n",
    "        match_probabilities = [np.random.random()/4+0.75 for i in range(all_population_size * volunteers_per_arm)] \n",
    "    elif prob_distro == 'normal':\n",
    "        match_probabilities = [np.clip(np.random.normal(0.25, 0.1),0,1) for i in range(all_population_size * volunteers_per_arm)] \n",
    "\n",
    "    all_features = np.arange(all_population_size)\n",
    "    match_probabilities = create_prob_distro(prob_distro,all_population_size*volunteers_per_arm)\n",
    "    simulator = RMABSimulator(all_population_size, all_features, all_transitions,\n",
    "                n_arms, volunteers_per_arm, episode_len, n_epochs, n_episodes, budget, discount,number_states=n_states, reward_style='match',match_probability_list=match_probabilities,TIME_PER_RUN=TIME_PER_RUN)\n",
    "\n",
    "    return simulator "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_multi_seed(seed_list,policy,is_mcts=False,per_epoch_function=None,train_iterations=0,test_iterations=0,test_length=500):\n",
    "    memories = []\n",
    "    scores = {\n",
    "        'reward': [],\n",
    "        'time': [], \n",
    "        'match': [], \n",
    "        'active_rate': [],\n",
    "    }\n",
    "\n",
    "    for seed in seed_list:\n",
    "        simulator = create_environment(seed)\n",
    "        if is_mcts:\n",
    "            simulator.mcts_train_iterations = train_iterations\n",
    "            simulator.mcts_test_iterations = test_iterations\n",
    "            simulator.policy_lr = policy_lr\n",
    "            simulator.value_lr = value_lr\n",
    "\n",
    "        if is_mcts:\n",
    "            match, active_rate, memory = run_heterogenous_policy(simulator, n_episodes, n_epochs, discount,policy,seed,lamb=lamb,should_train=True,test_T=test_length,get_memory=True,per_epoch_function=per_epoch_function)\n",
    "        else:\n",
    "            match, active_rate = run_heterogenous_policy(simulator, n_episodes, n_epochs, discount,policy,seed,lamb=lamb,should_train=True,test_T=test_length,per_epoch_function=per_epoch_function)\n",
    "        time_whittle = simulator.time_taken\n",
    "        discounted_reward = get_discounted_reward(match,active_rate,discount,lamb)\n",
    "        scores['reward'].append(discounted_reward)\n",
    "        scores['time'].append(time_whittle)\n",
    "        scores['match'].append(np.mean(match))\n",
    "        scores['active_rate'].append(np.mean(active_rate))\n",
    "        if is_mcts:\n",
    "            memories.append(memory)\n",
    "\n",
    "    return scores, memories, simulator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = {}\n",
    "results['parameters'] = {'seed'      : seed,\n",
    "        'n_arms'    : n_arms,\n",
    "        'volunteers_per_arm': volunteers_per_arm, \n",
    "        'budget'    : budget,\n",
    "        'discount'  : discount, \n",
    "        'alpha'     : alpha, \n",
    "        'n_episodes': n_episodes, \n",
    "        'episode_len': episode_len, \n",
    "        'n_epochs'  : n_epochs, \n",
    "        'lamb': lamb,\n",
    "        'time_per_run': TIME_PER_RUN, \n",
    "        'prob_distro': prob_distro, \n",
    "        'policy_lr': policy_lr, \n",
    "        'value_lr': value_lr, \n",
    "        'train_iterations': train_iterations, \n",
    "        'test_iterations': test_iterations,} "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Index Policies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_list = [seed]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acting should always be good! 0.000 < 0.044\n",
      "acting should always be good! 0.000 < 0.162\n",
      "acting should always be good! 0.108 < 0.183\n",
      "good start state should always be good! 0.380 < 0.508\n",
      "good start state should always be good! 0.506 < 0.760\n",
      "cohort [73 66]\n",
      "instance 0, ep 1\n",
      "Input tensor([[0.1863, 0.5114, 0.4432, 0.7202, 0.6351, 1.0000, 1.0000, 1.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.1863, 0.5114, 0.4432, 0.7202, 0.0453, 1.0000, 1.0000, 1.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.2156, 0.4923, 0.4462, 0.7453, 0.0144, 0.0000, 1.0000, 1.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.2156, 0.4923, 0.4462, 0.7453, 0.1161, 0.0000, 1.0000, 1.0000, 0.0000,\n",
      "         0.0000]])\n",
      "Output tensor([[0.5417],\n",
      "        [0.5340],\n",
      "        [0.5255],\n",
      "        [0.5251]], grad_fn=<SigmoidBackward>), target tensor([1., 0., 1., 1.])\n",
      "Input tensor([[0.1863, 0.5114, 0.4432, 0.7202, 0.6351, 1.0000, 1.0000, 1.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.1863, 0.5114, 0.4432, 0.7202, 0.0453, 1.0000, 1.0000, 1.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.2156, 0.4923, 0.4462, 0.7453, 0.0144, 0.0000, 1.0000, 1.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.2156, 0.4923, 0.4462, 0.7453, 0.1161, 0.0000, 1.0000, 1.0000, 0.0000,\n",
      "         0.0000]])\n",
      "Output tensor([[0.5865],\n",
      "        [0.5732],\n",
      "        [0.5747],\n",
      "        [0.5755]], grad_fn=<SigmoidBackward>), target tensor([1., 0., 1., 1.])\n",
      "Input tensor([[0.1863, 0.5114, 0.4432, 0.7202, 0.6351, 1.0000, 1.0000, 1.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.1863, 0.5114, 0.4432, 0.7202, 0.0453, 1.0000, 1.0000, 1.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.2156, 0.4923, 0.4462, 0.7453, 0.0144, 0.0000, 1.0000, 1.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.2156, 0.4923, 0.4462, 0.7453, 0.1161, 0.0000, 1.0000, 1.0000, 0.0000,\n",
      "         0.0000]])\n",
      "Output tensor([[0.6292],\n",
      "        [0.6119],\n",
      "        [0.6220],\n",
      "        [0.6234]], grad_fn=<SigmoidBackward>), target tensor([1., 0., 1., 1.])\n",
      "Input tensor([[0.1863, 0.5114, 0.4432, 0.7202, 0.6351, 1.0000, 1.0000, 1.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.1863, 0.5114, 0.4432, 0.7202, 0.0453, 1.0000, 1.0000, 1.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.2156, 0.4923, 0.4462, 0.7453, 0.0144, 0.0000, 1.0000, 1.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.2156, 0.4923, 0.4462, 0.7453, 0.1161, 0.0000, 1.0000, 1.0000, 0.0000,\n",
      "         0.0000]])\n",
      "Output tensor([[0.6684],\n",
      "        [0.6478],\n",
      "        [0.6663],\n",
      "        [0.6681]], grad_fn=<SigmoidBackward>), target tensor([1., 0., 1., 1.])\n",
      "Input tensor([[0.1863, 0.5114, 0.4432, 0.7202, 0.6351, 1.0000, 1.0000, 1.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.1863, 0.5114, 0.4432, 0.7202, 0.0453, 1.0000, 1.0000, 1.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.2156, 0.4923, 0.4462, 0.7453, 0.0144, 0.0000, 1.0000, 1.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.2156, 0.4923, 0.4462, 0.7453, 0.1161, 0.0000, 1.0000, 1.0000, 0.0000,\n",
      "         0.0000]])\n",
      "Output tensor([[0.7030],\n",
      "        [0.6798],\n",
      "        [0.7064],\n",
      "        [0.7085]], grad_fn=<SigmoidBackward>), target tensor([1., 0., 1., 1.])\n",
      "Input tensor([[0.1863, 0.5114, 0.4432, 0.7202, 0.6351, 1.0000, 1.0000, 1.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.1863, 0.5114, 0.4432, 0.7202, 0.0453, 1.0000, 1.0000, 1.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.2156, 0.4923, 0.4462, 0.7453, 0.0144, 0.0000, 1.0000, 1.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.2156, 0.4923, 0.4462, 0.7453, 0.1161, 0.0000, 1.0000, 1.0000, 0.0000,\n",
      "         0.0000]])\n",
      "Output tensor([[0.7332],\n",
      "        [0.7075],\n",
      "        [0.7412],\n",
      "        [0.7439]], grad_fn=<SigmoidBackward>), target tensor([1., 0., 1., 1.])\n",
      "Input tensor([[0.1863, 0.5114, 0.4432, 0.7202, 0.6351, 1.0000, 1.0000, 1.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.1863, 0.5114, 0.4432, 0.7202, 0.0453, 1.0000, 1.0000, 1.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.2156, 0.4923, 0.4462, 0.7453, 0.0144, 0.0000, 1.0000, 1.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.2156, 0.4923, 0.4462, 0.7453, 0.1161, 0.0000, 1.0000, 1.0000, 0.0000,\n",
      "         0.0000]])\n",
      "Output tensor([[0.7585],\n",
      "        [0.7305],\n",
      "        [0.7704],\n",
      "        [0.7732]], grad_fn=<SigmoidBackward>), target tensor([1., 0., 1., 1.])\n",
      "Input tensor([[0.1863, 0.5114, 0.4432, 0.7202, 0.6351, 1.0000, 1.0000, 1.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.1863, 0.5114, 0.4432, 0.7202, 0.0453, 1.0000, 1.0000, 1.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.2156, 0.4923, 0.4462, 0.7453, 0.0144, 0.0000, 1.0000, 1.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.2156, 0.4923, 0.4462, 0.7453, 0.1161, 0.0000, 1.0000, 1.0000, 0.0000,\n",
      "         0.0000]])\n",
      "Output tensor([[0.7782],\n",
      "        [0.7474],\n",
      "        [0.7936],\n",
      "        [0.7967]], grad_fn=<SigmoidBackward>), target tensor([1., 0., 1., 1.])\n",
      "Input tensor([[0.1863, 0.5114, 0.4432, 0.7202, 0.6351, 1.0000, 1.0000, 1.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.1863, 0.5114, 0.4432, 0.7202, 0.0453, 1.0000, 1.0000, 1.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.2156, 0.4923, 0.4462, 0.7453, 0.0144, 0.0000, 1.0000, 1.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.2156, 0.4923, 0.4462, 0.7453, 0.1161, 0.0000, 1.0000, 1.0000, 0.0000,\n",
      "         0.0000]])\n",
      "Output tensor([[0.7922],\n",
      "        [0.7589],\n",
      "        [0.8111],\n",
      "        [0.8143]], grad_fn=<SigmoidBackward>), target tensor([1., 0., 1., 1.])\n",
      "Input tensor([[0.1863, 0.5114, 0.4432, 0.7202, 0.6351, 1.0000, 1.0000, 1.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.1863, 0.5114, 0.4432, 0.7202, 0.0453, 1.0000, 1.0000, 1.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.2156, 0.4923, 0.4462, 0.7453, 0.0144, 0.0000, 1.0000, 1.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.2156, 0.4923, 0.4462, 0.7453, 0.1161, 0.0000, 1.0000, 1.0000, 0.0000,\n",
      "         0.0000]])\n",
      "Output tensor([[0.8013],\n",
      "        [0.7649],\n",
      "        [0.8232],\n",
      "        [0.8266]], grad_fn=<SigmoidBackward>), target tensor([1., 0., 1., 1.])\n",
      "Input tensor([[0.1863, 0.5114, 0.4432, 0.7202, 0.6351, 1.0000, 1.0000, 1.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.1863, 0.5114, 0.4432, 0.7202, 0.0453, 1.0000, 1.0000, 1.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.2156, 0.4923, 0.4462, 0.7453, 0.0144, 0.0000, 1.0000, 1.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.2156, 0.4923, 0.4462, 0.7453, 0.1161, 0.0000, 1.0000, 1.0000, 0.0000,\n",
      "         0.0000]])\n",
      "Output tensor([[0.8055],\n",
      "        [0.7649],\n",
      "        [0.8307],\n",
      "        [0.8342]], grad_fn=<SigmoidBackward>), target tensor([1., 0., 1., 1.])\n",
      "Input tensor([[0.1863, 0.5114, 0.4432, 0.7202, 0.6351, 1.0000, 1.0000, 1.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.1863, 0.5114, 0.4432, 0.7202, 0.0453, 1.0000, 1.0000, 1.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.2156, 0.4923, 0.4462, 0.7453, 0.0144, 0.0000, 1.0000, 1.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.2156, 0.4923, 0.4462, 0.7453, 0.1161, 0.0000, 1.0000, 1.0000, 0.0000,\n",
      "         0.0000]])\n",
      "Output tensor([[0.8055],\n",
      "        [0.7597],\n",
      "        [0.8341],\n",
      "        [0.8380]], grad_fn=<SigmoidBackward>), target tensor([1., 0., 1., 1.])\n",
      "Input tensor([[0.1863, 0.5114, 0.4432, 0.7202, 0.6351, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         1.0000],\n",
      "        [0.1863, 0.5114, 0.4432, 0.7202, 0.0453, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         1.0000],\n",
      "        [0.2156, 0.4923, 0.4462, 0.7453, 0.0144, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         1.0000],\n",
      "        [0.2156, 0.4923, 0.4462, 0.7453, 0.1161, 1.0000, 0.0000, 0.0000, 0.0000,\n",
      "         1.0000]])\n",
      "Output tensor([[0.7891],\n",
      "        [0.7603],\n",
      "        [0.7613],\n",
      "        [0.7057]], grad_fn=<SigmoidBackward>), target tensor([1., 0., 1., 1.])\n",
      "Input tensor([[0.1863, 0.5114, 0.4432, 0.7202, 0.6351, 1.0000, 1.0000, 1.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.1863, 0.5114, 0.4432, 0.7202, 0.0453, 1.0000, 1.0000, 1.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.2156, 0.4923, 0.4462, 0.7453, 0.0144, 0.0000, 1.0000, 1.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.2156, 0.4923, 0.4462, 0.7453, 0.1161, 0.0000, 1.0000, 1.0000, 0.0000,\n",
      "         0.0000]])\n",
      "Output tensor([[0.7990],\n",
      "        [0.7407],\n",
      "        [0.8337],\n",
      "        [0.8385]], grad_fn=<SigmoidBackward>), target tensor([1., 0., 1., 1.])\n",
      "Input tensor([[0.1863, 0.5114, 0.4432, 0.7202, 0.6351, 1.0000, 1.0000, 0.0000, 1.0000,\n",
      "         0.0000],\n",
      "        [0.1863, 0.5114, 0.4432, 0.7202, 0.0453, 0.0000, 1.0000, 0.0000, 1.0000,\n",
      "         0.0000],\n",
      "        [0.2156, 0.4923, 0.4462, 0.7453, 0.0144, 1.0000, 1.0000, 0.0000, 1.0000,\n",
      "         0.0000],\n",
      "        [0.2156, 0.4923, 0.4462, 0.7453, 0.1161, 0.0000, 1.0000, 0.0000, 1.0000,\n",
      "         0.0000]])\n",
      "Output tensor([[0.7666],\n",
      "        [0.7816],\n",
      "        [0.7210],\n",
      "        [0.7870]], grad_fn=<SigmoidBackward>), target tensor([1., 1., 1., 0.])\n",
      "Input tensor([[0.1863, 0.5114, 0.4432, 0.7202, 0.6351, 1.0000, 1.0000, 1.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.1863, 0.5114, 0.4432, 0.7202, 0.0453, 1.0000, 1.0000, 1.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.2156, 0.4923, 0.4462, 0.7453, 0.0144, 0.0000, 1.0000, 1.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.2156, 0.4923, 0.4462, 0.7453, 0.1161, 0.0000, 1.0000, 1.0000, 0.0000,\n",
      "         0.0000]])\n",
      "Output tensor([[0.7891],\n",
      "        [0.7181],\n",
      "        [0.8264],\n",
      "        [0.8323]], grad_fn=<SigmoidBackward>), target tensor([1., 0., 1., 1.])\n",
      "Input tensor([[0.1863, 0.5114, 0.4432, 0.7202, 0.6351, 1.0000, 1.0000, 1.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.1863, 0.5114, 0.4432, 0.7202, 0.0453, 1.0000, 1.0000, 1.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.2156, 0.4923, 0.4462, 0.7453, 0.0144, 0.0000, 1.0000, 1.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.2156, 0.4923, 0.4462, 0.7453, 0.1161, 0.0000, 1.0000, 1.0000, 0.0000,\n",
      "         0.0000]])\n",
      "Output tensor([[0.7823],\n",
      "        [0.7042],\n",
      "        [0.8212],\n",
      "        [0.8276]], grad_fn=<SigmoidBackward>), target tensor([1., 0., 1., 1.])\n",
      "Input tensor([[0.1863, 0.5114, 0.4432, 0.7202, 0.6351, 1.0000, 1.0000, 1.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.1863, 0.5114, 0.4432, 0.7202, 0.0453, 1.0000, 1.0000, 1.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.2156, 0.4923, 0.4462, 0.7453, 0.0144, 0.0000, 1.0000, 1.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.2156, 0.4923, 0.4462, 0.7453, 0.1161, 0.0000, 1.0000, 1.0000, 0.0000,\n",
      "         0.0000]])\n",
      "Output tensor([[0.7742],\n",
      "        [0.6874],\n",
      "        [0.8152],\n",
      "        [0.8222]], grad_fn=<SigmoidBackward>), target tensor([1., 0., 1., 1.])\n",
      "Input tensor([[0.1863, 0.5114, 0.4432, 0.7202, 0.6351, 1.0000, 1.0000, 1.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.1863, 0.5114, 0.4432, 0.7202, 0.0453, 1.0000, 1.0000, 1.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.2156, 0.4923, 0.4462, 0.7453, 0.0144, 0.0000, 1.0000, 1.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.2156, 0.4923, 0.4462, 0.7453, 0.1161, 0.0000, 1.0000, 1.0000, 0.0000,\n",
      "         0.0000]])\n",
      "Output tensor([[0.7648],\n",
      "        [0.6686],\n",
      "        [0.8088],\n",
      "        [0.8165]], grad_fn=<SigmoidBackward>), target tensor([1., 0., 1., 1.])\n",
      "Input tensor([[0.1863, 0.5114, 0.4432, 0.7202, 0.6351, 1.0000, 1.0000, 1.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.1863, 0.5114, 0.4432, 0.7202, 0.0453, 1.0000, 1.0000, 1.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.2156, 0.4923, 0.4462, 0.7453, 0.0144, 0.0000, 1.0000, 1.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.2156, 0.4923, 0.4462, 0.7453, 0.1161, 0.0000, 1.0000, 1.0000, 0.0000,\n",
      "         0.0000]])\n",
      "Output tensor([[0.7552],\n",
      "        [0.6486],\n",
      "        [0.8027],\n",
      "        [0.8111]], grad_fn=<SigmoidBackward>), target tensor([1., 0., 1., 1.])\n",
      "Input tensor([[0.1863, 0.5114, 0.4432, 0.7202, 0.6351, 1.0000, 1.0000, 1.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.1863, 0.5114, 0.4432, 0.7202, 0.0453, 1.0000, 1.0000, 1.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.2156, 0.4923, 0.4462, 0.7453, 0.0144, 0.0000, 1.0000, 1.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.2156, 0.4923, 0.4462, 0.7453, 0.1161, 0.0000, 1.0000, 1.0000, 0.0000,\n",
      "         0.0000]])\n",
      "Output tensor([[0.7470],\n",
      "        [0.6289],\n",
      "        [0.7978],\n",
      "        [0.8070]], grad_fn=<SigmoidBackward>), target tensor([1., 0., 1., 1.])\n",
      "Input tensor([[0.1863, 0.5114, 0.4432, 0.7202, 0.6351, 1.0000, 1.0000, 1.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.1863, 0.5114, 0.4432, 0.7202, 0.0453, 1.0000, 1.0000, 1.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.2156, 0.4923, 0.4462, 0.7453, 0.0144, 0.0000, 1.0000, 1.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.2156, 0.4923, 0.4462, 0.7453, 0.1161, 0.0000, 1.0000, 1.0000, 0.0000,\n",
      "         0.0000]])\n",
      "Output tensor([[0.7412],\n",
      "        [0.6126],\n",
      "        [0.7947],\n",
      "        [0.8047]], grad_fn=<SigmoidBackward>), target tensor([1., 0., 1., 1.])\n",
      "Input tensor([[0.1863, 0.5114, 0.4432, 0.7202, 0.6351, 1.0000, 1.0000, 1.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.1863, 0.5114, 0.4432, 0.7202, 0.0453, 1.0000, 1.0000, 1.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.2156, 0.4923, 0.4462, 0.7453, 0.0144, 0.0000, 1.0000, 1.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.2156, 0.4923, 0.4462, 0.7453, 0.1161, 0.0000, 1.0000, 1.0000, 0.0000,\n",
      "         0.0000]])\n",
      "Output tensor([[0.7370],\n",
      "        [0.5978],\n",
      "        [0.7935],\n",
      "        [0.8041]], grad_fn=<SigmoidBackward>), target tensor([1., 0., 1., 1.])\n",
      "Input tensor([[0.1863, 0.5114, 0.4432, 0.7202, 0.6351, 1.0000, 1.0000, 1.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.1863, 0.5114, 0.4432, 0.7202, 0.0453, 1.0000, 1.0000, 1.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.2156, 0.4923, 0.4462, 0.7453, 0.0144, 0.0000, 1.0000, 1.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.2156, 0.4923, 0.4462, 0.7453, 0.1161, 0.0000, 1.0000, 1.0000, 0.0000,\n",
      "         0.0000]])\n",
      "Output tensor([[0.7350],\n",
      "        [0.5850],\n",
      "        [0.7945],\n",
      "        [0.8059]], grad_fn=<SigmoidBackward>), target tensor([1., 0., 1., 1.])\n",
      "Input tensor([[0.1863, 0.5114, 0.4432, 0.7202, 0.6351, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "         1.0000],\n",
      "        [0.1863, 0.5114, 0.4432, 0.7202, 0.0453, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "         1.0000],\n",
      "        [0.2156, 0.4923, 0.4462, 0.7453, 0.0144, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "         1.0000],\n",
      "        [0.2156, 0.4923, 0.4462, 0.7453, 0.1161, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "         1.0000]])\n",
      "Output tensor([[0.7267],\n",
      "        [0.6211],\n",
      "        [0.6189],\n",
      "        [0.6373]], grad_fn=<SigmoidBackward>), target tensor([1., 1., 0., 1.])\n",
      "instance 0, ep 2\n",
      "Input tensor([[0.1863, 0.5114, 0.4432, 0.7202, 0.6351, 1.0000, 1.0000, 1.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.1863, 0.5114, 0.4432, 0.7202, 0.0453, 1.0000, 1.0000, 1.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.2156, 0.4923, 0.4462, 0.7453, 0.0144, 0.0000, 1.0000, 1.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.2156, 0.4923, 0.4462, 0.7453, 0.1161, 0.0000, 1.0000, 1.0000, 0.0000,\n",
      "         0.0000]])\n",
      "Output tensor([[0.7455],\n",
      "        [0.5769],\n",
      "        [0.8073],\n",
      "        [0.8197]], grad_fn=<SigmoidBackward>), target tensor([1., 0., 1., 1.])\n",
      "Input tensor([[0.1863, 0.5114, 0.4432, 0.7202, 0.6351, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "         1.0000],\n",
      "        [0.1863, 0.5114, 0.4432, 0.7202, 0.0453, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "         1.0000],\n",
      "        [0.2156, 0.4923, 0.4462, 0.7453, 0.0144, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "         1.0000],\n",
      "        [0.2156, 0.4923, 0.4462, 0.7453, 0.1161, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "         1.0000]])\n",
      "Output tensor([[0.7631],\n",
      "        [0.6476],\n",
      "        [0.6445],\n",
      "        [0.6662]], grad_fn=<SigmoidBackward>), target tensor([1., 1., 0., 1.])\n",
      "Input tensor([[0.1863, 0.5114, 0.4432, 0.7202, 0.6351, 1.0000, 1.0000, 1.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.1863, 0.5114, 0.4432, 0.7202, 0.0453, 1.0000, 1.0000, 1.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.2156, 0.4923, 0.4462, 0.7453, 0.0144, 0.0000, 1.0000, 1.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.2156, 0.4923, 0.4462, 0.7453, 0.1161, 0.0000, 1.0000, 1.0000, 0.0000,\n",
      "         0.0000]])\n",
      "Output tensor([[0.7743],\n",
      "        [0.5926],\n",
      "        [0.8319],\n",
      "        [0.8445]], grad_fn=<SigmoidBackward>), target tensor([1., 0., 1., 1.])\n",
      "Input tensor([[0.1863, 0.5114, 0.4432, 0.7202, 0.6351, 1.0000, 1.0000, 1.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.1863, 0.5114, 0.4432, 0.7202, 0.0453, 1.0000, 1.0000, 1.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.2156, 0.4923, 0.4462, 0.7453, 0.0144, 0.0000, 1.0000, 1.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.2156, 0.4923, 0.4462, 0.7453, 0.1161, 0.0000, 1.0000, 1.0000, 0.0000,\n",
      "         0.0000]])\n",
      "Output tensor([[0.7880],\n",
      "        [0.6005],\n",
      "        [0.8437],\n",
      "        [0.8563]], grad_fn=<SigmoidBackward>), target tensor([1., 0., 1., 1.])\n",
      "Input tensor([[0.1863, 0.5114, 0.4432, 0.7202, 0.6351, 1.0000, 1.0000, 1.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.1863, 0.5114, 0.4432, 0.7202, 0.0453, 1.0000, 1.0000, 1.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.2156, 0.4923, 0.4462, 0.7453, 0.0144, 0.0000, 1.0000, 1.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.2156, 0.4923, 0.4462, 0.7453, 0.1161, 0.0000, 1.0000, 1.0000, 0.0000,\n",
      "         0.0000]])\n",
      "Output tensor([[0.7973],\n",
      "        [0.6031],\n",
      "        [0.8530],\n",
      "        [0.8657]], grad_fn=<SigmoidBackward>), target tensor([1., 0., 1., 1.])\n",
      "Input tensor([[0.1863, 0.5114, 0.4432, 0.7202, 0.6351, 1.0000, 1.0000, 1.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.1863, 0.5114, 0.4432, 0.7202, 0.0453, 1.0000, 1.0000, 1.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.2156, 0.4923, 0.4462, 0.7453, 0.0144, 0.0000, 1.0000, 1.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.2156, 0.4923, 0.4462, 0.7453, 0.1161, 0.0000, 1.0000, 1.0000, 0.0000,\n",
      "         0.0000]])\n",
      "Output tensor([[0.8024],\n",
      "        [0.5994],\n",
      "        [0.8595],\n",
      "        [0.8724]], grad_fn=<SigmoidBackward>), target tensor([1., 0., 1., 1.])\n",
      "Input tensor([[0.1863, 0.5114, 0.4432, 0.7202, 0.6351, 1.0000, 1.0000, 1.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.1863, 0.5114, 0.4432, 0.7202, 0.0453, 1.0000, 1.0000, 1.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.2156, 0.4923, 0.4462, 0.7453, 0.0144, 0.0000, 1.0000, 1.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.2156, 0.4923, 0.4462, 0.7453, 0.1161, 0.0000, 1.0000, 1.0000, 0.0000,\n",
      "         0.0000]])\n",
      "Output tensor([[0.8041],\n",
      "        [0.5898],\n",
      "        [0.8633],\n",
      "        [0.8766]], grad_fn=<SigmoidBackward>), target tensor([1., 0., 1., 1.])\n",
      "Input tensor([[0.1863, 0.5114, 0.4432, 0.7202, 0.6351, 1.0000, 1.0000, 1.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.1863, 0.5114, 0.4432, 0.7202, 0.0453, 1.0000, 1.0000, 1.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.2156, 0.4923, 0.4462, 0.7453, 0.0144, 0.0000, 1.0000, 1.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.2156, 0.4923, 0.4462, 0.7453, 0.1161, 0.0000, 1.0000, 1.0000, 0.0000,\n",
      "         0.0000]])\n",
      "Output tensor([[0.8031],\n",
      "        [0.5752],\n",
      "        [0.8649],\n",
      "        [0.8788]], grad_fn=<SigmoidBackward>), target tensor([1., 0., 1., 1.])\n",
      "Input tensor([[0.1863, 0.5114, 0.4432, 0.7202, 0.6351, 1.0000, 1.0000, 1.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.1863, 0.5114, 0.4432, 0.7202, 0.0453, 1.0000, 1.0000, 1.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.2156, 0.4923, 0.4462, 0.7453, 0.0144, 0.0000, 1.0000, 1.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.2156, 0.4923, 0.4462, 0.7453, 0.1161, 0.0000, 1.0000, 1.0000, 0.0000,\n",
      "         0.0000]])\n",
      "Output tensor([[0.8003],\n",
      "        [0.5561],\n",
      "        [0.8647],\n",
      "        [0.8794]], grad_fn=<SigmoidBackward>), target tensor([1., 0., 1., 1.])\n",
      "Input tensor([[0.1863, 0.5114, 0.4432, 0.7202, 0.6351, 1.0000, 1.0000, 1.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.1863, 0.5114, 0.4432, 0.7202, 0.0453, 1.0000, 1.0000, 1.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.2156, 0.4923, 0.4462, 0.7453, 0.0144, 0.0000, 1.0000, 1.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.2156, 0.4923, 0.4462, 0.7453, 0.1161, 0.0000, 1.0000, 1.0000, 0.0000,\n",
      "         0.0000]])\n",
      "Output tensor([[0.7963],\n",
      "        [0.5350],\n",
      "        [0.8631],\n",
      "        [0.8788]], grad_fn=<SigmoidBackward>), target tensor([1., 0., 1., 1.])\n",
      "Input tensor([[0.1863, 0.5114, 0.4432, 0.7202, 0.6351, 1.0000, 1.0000, 1.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.1863, 0.5114, 0.4432, 0.7202, 0.0453, 1.0000, 1.0000, 1.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.2156, 0.4923, 0.4462, 0.7453, 0.0144, 0.0000, 1.0000, 1.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.2156, 0.4923, 0.4462, 0.7453, 0.1161, 0.0000, 1.0000, 1.0000, 0.0000,\n",
      "         0.0000]])\n",
      "Output tensor([[0.7920],\n",
      "        [0.5123],\n",
      "        [0.8610],\n",
      "        [0.8776]], grad_fn=<SigmoidBackward>), target tensor([1., 0., 1., 1.])\n",
      "Input tensor([[0.1863, 0.5114, 0.4432, 0.7202, 0.6351, 1.0000, 1.0000, 1.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.1863, 0.5114, 0.4432, 0.7202, 0.0453, 1.0000, 1.0000, 1.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.2156, 0.4923, 0.4462, 0.7453, 0.0144, 0.0000, 1.0000, 1.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.2156, 0.4923, 0.4462, 0.7453, 0.1161, 0.0000, 1.0000, 1.0000, 0.0000,\n",
      "         0.0000]])\n",
      "Output tensor([[0.7883],\n",
      "        [0.4879],\n",
      "        [0.8592],\n",
      "        [0.8769]], grad_fn=<SigmoidBackward>), target tensor([1., 0., 1., 1.])\n",
      "Input tensor([[0.1863, 0.5114, 0.4432, 0.7202, 0.6351, 1.0000, 1.0000, 1.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.1863, 0.5114, 0.4432, 0.7202, 0.0453, 1.0000, 1.0000, 1.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.2156, 0.4923, 0.4462, 0.7453, 0.0144, 0.0000, 1.0000, 1.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.2156, 0.4923, 0.4462, 0.7453, 0.1161, 0.0000, 1.0000, 1.0000, 0.0000,\n",
      "         0.0000]])\n",
      "Output tensor([[0.7852],\n",
      "        [0.4651],\n",
      "        [0.8581],\n",
      "        [0.8769]], grad_fn=<SigmoidBackward>), target tensor([1., 0., 1., 1.])\n",
      "Input tensor([[0.1863, 0.5114, 0.4432, 0.7202, 0.6351, 0.0000, 0.0000, 1.0000, 1.0000,\n",
      "         0.0000],\n",
      "        [0.1863, 0.5114, 0.4432, 0.7202, 0.0453, 1.0000, 0.0000, 1.0000, 1.0000,\n",
      "         0.0000],\n",
      "        [0.2156, 0.4923, 0.4462, 0.7453, 0.0144, 1.0000, 0.0000, 1.0000, 1.0000,\n",
      "         0.0000],\n",
      "        [0.2156, 0.4923, 0.4462, 0.7453, 0.1161, 0.0000, 0.0000, 1.0000, 1.0000,\n",
      "         0.0000]])\n",
      "Output tensor([[0.9521],\n",
      "        [0.6076],\n",
      "        [0.5974],\n",
      "        [0.8860]], grad_fn=<SigmoidBackward>), target tensor([1., 1., 1., 0.])\n",
      "Input tensor([[0.1863, 0.5114, 0.4432, 0.7202, 0.6351, 1.0000, 1.0000, 0.0000, 0.0000,\n",
      "         1.0000],\n",
      "        [0.1863, 0.5114, 0.4432, 0.7202, 0.0453, 0.0000, 1.0000, 0.0000, 0.0000,\n",
      "         1.0000],\n",
      "        [0.2156, 0.4923, 0.4462, 0.7453, 0.0144, 0.0000, 1.0000, 0.0000, 0.0000,\n",
      "         1.0000],\n",
      "        [0.2156, 0.4923, 0.4462, 0.7453, 0.1161, 1.0000, 1.0000, 0.0000, 0.0000,\n",
      "         1.0000]])\n",
      "Output tensor([[0.7730],\n",
      "        [0.8356],\n",
      "        [0.8330],\n",
      "        [0.5684]], grad_fn=<SigmoidBackward>), target tensor([1., 1., 0., 1.])\n",
      "Input tensor([[0.1863, 0.5114, 0.4432, 0.7202, 0.6351, 1.0000, 1.0000, 1.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.1863, 0.5114, 0.4432, 0.7202, 0.0453, 1.0000, 1.0000, 1.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.2156, 0.4923, 0.4462, 0.7453, 0.0144, 0.0000, 1.0000, 1.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.2156, 0.4923, 0.4462, 0.7453, 0.1161, 0.0000, 1.0000, 1.0000, 0.0000,\n",
      "         0.0000]])\n",
      "Output tensor([[0.7857],\n",
      "        [0.4183],\n",
      "        [0.8508],\n",
      "        [0.8732]], grad_fn=<SigmoidBackward>), target tensor([1., 0., 1., 1.])\n",
      "Input tensor([[0.1863, 0.5114, 0.4432, 0.7202, 0.6351, 1.0000, 1.0000, 1.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.1863, 0.5114, 0.4432, 0.7202, 0.0453, 1.0000, 1.0000, 1.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.2156, 0.4923, 0.4462, 0.7453, 0.0144, 0.0000, 1.0000, 1.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.2156, 0.4923, 0.4462, 0.7453, 0.1161, 0.0000, 1.0000, 1.0000, 0.0000,\n",
      "         0.0000]])\n",
      "Output tensor([[0.7925],\n",
      "        [0.4111],\n",
      "        [0.8501],\n",
      "        [0.8734]], grad_fn=<SigmoidBackward>), target tensor([1., 0., 1., 1.])\n",
      "Input tensor([[0.1863, 0.5114, 0.4432, 0.7202, 0.6351, 1.0000, 1.0000, 1.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.1863, 0.5114, 0.4432, 0.7202, 0.0453, 1.0000, 1.0000, 1.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.2156, 0.4923, 0.4462, 0.7453, 0.0144, 0.0000, 1.0000, 1.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.2156, 0.4923, 0.4462, 0.7453, 0.1161, 0.0000, 1.0000, 1.0000, 0.0000,\n",
      "         0.0000]])\n",
      "Output tensor([[0.8029],\n",
      "        [0.4090],\n",
      "        [0.8528],\n",
      "        [0.8767]], grad_fn=<SigmoidBackward>), target tensor([1., 0., 1., 1.])\n",
      "Input tensor([[0.1863, 0.5114, 0.4432, 0.7202, 0.6351, 1.0000, 1.0000, 1.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.1863, 0.5114, 0.4432, 0.7202, 0.0453, 1.0000, 1.0000, 1.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.2156, 0.4923, 0.4462, 0.7453, 0.0144, 0.0000, 1.0000, 1.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.2156, 0.4923, 0.4462, 0.7453, 0.1161, 0.0000, 1.0000, 1.0000, 0.0000,\n",
      "         0.0000]])\n",
      "Output tensor([[0.8145],\n",
      "        [0.4089],\n",
      "        [0.8578],\n",
      "        [0.8819]], grad_fn=<SigmoidBackward>), target tensor([1., 0., 1., 1.])\n",
      "Input tensor([[0.1863, 0.5114, 0.4432, 0.7202, 0.6351, 1.0000, 1.0000, 1.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.1863, 0.5114, 0.4432, 0.7202, 0.0453, 1.0000, 1.0000, 1.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.2156, 0.4923, 0.4462, 0.7453, 0.0144, 0.0000, 1.0000, 1.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.2156, 0.4923, 0.4462, 0.7453, 0.1161, 0.0000, 1.0000, 1.0000, 0.0000,\n",
      "         0.0000]])\n",
      "Output tensor([[0.8258],\n",
      "        [0.4082],\n",
      "        [0.8642],\n",
      "        [0.8881]], grad_fn=<SigmoidBackward>), target tensor([1., 0., 1., 1.])\n",
      "Input tensor([[0.1863, 0.5114, 0.4432, 0.7202, 0.6351, 1.0000, 1.0000, 1.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.1863, 0.5114, 0.4432, 0.7202, 0.0453, 1.0000, 1.0000, 1.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.2156, 0.4923, 0.4462, 0.7453, 0.0144, 0.0000, 1.0000, 1.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.2156, 0.4923, 0.4462, 0.7453, 0.1161, 0.0000, 1.0000, 1.0000, 0.0000,\n",
      "         0.0000]])\n",
      "Output tensor([[0.8353],\n",
      "        [0.4056],\n",
      "        [0.8710],\n",
      "        [0.8946]], grad_fn=<SigmoidBackward>), target tensor([1., 0., 1., 1.])\n",
      "Input tensor([[0.1863, 0.5114, 0.4432, 0.7202, 0.6351, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         1.0000],\n",
      "        [0.1863, 0.5114, 0.4432, 0.7202, 0.0453, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         1.0000],\n",
      "        [0.2156, 0.4923, 0.4462, 0.7453, 0.0144, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         1.0000],\n",
      "        [0.2156, 0.4923, 0.4462, 0.7453, 0.1161, 1.0000, 0.0000, 0.0000, 0.0000,\n",
      "         1.0000]])\n",
      "Output tensor([[0.9565],\n",
      "        [0.8487],\n",
      "        [0.8441],\n",
      "        [0.6180]], grad_fn=<SigmoidBackward>), target tensor([1., 0., 1., 1.])\n",
      "Input tensor([[0.1863, 0.5114, 0.4432, 0.7202, 0.6351, 1.0000, 1.0000, 1.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.1863, 0.5114, 0.4432, 0.7202, 0.0453, 1.0000, 1.0000, 1.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.2156, 0.4923, 0.4462, 0.7453, 0.0144, 0.0000, 1.0000, 1.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.2156, 0.4923, 0.4462, 0.7453, 0.1161, 0.0000, 1.0000, 1.0000, 0.0000,\n",
      "         0.0000]])\n",
      "Output tensor([[0.8476],\n",
      "        [0.3951],\n",
      "        [0.8798],\n",
      "        [0.9034]], grad_fn=<SigmoidBackward>), target tensor([1., 0., 1., 1.])\n",
      "Input tensor([[0.1863, 0.5114, 0.4432, 0.7202, 0.6351, 1.0000, 1.0000, 1.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.1863, 0.5114, 0.4432, 0.7202, 0.0453, 1.0000, 1.0000, 1.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.2156, 0.4923, 0.4462, 0.7453, 0.0144, 0.0000, 1.0000, 1.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.2156, 0.4923, 0.4462, 0.7453, 0.1161, 0.0000, 1.0000, 1.0000, 0.0000,\n",
      "         0.0000]])\n",
      "Output tensor([[0.8512],\n",
      "        [0.3849],\n",
      "        [0.8817],\n",
      "        [0.9057]], grad_fn=<SigmoidBackward>), target tensor([1., 0., 1., 1.])\n",
      "Input tensor([[0.1863, 0.5114, 0.4432, 0.7202, 0.6351, 1.0000, 1.0000, 1.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.1863, 0.5114, 0.4432, 0.7202, 0.0453, 1.0000, 1.0000, 1.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.2156, 0.4923, 0.4462, 0.7453, 0.0144, 0.0000, 1.0000, 1.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.2156, 0.4923, 0.4462, 0.7453, 0.1161, 0.0000, 1.0000, 1.0000, 0.0000,\n",
      "         0.0000]])\n",
      "Output tensor([[0.8538],\n",
      "        [0.3722],\n",
      "        [0.8835],\n",
      "        [0.9079]], grad_fn=<SigmoidBackward>), target tensor([1., 0., 1., 1.])\n",
      "instance 0, ep 3\n",
      "Input tensor([[0.1863, 0.5114, 0.4432, 0.7202, 0.6351, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         1.0000],\n",
      "        [0.1863, 0.5114, 0.4432, 0.7202, 0.0453, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         1.0000],\n",
      "        [0.2156, 0.4923, 0.4462, 0.7453, 0.0144, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         1.0000],\n",
      "        [0.2156, 0.4923, 0.4462, 0.7453, 0.1161, 1.0000, 0.0000, 0.0000, 0.0000,\n",
      "         1.0000]])\n",
      "Output tensor([[0.9608],\n",
      "        [0.8315],\n",
      "        [0.8255],\n",
      "        [0.5886]], grad_fn=<SigmoidBackward>), target tensor([1., 0., 1., 1.])\n",
      "Input tensor([[0.1863, 0.5114, 0.4432, 0.7202, 0.6351, 1.0000, 1.0000, 1.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.1863, 0.5114, 0.4432, 0.7202, 0.0453, 1.0000, 1.0000, 1.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.2156, 0.4923, 0.4462, 0.7453, 0.0144, 0.0000, 1.0000, 1.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.2156, 0.4923, 0.4462, 0.7453, 0.1161, 0.0000, 1.0000, 1.0000, 0.0000,\n",
      "         0.0000]])\n",
      "Output tensor([[0.8576],\n",
      "        [0.3488],\n",
      "        [0.8847],\n",
      "        [0.9107]], grad_fn=<SigmoidBackward>), target tensor([1., 0., 1., 1.])\n",
      "Input tensor([[0.1863, 0.5114, 0.4432, 0.7202, 0.6351, 1.0000, 1.0000, 0.0000, 1.0000,\n",
      "         0.0000],\n",
      "        [0.1863, 0.5114, 0.4432, 0.7202, 0.0453, 0.0000, 1.0000, 0.0000, 1.0000,\n",
      "         0.0000],\n",
      "        [0.2156, 0.4923, 0.4462, 0.7453, 0.0144, 1.0000, 1.0000, 0.0000, 1.0000,\n",
      "         0.0000],\n",
      "        [0.2156, 0.4923, 0.4462, 0.7453, 0.1161, 0.0000, 1.0000, 0.0000, 1.0000,\n",
      "         0.0000]])\n",
      "Output tensor([[0.8723],\n",
      "        [0.8405],\n",
      "        [0.5063],\n",
      "        [0.8642]], grad_fn=<SigmoidBackward>), target tensor([1., 1., 1., 0.])\n",
      "Input tensor([[0.1863, 0.5114, 0.4432, 0.7202, 0.6351, 1.0000, 1.0000, 1.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.1863, 0.5114, 0.4432, 0.7202, 0.0453, 1.0000, 1.0000, 1.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.2156, 0.4923, 0.4462, 0.7453, 0.0144, 0.0000, 1.0000, 1.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.2156, 0.4923, 0.4462, 0.7453, 0.1161, 0.0000, 1.0000, 1.0000, 0.0000,\n",
      "         0.0000]])\n",
      "Output tensor([[0.8643],\n",
      "        [0.3312],\n",
      "        [0.8831],\n",
      "        [0.9109]], grad_fn=<SigmoidBackward>), target tensor([1., 0., 1., 1.])\n",
      "Input tensor([[0.1863, 0.5114, 0.4432, 0.7202, 0.6351, 1.0000, 1.0000, 1.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.1863, 0.5114, 0.4432, 0.7202, 0.0453, 1.0000, 1.0000, 1.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.2156, 0.4923, 0.4462, 0.7453, 0.0144, 0.0000, 1.0000, 1.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.2156, 0.4923, 0.4462, 0.7453, 0.1161, 0.0000, 1.0000, 1.0000, 0.0000,\n",
      "         0.0000]])\n",
      "Output tensor([[0.8692],\n",
      "        [0.3251],\n",
      "        [0.8826],\n",
      "        [0.9112]], grad_fn=<SigmoidBackward>), target tensor([1., 0., 1., 1.])\n",
      "Input tensor([[0.1863, 0.5114, 0.4432, 0.7202, 0.6351, 1.0000, 1.0000, 0.0000, 1.0000,\n",
      "         0.0000],\n",
      "        [0.1863, 0.5114, 0.4432, 0.7202, 0.0453, 0.0000, 1.0000, 0.0000, 1.0000,\n",
      "         0.0000],\n",
      "        [0.2156, 0.4923, 0.4462, 0.7453, 0.0144, 1.0000, 1.0000, 0.0000, 1.0000,\n",
      "         0.0000],\n",
      "        [0.2156, 0.4923, 0.4462, 0.7453, 0.1161, 0.0000, 1.0000, 0.0000, 1.0000,\n",
      "         0.0000]])\n",
      "Output tensor([[0.8833],\n",
      "        [0.8249],\n",
      "        [0.5020],\n",
      "        [0.8508]], grad_fn=<SigmoidBackward>), target tensor([1., 1., 1., 0.])\n",
      "Input tensor([[0.1863, 0.5114, 0.4432, 0.7202, 0.6351, 1.0000, 1.0000, 1.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.1863, 0.5114, 0.4432, 0.7202, 0.0453, 1.0000, 1.0000, 1.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.2156, 0.4923, 0.4462, 0.7453, 0.0144, 0.0000, 1.0000, 1.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.2156, 0.4923, 0.4462, 0.7453, 0.1161, 0.0000, 1.0000, 1.0000, 0.0000,\n",
      "         0.0000]])\n",
      "Output tensor([[0.8809],\n",
      "        [0.3180],\n",
      "        [0.8823],\n",
      "        [0.9120]], grad_fn=<SigmoidBackward>), target tensor([1., 0., 1., 1.])\n",
      "Input tensor([[0.1863, 0.5114, 0.4432, 0.7202, 0.6351, 1.0000, 1.0000, 1.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.1863, 0.5114, 0.4432, 0.7202, 0.0453, 1.0000, 1.0000, 1.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.2156, 0.4923, 0.4462, 0.7453, 0.0144, 0.0000, 1.0000, 1.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.2156, 0.4923, 0.4462, 0.7453, 0.1161, 0.0000, 1.0000, 1.0000, 0.0000,\n",
      "         0.0000]])\n",
      "Output tensor([[0.8867],\n",
      "        [0.3153],\n",
      "        [0.8824],\n",
      "        [0.9124]], grad_fn=<SigmoidBackward>), target tensor([1., 0., 1., 1.])\n",
      "Input tensor([[0.1863, 0.5114, 0.4432, 0.7202, 0.6351, 1.0000, 1.0000, 1.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.1863, 0.5114, 0.4432, 0.7202, 0.0453, 1.0000, 1.0000, 1.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.2156, 0.4923, 0.4462, 0.7453, 0.0144, 0.0000, 1.0000, 1.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.2156, 0.4923, 0.4462, 0.7453, 0.1161, 0.0000, 1.0000, 1.0000, 0.0000,\n",
      "         0.0000]])\n",
      "Output tensor([[0.8916],\n",
      "        [0.3108],\n",
      "        [0.8834],\n",
      "        [0.9135]], grad_fn=<SigmoidBackward>), target tensor([1., 0., 1., 1.])\n",
      "Input tensor([[0.1863, 0.5114, 0.4432, 0.7202, 0.6351, 1.0000, 1.0000, 1.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.1863, 0.5114, 0.4432, 0.7202, 0.0453, 1.0000, 1.0000, 1.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.2156, 0.4923, 0.4462, 0.7453, 0.0144, 0.0000, 1.0000, 1.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.2156, 0.4923, 0.4462, 0.7453, 0.1161, 0.0000, 1.0000, 1.0000, 0.0000,\n",
      "         0.0000]])\n",
      "Output tensor([[0.8964],\n",
      "        [0.3060],\n",
      "        [0.8856],\n",
      "        [0.9157]], grad_fn=<SigmoidBackward>), target tensor([1., 0., 1., 1.])\n",
      "Input tensor([[0.1863, 0.5114, 0.4432, 0.7202, 0.6351, 1.0000, 1.0000, 1.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.1863, 0.5114, 0.4432, 0.7202, 0.0453, 1.0000, 1.0000, 1.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.2156, 0.4923, 0.4462, 0.7453, 0.0144, 0.0000, 1.0000, 1.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.2156, 0.4923, 0.4462, 0.7453, 0.1161, 0.0000, 1.0000, 1.0000, 0.0000,\n",
      "         0.0000]])\n",
      "Output tensor([[0.9009],\n",
      "        [0.2996],\n",
      "        [0.8884],\n",
      "        [0.9183]], grad_fn=<SigmoidBackward>), target tensor([1., 0., 1., 1.])\n",
      "Input tensor([[0.1863, 0.5114, 0.4432, 0.7202, 0.6351, 1.0000, 1.0000, 1.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.1863, 0.5114, 0.4432, 0.7202, 0.0453, 1.0000, 1.0000, 1.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.2156, 0.4923, 0.4462, 0.7453, 0.0144, 0.0000, 1.0000, 1.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.2156, 0.4923, 0.4462, 0.7453, 0.1161, 0.0000, 1.0000, 1.0000, 0.0000,\n",
      "         0.0000]])\n",
      "Output tensor([[0.9049],\n",
      "        [0.2922],\n",
      "        [0.8917],\n",
      "        [0.9212]], grad_fn=<SigmoidBackward>), target tensor([1., 0., 1., 1.])\n",
      "Input tensor([[0.1863, 0.5114, 0.4432, 0.7202, 0.6351, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         1.0000],\n",
      "        [0.1863, 0.5114, 0.4432, 0.7202, 0.0453, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         1.0000],\n",
      "        [0.2156, 0.4923, 0.4462, 0.7453, 0.0144, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         1.0000],\n",
      "        [0.2156, 0.4923, 0.4462, 0.7453, 0.1161, 1.0000, 0.0000, 0.0000, 0.0000,\n",
      "         1.0000]])\n",
      "Output tensor([[0.9642],\n",
      "        [0.7336],\n",
      "        [0.7225],\n",
      "        [0.5207]], grad_fn=<SigmoidBackward>), target tensor([1., 0., 1., 1.])\n",
      "Input tensor([[0.1863, 0.5114, 0.4432, 0.7202, 0.6351, 1.0000, 1.0000, 0.0000, 1.0000,\n",
      "         0.0000],\n",
      "        [0.1863, 0.5114, 0.4432, 0.7202, 0.0453, 0.0000, 1.0000, 0.0000, 1.0000,\n",
      "         0.0000],\n",
      "        [0.2156, 0.4923, 0.4462, 0.7453, 0.0144, 1.0000, 1.0000, 0.0000, 1.0000,\n",
      "         0.0000],\n",
      "        [0.2156, 0.4923, 0.4462, 0.7453, 0.1161, 0.0000, 1.0000, 0.0000, 1.0000,\n",
      "         0.0000]])\n",
      "Output tensor([[0.9079],\n",
      "        [0.7838],\n",
      "        [0.4926],\n",
      "        [0.8200]], grad_fn=<SigmoidBackward>), target tensor([1., 1., 1., 0.])\n",
      "Input tensor([[0.1863, 0.5114, 0.4432, 0.7202, 0.6351, 1.0000, 1.0000, 1.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.1863, 0.5114, 0.4432, 0.7202, 0.0453, 1.0000, 1.0000, 1.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.2156, 0.4923, 0.4462, 0.7453, 0.0144, 0.0000, 1.0000, 1.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.2156, 0.4923, 0.4462, 0.7453, 0.1161, 0.0000, 1.0000, 1.0000, 0.0000,\n",
      "         0.0000]])\n",
      "Output tensor([[0.9189],\n",
      "        [0.2852],\n",
      "        [0.8989],\n",
      "        [0.9279]], grad_fn=<SigmoidBackward>), target tensor([1., 0., 1., 1.])\n",
      "Input tensor([[0.1863, 0.5114, 0.4432, 0.7202, 0.6351, 1.0000, 1.0000, 1.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.1863, 0.5114, 0.4432, 0.7202, 0.0453, 1.0000, 1.0000, 1.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.2156, 0.4923, 0.4462, 0.7453, 0.0144, 0.0000, 1.0000, 1.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.2156, 0.4923, 0.4462, 0.7453, 0.1161, 0.0000, 1.0000, 1.0000, 0.0000,\n",
      "         0.0000]])\n",
      "Output tensor([[0.9228],\n",
      "        [0.2821],\n",
      "        [0.8995],\n",
      "        [0.9285]], grad_fn=<SigmoidBackward>), target tensor([1., 0., 1., 1.])\n",
      "Input tensor([[0.1863, 0.5114, 0.4432, 0.7202, 0.6351, 1.0000, 1.0000, 1.0000, 0.0000,\n",
      "         1.0000],\n",
      "        [0.1863, 0.5114, 0.4432, 0.7202, 0.0453, 1.0000, 1.0000, 1.0000, 0.0000,\n",
      "         1.0000],\n",
      "        [0.2156, 0.4923, 0.4462, 0.7453, 0.0144, 0.0000, 1.0000, 1.0000, 0.0000,\n",
      "         1.0000],\n",
      "        [0.2156, 0.4923, 0.4462, 0.7453, 0.1161, 1.0000, 1.0000, 1.0000, 0.0000,\n",
      "         1.0000]])\n",
      "Output tensor([[0.9188],\n",
      "        [0.3992],\n",
      "        [0.8811],\n",
      "        [0.4769]], grad_fn=<SigmoidBackward>), target tensor([1., 1., 0., 1.])\n",
      "Input tensor([[0.1863, 0.5114, 0.4432, 0.7202, 0.6351, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "         1.0000],\n",
      "        [0.1863, 0.5114, 0.4432, 0.7202, 0.0453, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "         1.0000],\n",
      "        [0.2156, 0.4923, 0.4462, 0.7453, 0.0144, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "         1.0000],\n",
      "        [0.2156, 0.4923, 0.4462, 0.7453, 0.1161, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "         1.0000]])\n",
      "Output tensor([[0.9402],\n",
      "        [0.5261],\n",
      "        [0.5020],\n",
      "        [0.6061]], grad_fn=<SigmoidBackward>), target tensor([1., 1., 0., 1.])\n",
      "Input tensor([[0.1863, 0.5114, 0.4432, 0.7202, 0.6351, 0.0000, 0.0000, 1.0000, 1.0000,\n",
      "         0.0000],\n",
      "        [0.1863, 0.5114, 0.4432, 0.7202, 0.0453, 1.0000, 0.0000, 1.0000, 1.0000,\n",
      "         0.0000],\n",
      "        [0.2156, 0.4923, 0.4462, 0.7453, 0.0144, 1.0000, 0.0000, 1.0000, 1.0000,\n",
      "         0.0000],\n",
      "        [0.2156, 0.4923, 0.4462, 0.7453, 0.1161, 0.0000, 0.0000, 1.0000, 1.0000,\n",
      "         0.0000]])\n",
      "Output tensor([[0.9909],\n",
      "        [0.6031],\n",
      "        [0.5789],\n",
      "        [0.9049]], grad_fn=<SigmoidBackward>), target tensor([1., 1., 1., 0.])\n",
      "Input tensor([[0.1863, 0.5114, 0.4432, 0.7202, 0.6351, 1.0000, 1.0000, 1.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.1863, 0.5114, 0.4432, 0.7202, 0.0453, 1.0000, 1.0000, 1.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.2156, 0.4923, 0.4462, 0.7453, 0.0144, 0.0000, 1.0000, 1.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.2156, 0.4923, 0.4462, 0.7453, 0.1161, 0.0000, 1.0000, 1.0000, 0.0000,\n",
      "         0.0000]])\n",
      "Output tensor([[0.9583],\n",
      "        [0.3866],\n",
      "        [0.9194],\n",
      "        [0.9441]], grad_fn=<SigmoidBackward>), target tensor([1., 0., 1., 1.])\n",
      "Input tensor([[0.1863, 0.5114, 0.4432, 0.7202, 0.6351, 1.0000, 1.0000, 1.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.1863, 0.5114, 0.4432, 0.7202, 0.0453, 1.0000, 1.0000, 1.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.2156, 0.4923, 0.4462, 0.7453, 0.0144, 0.0000, 1.0000, 1.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.2156, 0.4923, 0.4462, 0.7453, 0.1161, 0.0000, 1.0000, 1.0000, 0.0000,\n",
      "         0.0000]])\n",
      "Output tensor([[0.9629],\n",
      "        [0.4113],\n",
      "        [0.9211],\n",
      "        [0.9450]], grad_fn=<SigmoidBackward>), target tensor([1., 0., 1., 1.])\n",
      "Input tensor([[0.1863, 0.5114, 0.4432, 0.7202, 0.6351, 1.0000, 1.0000, 1.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.1863, 0.5114, 0.4432, 0.7202, 0.0453, 1.0000, 1.0000, 1.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.2156, 0.4923, 0.4462, 0.7453, 0.0144, 0.0000, 1.0000, 1.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.2156, 0.4923, 0.4462, 0.7453, 0.1161, 0.0000, 1.0000, 1.0000, 0.0000,\n",
      "         0.0000]])\n",
      "Output tensor([[0.9644],\n",
      "        [0.4138],\n",
      "        [0.9197],\n",
      "        [0.9437]], grad_fn=<SigmoidBackward>), target tensor([1., 0., 1., 1.])\n",
      "Input tensor([[0.1863, 0.5114, 0.4432, 0.7202, 0.6351, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "         1.0000],\n",
      "        [0.1863, 0.5114, 0.4432, 0.7202, 0.0453, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "         1.0000],\n",
      "        [0.2156, 0.4923, 0.4462, 0.7453, 0.0144, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "         1.0000],\n",
      "        [0.2156, 0.4923, 0.4462, 0.7453, 0.1161, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "         1.0000]])\n",
      "Output tensor([[0.9759],\n",
      "        [0.7197],\n",
      "        [0.6987],\n",
      "        [0.7835]], grad_fn=<SigmoidBackward>), target tensor([1., 1., 0., 1.])\n",
      "Input tensor([[0.1863, 0.5114, 0.4432, 0.7202, 0.6351, 1.0000, 1.0000, 1.0000, 0.0000,\n",
      "         1.0000],\n",
      "        [0.1863, 0.5114, 0.4432, 0.7202, 0.0453, 1.0000, 1.0000, 1.0000, 0.0000,\n",
      "         1.0000],\n",
      "        [0.2156, 0.4923, 0.4462, 0.7453, 0.0144, 0.0000, 1.0000, 1.0000, 0.0000,\n",
      "         1.0000],\n",
      "        [0.2156, 0.4923, 0.4462, 0.7453, 0.1161, 1.0000, 1.0000, 1.0000, 0.0000,\n",
      "         1.0000]])\n",
      "Output tensor([[0.9670],\n",
      "        [0.5955],\n",
      "        [0.8965],\n",
      "        [0.6727]], grad_fn=<SigmoidBackward>), target tensor([1., 1., 0., 1.])\n",
      "Input tensor([[0.1863, 0.5114, 0.4432, 0.7202, 0.6351, 1.0000, 1.0000, 1.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.1863, 0.5114, 0.4432, 0.7202, 0.0453, 1.0000, 1.0000, 1.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.2156, 0.4923, 0.4462, 0.7453, 0.0144, 0.0000, 1.0000, 1.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.2156, 0.4923, 0.4462, 0.7453, 0.1161, 0.0000, 1.0000, 1.0000, 0.0000,\n",
      "         0.0000]])\n",
      "Output tensor([[0.9579],\n",
      "        [0.3596],\n",
      "        [0.8962],\n",
      "        [0.9274]], grad_fn=<SigmoidBackward>), target tensor([1., 0., 1., 1.])\n",
      "instance 0, ep 4\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 6\u001b[0m\n\u001b[1;32m      2\u001b[0m name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmcts\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      4\u001b[0m train_iterations \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m30\u001b[39m\n\u001b[0;32m----> 6\u001b[0m rewards, memory, simulator \u001b[38;5;241m=\u001b[39m \u001b[43mrun_multi_seed\u001b[49m\u001b[43m(\u001b[49m\u001b[43mseed_list\u001b[49m\u001b[43m,\u001b[49m\u001b[43mpolicy\u001b[49m\u001b[43m,\u001b[49m\u001b[43mis_mcts\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43mtrain_iterations\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_iterations\u001b[49m\u001b[43m,\u001b[49m\u001b[43mtest_iterations\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest_iterations\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      7\u001b[0m results[\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m_reward\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(name)] \u001b[38;5;241m=\u001b[39m rewards[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mreward\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m      8\u001b[0m results[\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m_match\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(name)] \u001b[38;5;241m=\u001b[39m  rewards[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmatch\u001b[39m\u001b[38;5;124m'\u001b[39m] \n",
      "Cell \u001b[0;32mIn[10], line 19\u001b[0m, in \u001b[0;36mrun_multi_seed\u001b[0;34m(seed_list, policy, is_mcts, per_epoch_function, train_iterations, test_iterations, test_length)\u001b[0m\n\u001b[1;32m     16\u001b[0m     simulator\u001b[38;5;241m.\u001b[39mvalue_lr \u001b[38;5;241m=\u001b[39m value_lr\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_mcts:\n\u001b[0;32m---> 19\u001b[0m     match, active_rate, memory \u001b[38;5;241m=\u001b[39m \u001b[43mrun_heterogenous_policy\u001b[49m\u001b[43m(\u001b[49m\u001b[43msimulator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_episodes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_epochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdiscount\u001b[49m\u001b[43m,\u001b[49m\u001b[43mpolicy\u001b[49m\u001b[43m,\u001b[49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\u001b[43mlamb\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlamb\u001b[49m\u001b[43m,\u001b[49m\u001b[43mshould_train\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43mtest_T\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest_length\u001b[49m\u001b[43m,\u001b[49m\u001b[43mget_memory\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43mper_epoch_function\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mper_epoch_function\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     21\u001b[0m     match, active_rate \u001b[38;5;241m=\u001b[39m run_heterogenous_policy(simulator, n_episodes, n_epochs, discount,policy,seed,lamb\u001b[38;5;241m=\u001b[39mlamb,should_train\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,test_T\u001b[38;5;241m=\u001b[39mtest_length,per_epoch_function\u001b[38;5;241m=\u001b[39mper_epoch_function)\n",
      "File \u001b[0;32m~/projects/food_rescue_rmab/rmab/omniscient_policies.py:953\u001b[0m, in \u001b[0;36mrun_heterogenous_policy\u001b[0;34m(env, n_episodes, n_epochs, discount, policy, seed, per_epoch_function, lamb, get_memory, should_train, test_T)\u001b[0m\n\u001b[1;32m    950\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    951\u001b[0m     all_active_rate[epoch,t] \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39msum(state)\u001b[38;5;241m/\u001b[39m\u001b[38;5;28mlen\u001b[39m(state)\n\u001b[0;32m--> 953\u001b[0m action,memory \u001b[38;5;241m=\u001b[39m \u001b[43mpolicy\u001b[49m\u001b[43m(\u001b[49m\u001b[43menv\u001b[49m\u001b[43m,\u001b[49m\u001b[43mstate\u001b[49m\u001b[43m,\u001b[49m\u001b[43mbudget\u001b[49m\u001b[43m,\u001b[49m\u001b[43mlamb\u001b[49m\u001b[43m,\u001b[49m\u001b[43mmemory\u001b[49m\u001b[43m,\u001b[49m\u001b[43mper_epoch_results\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    954\u001b[0m next_state, reward, done, _ \u001b[38;5;241m=\u001b[39m env\u001b[38;5;241m.\u001b[39mstep(action)\n\u001b[1;32m    956\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m done \u001b[38;5;129;01mand\u001b[39;00m t\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m<\u001b[39m T: env\u001b[38;5;241m.\u001b[39mreset()\n",
      "File \u001b[0;32m~/projects/food_rescue_rmab/rmab/mcts_policies.py:564\u001b[0m, in \u001b[0;36mfull_mcts_policy\u001b[0;34m(env, state, budget, lamb, memory, per_epoch_results, contextual)\u001b[0m\n\u001b[1;32m    562\u001b[0m should_break \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m \n\u001b[1;32m    563\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(scores_current_combo) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m--> 564\u001b[0m     current_value \u001b[38;5;241m=\u001b[39m \u001b[43mget_total_value\u001b[49m\u001b[43m(\u001b[49m\u001b[43menv\u001b[49m\u001b[43m,\u001b[49m\u001b[43mall_match_probs\u001b[49m\u001b[43m,\u001b[49m\u001b[43mbest_group_arms\u001b[49m\u001b[43m,\u001b[49m\u001b[43mstate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    565\u001b[0m \u001b[43m                                    \u001b[49m\u001b[43mgroup_indices\u001b[49m\u001b[43m,\u001b[49m\u001b[43mvalue_network\u001b[49m\u001b[43m,\u001b[49m\u001b[43mpolicy_network\u001b[49m\u001b[43m,\u001b[49m\u001b[43mlamb\u001b[49m\u001b[43m,\u001b[49m\u001b[43mnum_future_samples\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m25\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mcontextual\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcontextual\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    566\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m arm \u001b[38;5;129;01min\u001b[39;00m scores_current_combo:\n\u001b[1;32m    567\u001b[0m         new_group_index \u001b[38;5;241m=\u001b[39m deepcopy(group_indices)\n",
      "File \u001b[0;32m~/projects/food_rescue_rmab/rmab/mcts_policies.py:164\u001b[0m, in \u001b[0;36mget_total_value\u001b[0;34m(env, all_match_probs, best_group_arms, state, group_indices, value_network, policy_network, lamb, num_future_samples, weighted, contextual)\u001b[0m\n\u001b[1;32m    161\u001b[0m samples \u001b[38;5;241m=\u001b[39m samples \u001b[38;5;241m<\u001b[39m probs \n\u001b[1;32m    162\u001b[0m samples \u001b[38;5;241m=\u001b[39m samples\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mfloat\u001b[39m)\n\u001b[0;32m--> 164\u001b[0m future_actions \u001b[38;5;241m=\u001b[39m \u001b[43mget_action_state\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpolicy_network\u001b[49m\u001b[43m,\u001b[49m\u001b[43msamples\u001b[49m\u001b[43m,\u001b[49m\u001b[43menv\u001b[49m\u001b[43m,\u001b[49m\u001b[43mcontextual\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcontextual\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    166\u001b[0m future_actions \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mTensor(future_actions)\n\u001b[1;32m    167\u001b[0m future_states \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mTensor(samples)\n",
      "File \u001b[0;32m~/projects/food_rescue_rmab/rmab/mcts_policies.py:392\u001b[0m, in \u001b[0;36mget_action_state\u001b[0;34m(policy_network, state_list, env, contextual)\u001b[0m\n\u001b[1;32m    381\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Given a state, find the best action using the policy network\u001b[39;00m\n\u001b[1;32m    382\u001b[0m \u001b[38;5;124;03m\u001b[39;00m\n\u001b[1;32m    383\u001b[0m \u001b[38;5;124;03mArguments: \u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    387\u001b[0m \u001b[38;5;124;03m\u001b[39;00m\n\u001b[1;32m    388\u001b[0m \u001b[38;5;124;03mReturns: Numpy array, 0-1 action for each agent\"\"\"\u001b[39;00m\n\u001b[1;32m    390\u001b[0m x_points \u001b[38;5;241m=\u001b[39m get_policy_network_input_many_state(env,np\u001b[38;5;241m.\u001b[39marray(state_list),contextual\u001b[38;5;241m=\u001b[39mcontextual)\n\u001b[0;32m--> 392\u001b[0m policy_network_predictions \u001b[38;5;241m=\u001b[39m \u001b[43mpolicy_network\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_points\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mdetach() \n\u001b[1;32m    393\u001b[0m policy_network_predictions \u001b[38;5;241m=\u001b[39m policy_network_predictions\u001b[38;5;241m.\u001b[39mnumpy()\n\u001b[1;32m    395\u001b[0m action \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mzeros(np\u001b[38;5;241m.\u001b[39marray(state_list)\u001b[38;5;241m.\u001b[39mshape, dtype\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mint8)\n",
      "File \u001b[0;32m~/miniconda3/envs/food/lib/python3.8/site-packages/torch/nn/modules/module.py:889\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_slow_forward(\u001b[38;5;241m*\u001b[39m\u001b[38;5;28minput\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    888\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 889\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    890\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m hook \u001b[38;5;129;01min\u001b[39;00m itertools\u001b[38;5;241m.\u001b[39mchain(\n\u001b[1;32m    891\u001b[0m         _global_forward_hooks\u001b[38;5;241m.\u001b[39mvalues(),\n\u001b[1;32m    892\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks\u001b[38;5;241m.\u001b[39mvalues()):\n\u001b[1;32m    893\u001b[0m     hook_result \u001b[38;5;241m=\u001b[39m hook(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m, result)\n",
      "File \u001b[0;32m~/projects/food_rescue_rmab/rmab/mcts_policies.py:26\u001b[0m, in \u001b[0;36mMLP.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[0;32m---> 26\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfc1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     27\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrelu(x)\n\u001b[1;32m     28\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfc2(x)\n",
      "File \u001b[0;32m~/miniconda3/envs/food/lib/python3.8/site-packages/torch/nn/modules/module.py:889\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_slow_forward(\u001b[38;5;241m*\u001b[39m\u001b[38;5;28minput\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    888\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 889\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    890\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m hook \u001b[38;5;129;01min\u001b[39;00m itertools\u001b[38;5;241m.\u001b[39mchain(\n\u001b[1;32m    891\u001b[0m         _global_forward_hooks\u001b[38;5;241m.\u001b[39mvalues(),\n\u001b[1;32m    892\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks\u001b[38;5;241m.\u001b[39mvalues()):\n\u001b[1;32m    893\u001b[0m     hook_result \u001b[38;5;241m=\u001b[39m hook(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m, result)\n",
      "File \u001b[0;32m~/miniconda3/envs/food/lib/python3.8/site-packages/torch/nn/modules/linear.py:94\u001b[0m, in \u001b[0;36mLinear.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     93\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m---> 94\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/food/lib/python3.8/site-packages/torch/nn/functional.py:1753\u001b[0m, in \u001b[0;36mlinear\u001b[0;34m(input, weight, bias)\u001b[0m\n\u001b[1;32m   1751\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_variadic(\u001b[38;5;28minput\u001b[39m, weight):\n\u001b[1;32m   1752\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(linear, (\u001b[38;5;28minput\u001b[39m, weight), \u001b[38;5;28minput\u001b[39m, weight, bias\u001b[38;5;241m=\u001b[39mbias)\n\u001b[0;32m-> 1753\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_C\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_nn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "policy = full_mcts_policy \n",
    "name = \"mcts\"\n",
    "\n",
    "train_iterations = 30\n",
    "\n",
    "rewards, memory, simulator = run_multi_seed(seed_list,policy,is_mcts=True,train_iterations=train_iterations,test_iterations=test_iterations)\n",
    "results['{}_reward'.format(name)] = rewards['reward']\n",
    "results['{}_match'.format(name)] =  rewards['match'] \n",
    "results['{}_active'.format(name)] = rewards['active_rate']\n",
    "results['{}_time'.format(name)] =  rewards['time']\n",
    "print(np.mean(rewards['reward']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_sliding_window(data):\n",
    "    return [np.mean(data[i:i+100]) for i in range(len(data)-100)]\n",
    "policy_loss_1 = memory[0][-5]\n",
    "value_loss_1 = memory[0][-9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "if is_jupyter:  \n",
    "    plt.plot(plot_sliding_window(value_loss_1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "if is_jupyter:\n",
    "    plt.plot(plot_sliding_window(policy_loss_1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "results['policy_loss'] = policy_loss_1\n",
    "results['value_loss'] = value_loss_1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ground Truth Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "policy_network, value_network = memory[0][-4], memory[0][-8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1267126/2068906370.py:3: DeprecationWarning: elementwise comparison failed; this will raise an error in the future.\n",
      "  if match_probability != []:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.7217488288879395 4.5101311390015635\n",
      "4.986460208892822 4.741027640875495\n",
      "4.879215240478516 4.667865269771092\n",
      "5.102160453796387 4.898761752189062\n",
      "4.849817276000977 4.689985718068489\n",
      "5.132834434509277 4.918164728001081\n",
      "5.040750503540039 4.847719895605013\n",
      "5.281506538391113 5.075898877924958\n",
      "5.181951522827148 5.049054991726956\n",
      "5.411447525024414 5.24129544350582\n",
      "5.396163463592529 5.206789163212061\n",
      "5.600570201873779 5.399029588227538\n",
      "5.334846496582031 5.213969434709716\n",
      "5.57490348815918 5.405178993132531\n",
      "5.546046257019043 5.3717036666905855\n",
      "5.771955966949463 5.562913187049813\n"
     ]
    }
   ],
   "source": [
    "if volunteers_per_arm * n_arms <= 4:\n",
    "    match_probability = simulator.match_probability_list \n",
    "    if match_probability != []:\n",
    "        match_probability = np.array(match_probability)[simulator.agent_idx]\n",
    "    true_transitions = simulator.transitions\n",
    "    discount = simulator.discount \n",
    "    budget = simulator.budget \n",
    "\n",
    "    Q_vals = arm_value_iteration_exponential(true_transitions,discount,budget,simulator.volunteers_per_arm,\n",
    "                    reward_function='combined',lamb=lamb,\n",
    "                    match_probability_list=match_probability)\n",
    "\n",
    "    N = volunteers_per_arm*n_arms \n",
    "    error_max_action = []\n",
    "    error_overall = []\n",
    "    for s in range(2**(volunteers_per_arm*n_arms)):\n",
    "        state = [int(j) for j in bin(s)[2:].zfill(N)]\n",
    "        max_q_val = np.max(Q_vals[s])\n",
    "        max_action = np.argmax(Q_vals[s])\n",
    "        action = [int(j) for j in bin(max_action)[2:].zfill(N)]\n",
    "        predicted_q_val = value_network(torch.Tensor([state+action])).item() \n",
    "        error_max_action.append((predicted_q_val-max_q_val)**2)\n",
    "\n",
    "        print(predicted_q_val,max_q_val)\n",
    "\n",
    "        for a in range(2**(volunteers_per_arm*n_arms)):\n",
    "            action = [int(j) for j in bin(a)[2:].zfill(N)]\n",
    "            predicted_q_val = value_network(torch.Tensor([state+action])).item()\n",
    "            actual_q_val = Q_vals[s][a]\n",
    "            error_overall.append((predicted_q_val-actual_q_val)**2)\n",
    "    \n",
    "    results['value_error_max_action'] = error_max_action\n",
    "    results['value_error_overall'] = error_overall     \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.04478204667284639,\n",
       " 0.06023714544358009,\n",
       " 0.044668810118028986,\n",
       " 0.041371031815545675,\n",
       " 0.02554612691112607,\n",
       " 0.04608308289231527,\n",
       " 0.037260815599765774,\n",
       " 0.04227451004236576,\n",
       " 0.01766148797846452,\n",
       " 0.028951730845110393,\n",
       " 0.035862625644591715,\n",
       " 0.040618618948903375,\n",
       " 0.014611264086883563,\n",
       " 0.028806404212050846,\n",
       " 0.030395338802436344,\n",
       " 0.04369888382817348]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "error_max_action"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Monotonicity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Value Function monotonicity \n",
    "num_trials = 100\n",
    "num_not_monotonic = 0 \n",
    "avg_diff = []\n",
    "\n",
    "for i in range(num_trials):\n",
    "    random_state = [random.randint(0,1) for i in range(n_arms*volunteers_per_arm)]\n",
    "    while sum(random_state) == n_arms*volunteers_per_arm:\n",
    "        random_state = [random.randint(0,1) for i in range(n_arms*volunteers_per_arm)]\n",
    "    choices = [i for i in range(n_arms*volunteers_per_arm) if random_state[i] == 0]\n",
    "    random_arm = random.choice(choices) \n",
    "    random_action = [random.randint(0,1) for i in range(n_arms*volunteers_per_arm)]\n",
    "    \n",
    "    value_without = value_network(torch.Tensor(random_state+random_action)).item() \n",
    "    random_state[random_arm] = 1\n",
    "    value_with = value_network(torch.Tensor(random_state+random_action)).item() \n",
    "    if value_with < value_without:\n",
    "        num_not_monotonic += 1\n",
    "    avg_diff.append(value_with-value_without)\n",
    "\n",
    "results['num_not_monotonic'] = num_not_monotonic\n",
    "results['avg_monotonic_value_diff'] = avg_diff "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Policy Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_probabilities = []\n",
    "num_trials = 100\n",
    "\n",
    "for i in range(num_trials):\n",
    "    random_probs = policy_network(torch.Tensor(get_policy_network_input(simulator,[random.randint(0,1) for i in range(n_arms*volunteers_per_arm)],contextual=False)))\n",
    "    random_probs = random_probs.detach().numpy().flatten().tolist()\n",
    "    avg_probabilities.append(random_probs)\n",
    "results['policy_predictions_random'] = avg_probabilities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Write Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path = get_save_path(out_folder,save_name,seed,use_date=save_with_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "delete_duplicate_results(out_folder,\"\",results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "json.dump(results,open('../results/'+save_path,'w'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "food",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
